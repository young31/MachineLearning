{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier, \n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('./data/train.csv')\n",
    "te = pd.read_csv('./data/test.csv')\n",
    "\n",
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_lbe = LabelEncoder().fit(target)\n",
    "\n",
    "# t = target_lbe.transform(target)\n",
    "\n",
    "column_number = {}\n",
    "for i, column in enumerate(sub.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "tr['type_num'] = tr['type'].apply(lambda x: to_number(x, column_number))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tr['type_num']\n",
    "t = target.copy()\n",
    "\n",
    "train_X = tr.drop(['id', 'type', 'type_num', 'fiberID'], axis=1)\n",
    "test_X = te.drop(['id','fiberID'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train_X - np.mean(train_X))/np.std(train_X)\n",
    "test_X = (test_X - np.mean(test_X))/np.std(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "svc = SVC(kernel='rbf', probability=True)\n",
    "tree = DecisionTreeClassifier(max_depth=13)\n",
    "extree = ExtraTreeClassifier(max_depth=13)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                               max_depth=13,\n",
    "                               min_samples_split=5,\n",
    "                               min_samples_leaf=5,\n",
    "                               min_impurity_decrease = 0.001,\n",
    "                               max_features=None,\n",
    "                               oob_score=True,\n",
    "                               random_state=42)\n",
    "\n",
    "gbr = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                learning_rate=0.01,\n",
    "                                max_depth=9,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "#                                 loss='exponential',\n",
    "                                n_iter_no_change = 100,\n",
    "                                random_state=42)\n",
    "\n",
    "vclf = VotingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "    ('extree', extree),\n",
    "    ('tree', tree),\n",
    "],  n_jobs=-1, voting='soft'\n",
    ")\n",
    "\n",
    "stk_clf = StackingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "    ('extree', extree),\n",
    "    ('tree', tree),\n",
    "],  n_jobs=-1,\n",
    "    final_estimator=rf\n",
    ")\n",
    "\n",
    "pca = PCA(12)\n",
    "\n",
    "models = [lr, extree, rf, gbr, vclf, stk_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    print(np.mean(cross_val_score(m, train_X, t, cv=4, scoring='neg_log_loss')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[rf, extree, tree, pca], \n",
    "          [rf]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "Input Dimensionality 20 at Level 0 \n",
      "4 models included in Level 0 \n",
      "Fold 1/3 , model 0 , logloss===0.620507 \n",
      "Fold 1/3 , model 1 , logloss===1.832116 \n",
      "Fold 1/3 , model 2 , logloss===1.702189 \n",
      "=========== end of fold 1 in level 0 ===========\n",
      "Fold 2/3 , model 0 , logloss===0.621523 \n",
      "Fold 2/3 , model 1 , logloss===1.629268 \n",
      "Fold 2/3 , model 2 , logloss===1.609244 \n",
      "=========== end of fold 2 in level 0 ===========\n",
      "Fold 3/3 , model 0 , logloss===0.622132 \n",
      "Fold 3/3 , model 1 , logloss===1.603872 \n",
      "Fold 3/3 , model 2 , logloss===1.711076 \n",
      "=========== end of fold 3 in level 0 ===========\n",
      "Level 0, model 0 , logloss===0.621387 \n",
      "Level 0, model 1 , logloss===1.688418 \n",
      "Level 0, model 2 , logloss===1.674170 \n",
      "Output dimensionality of level 0 is 69 \n",
      "====================== End of Level 0 ======================\n",
      " level 0 lasted 2008.674325 seconds \n",
      "====================== Start of Level 1 ======================\n",
      "Input Dimensionality 69 at Level 1 \n",
      "1 models included in Level 1 \n",
      "Fold 1/3 , model 0 , logloss===0.596662 \n",
      "=========== end of fold 1 in level 1 ===========\n",
      "Fold 2/3 , model 0 , logloss===0.574865 \n",
      "=========== end of fold 2 in level 1 ===========\n",
      "Fold 3/3 , model 0 , logloss===0.586158 \n",
      "=========== end of fold 3 in level 1 ===========\n",
      "Level 1, model 0 , logloss===0.585895 \n",
      "Output dimensionality of level 1 is 19 \n",
      "====================== End of Level 1 ======================\n",
      " level 1 lasted 2165.562702 seconds \n",
      "====================== End of fit ======================\n",
      " fit() lasted 4174.253491 seconds \n"
     ]
    }
   ],
   "source": [
    "model = StackNetClassifier(models, \n",
    "                           metric=\"logloss\", \n",
    "                           folds=3,\n",
    "                           restacking=False,\n",
    "                           use_retraining=True,\n",
    "                           use_proba=True, # To use predict_proba after training\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "model.fit(train_X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "1 estimators included in Level 0 \n",
      "====================== Start of Level 1 ======================\n",
      "1 estimators included in Level 1 \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_proba(test_X)\n",
    "submission = pd.DataFrame(data=y_pred, columns=sub.columns, index=sub.index)\n",
    "submission.to_csv('./sub/sample1.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./sub/rf1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
