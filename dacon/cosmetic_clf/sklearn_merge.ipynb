{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('./data/train.csv')\n",
    "te = pd.read_csv('./data/test.csv')\n",
    "\n",
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_lbe = LabelEncoder().fit(target)\n",
    "\n",
    "# t = target_lbe.transform(target)\n",
    "\n",
    "column_number = {}\n",
    "for i, column in enumerate(sub.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "tr['type_num'] = tr['type'].apply(lambda x: to_number(x, column_number))\n",
    "\n",
    "target = tr['type_num']\n",
    "t = target.copy()\n",
    "\n",
    "train_X = tr.drop(['id', 'type', 'type_num'], axis=1)\n",
    "test_X = te.drop(['id',], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X['index'] = np.ones(len(train_X))\n",
    "test_X['index'] = np.ones(len(test_X))*2\n",
    "\n",
    "merge = pd.concat([train_X, test_X], ignore_index=True)\n",
    "\n",
    "k = train_X.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([merge, pd.get_dummies(merge['fiberID'], prefix='fiberID')], axis=1)\n",
    "merge = merge.drop('fiberID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = merge[merge['index'] == 1]\n",
    "train_X = train_X.drop('index', axis=1)\n",
    "test_X = merge[merge['index'] == 2]\n",
    "test_X = test_X.drop('index', axis=1)\n",
    "test_X.index = range(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = train_X[k]\n",
    "te_X = test_X[k]\n",
    "\n",
    "tr_X = (tr_X - np.mean(tr_X))/np.std(tr_X)\n",
    "te_X = (te_X - np.mean(te_X))/np.std(te_X)\n",
    "\n",
    "train_X[k] = tr_X\n",
    "test_X[k] = te_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "svc = SVC(kernel='rbf', probability=True)\n",
    "tree = DecisionTreeClassifier(max_depth=19)\n",
    "extree = ExtraTreeClassifier(max_depth=19)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1200,\n",
    "                               max_depth=13,\n",
    "                               min_samples_split=5,\n",
    "                               min_samples_leaf=5,\n",
    "                               min_impurity_decrease = 0.001,\n",
    "                               max_features=None,\n",
    "                               oob_score=True,\n",
    "                               random_state=42)\n",
    "\n",
    "gbr = GradientBoostingClassifier(n_estimators=6000,\n",
    "                                learning_rate=0.005,\n",
    "                                max_depth=9,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "#                                 loss='exponential',\n",
    "                                n_iter_no_change = 100,\n",
    "                                random_state=42)\n",
    "\n",
    "vclf = VotingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "    ('gbr', gbr),\n",
    "    ('lr', lr),\n",
    "#     ('extree', extree),\n",
    "    ('knn', knn)\n",
    "],  n_jobs=-1, voting='soft'\n",
    ")\n",
    "\n",
    "stk_clf = StackingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "#     ('gbr', gbr),\n",
    "    ('lr', lr),\n",
    "    ('extree', extree),\n",
    "#     ('knn', knn)\n",
    "],  n_jobs=-1,\n",
    "    final_estimator=rf\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models = [lr, extree, rf, gbr, vclf, stk_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators=150,\n",
    "                                max_depth=9, \n",
    "                                max_features='sqrt', \n",
    "                                random_state=42)\n",
    "\n",
    "pca = PCA(100)\n",
    "\n",
    "models = [[pca, rf], \n",
    "          [rf]]\n",
    "\n",
    "\n",
    "model = StackNetClassifier(models, \n",
    "                           metric=\"logloss\", \n",
    "                           folds=2,\n",
    "                           restacking=False,\n",
    "                           use_retraining=True,\n",
    "                           use_proba=True, # To use predict_proba after training\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "model.fit(train_X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_X)\n",
    "submission = pd.DataFrame(data=y_pred, columns=sub.columns, index=sub.index)\n",
    "submission.to_csv('./sub/stk_sample3.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    print(np.mean(cross_val_score(m, train_X, t, cv=4, scoring='neg_log_loss')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
