{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('./data/train.csv')\n",
    "te = pd.read_csv('./data/test.csv')\n",
    "\n",
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_lbe = LabelEncoder().fit(target)\n",
    "\n",
    "# t = target_lbe.transform(target)\n",
    "\n",
    "column_number = {}\n",
    "for i, column in enumerate(sub.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "tr['type_num'] = tr['type'].apply(lambda x: to_number(x, column_number))\n",
    "\n",
    "target = tr['type_num']\n",
    "t = target.copy()\n",
    "\n",
    "train_X = tr.drop(['id', 'type', 'type_num'], axis=1)\n",
    "test_X = te.drop(['id',], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train_X - np.mean(train_X))/np.std(train_X)\n",
    "test_X = (test_X - np.mean(test_X))/np.std(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseBlock(n, activation='relu'):\n",
    "    def f(x):\n",
    "        x = layers.Dense(n, kernel_initializer='he_normal', kernel_regularizer=L1L2(l2=0.001))(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(train_X.shape[1], ))\n",
    "\n",
    "x1 = layers.Dense(256*4, kernel_initializer='he_normal', kernel_regularizer=L1L2(l2=0.0001))(inputs)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Activation('relu')(x1)\n",
    "\n",
    "x1 = DenseBlock(256*4)(x1)\n",
    "# x1 = DenseBlock(256*3)(x1)\n",
    "x1 = DenseBlock(256*2)(x1)\n",
    "x1 = DenseBlock(256)(x1)\n",
    "x1 = DenseBlock(64)(x1)\n",
    "# x1 = DenseBlock(32)(x1)\n",
    "\n",
    "x2 = layers.Dense(256*2, kernel_initializer='he_normal', kernel_regularizer=L1L2(l2=0.0001))(inputs)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "\n",
    "x2 = DenseBlock(256, 'tanh')(x2)\n",
    "# x2 = DenseBlock(256, 'tanh')(x2)\n",
    "x2 = DenseBlock(128, 'tanh')(x2)\n",
    "x2 = DenseBlock(64, 'tanh')(x2)\n",
    "# x2 = DenseBlock(32, 'tanh')(x2)\n",
    "\n",
    "\n",
    "x = layers.add([x1, x2])\n",
    "\n",
    "# x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(19, activation='softmax')(x)\n",
    "\n",
    "m = models.Model(inputs, x)\n",
    "\n",
    "# sparse_categorical_crossentropy\n",
    "m.compile(optimizer = optimizers.Adam(lr=1e-4),\n",
    "         loss = 'sparse_categorical_crossentropy', \n",
    "          metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(train_X, t, \n",
    "     epochs = 1000,\n",
    "     validation_split=0.1,\n",
    "     batch_size=1024*16,\n",
    "      callbacks=[es]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(train_X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[sub.columns[1:]] = m.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./sub/nn2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
