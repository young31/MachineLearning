{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.wrappers.scikit_learn.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('./data/train.csv')\n",
    "te = pd.read_csv('./data/test.csv')\n",
    "\n",
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_lbe = LabelEncoder().fit(target)\n",
    "\n",
    "# t = target_lbe.transform(target)\n",
    "\n",
    "column_number = {}\n",
    "for i, column in enumerate(sub.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "tr['type_num'] = tr['type'].apply(lambda x: to_number(x, column_number))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tr['type_num']\n",
    "t = target.copy()\n",
    "\n",
    "train_X = tr.drop(['id', 'type', 'type_num'], axis=1)\n",
    "test_X = te.drop(['id',], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          8\n",
       "1          8\n",
       "2          8\n",
       "3          8\n",
       "4         10\n",
       "          ..\n",
       "199986     8\n",
       "199987     6\n",
       "199988    10\n",
       "199989     6\n",
       "199990     8\n",
       "Name: type_num, Length: 199991, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X['index'] = np.ones(len(train_X))\n",
    "test_X['index'] = np.ones(len(test_X))*2\n",
    "\n",
    "merge = pd.concat([train_X, test_X], ignore_index=True)\n",
    "\n",
    "k = train_X.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([merge, pd.get_dummies(merge['fiberID'], prefix='fiberID')], axis=1)\n",
    "merge = merge.drop('fiberID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = merge[merge['index'] == 1]\n",
    "train_X = train_X.drop('index', axis=1)\n",
    "test_X = merge[merge['index'] == 2]\n",
    "test_X = test_X.drop('index', axis=1)\n",
    "test_X.index = range(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = train_X[k]\n",
    "te_X = test_X[k]\n",
    "\n",
    "tr_X = (tr_X - np.mean(tr_X))/np.std(tr_X)\n",
    "te_X = (te_X - np.mean(te_X))/np.std(te_X)\n",
    "\n",
    "train_X[k] = tr_X\n",
    "test_X[k] = te_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "def schedule(epoch):\n",
    "    if epoch < 80:\n",
    "        return 0.0005\n",
    "    elif epoch < 160:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "lrs = LearningRateScheduler(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseBlock(n, activation='relu'):\n",
    "    def f(x):\n",
    "        x = layers.Dense(n, kernel_initializer='he_normal', kernel_regularizer=L1L2(l2=0.001))(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "        x = layers.advanced_activations.LeakyReLU(0.3)(x)\n",
    "        \n",
    "        return x\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(train_X.shape[1], ))\n",
    "\n",
    "x1 = layers.Dense(256*4, kernel_initializer='he_normal', kernel_regularizer=L1L2(l2=0.0001))(inputs)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Activation('relu')(x1)\n",
    "\n",
    "x1 = DenseBlock(256*4)(x1)\n",
    "# x1 = DenseBlock(256*3)(x1)\n",
    "x1 = DenseBlock(256*2)(x1)\n",
    "x1 = DenseBlock(256)(x1)\n",
    "x1 = DenseBlock(64)(x1)\n",
    "# x1 = DenseBlock(32)(x1)\n",
    "\n",
    "x2 = layers.Dense(256*4, kernel_initializer='he_normal', kernel_regularizer=L1L2(l2=0.0001))(inputs)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "\n",
    "x2 = DenseBlock(256, 'tanh')(x2)\n",
    "# x2 = DenseBlock(256, 'tanh')(x2)\n",
    "x2 = DenseBlock(128, 'tanh')(x2)\n",
    "x2 = DenseBlock(64, 'tanh')(x2)\n",
    "# x2 = DenseBlock(32, 'tanh')(x2)\n",
    "\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(19, activation='softmax')(x1)\n",
    "\n",
    "m = models.Model(inputs, x)\n",
    "\n",
    "# sparse_categorical_crossentropy\n",
    "m.compile(optimizer = 'adam',\n",
    "         loss = 'sparse_categorical_crossentropy', \n",
    "          metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.fit(train_X, t, \n",
    "     epochs = 1000,\n",
    "     validation_split=0.15,\n",
    "     batch_size=1024*16,\n",
    "      callbacks=[es, lrs]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(train_X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(train_X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(test_X)\n",
    "submission = pd.DataFrame(data=y_pred, columns=sub.columns, index=sub.index)\n",
    "submission.to_csv('./sub/nn6.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = pd.DataFrame(m.predict(test_X), columns=target_lbe.classes_)\n",
    "sub[sub.columns[1:]] = kk[sub.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./sub/nn4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.shape, test_X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
