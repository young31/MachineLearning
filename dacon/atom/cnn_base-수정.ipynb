{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.7.7\n",
      "pandas 1.0.4\n",
      "numpy 1.18.1\n",
      "lgb 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "print(f'python {python_version()}')\n",
    "print(f'pandas {pd.__version__}')\n",
    "print(f'numpy {np.__version__}')\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from scipy import integrate\n",
    "import seaborn as sns\n",
    "print(f'lgb {lgb.__version__}')\n",
    "import operator\n",
    "import datetime\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from scipy.stats import ks_2samp\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy.stats import norm, kurtosis\n",
    "from sklearn.metrics import make_scorer\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Dense, Activation, BatchNormalization, AlphaDropout, Dropout, Add, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Lambda, GlobalMaxPooling2D, SeparableConv2D\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential, Model, Input, load_model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    return x*K.tanh(K.softplus(x))\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.002\n",
    "    drop = 0.9\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    lrate = max(1e-5, lrate)\n",
    "    return lrate\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(patience=25, restore_best_weights=True)\n",
    "lrs = keras.callbacks.LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('./data/train_features.csv')\n",
    "train_target = pd.read_csv('./data/train_target.csv')\n",
    "test_features = pd.read_csv('./data/test_features.csv')\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 5\n",
    "# sampling frequency \n",
    "fmax = 32\n",
    "# sampling period\n",
    "dt = 1/fs\n",
    "# length of signal\n",
    "N  = 128\n",
    "\n",
    "df = fmax/N\n",
    "f = np.arange(0,N)*df\n",
    "\n",
    "train_ids = train_features.drop_duplicates(['id'])['id'].values\n",
    "\n",
    "signals = []\n",
    "ss = pd.DataFrame()\n",
    "sss = [[] for _ in range(4)]\n",
    "\n",
    "for i in tqdm(train_ids):\n",
    "    xf1 = np.fft.fft(train_features[train_features.id==i]['S1'].values)*dt\n",
    "    xf2 = np.fft.fft(train_features[train_features.id==i]['S2'].values)*dt\n",
    "    xf3 = np.fft.fft(train_features[train_features.id==i]['S3'].values)*dt\n",
    "    xf4 = np.fft.fft(train_features[train_features.id==i]['S4'].values)*dt\n",
    "    \n",
    "    signals.append(np.concatenate([np.abs(xf1[0:int(N/2+1)]), np.abs(xf2[0:int(N/2+1)]), np.abs(xf3[0:int(N/2+1)]), np.abs(xf4[0:int(N/2+1)])]))\n",
    "    ss['s1'] = np.abs(xf1[0:int(N/2+1)])\n",
    "    ss['s2'] = np.abs(xf2[0:int(N/2+1)])\n",
    "    ss['s3'] = np.abs(xf3[0:int(N/2+1)])\n",
    "    ss['s4'] = np.abs(xf4[0:int(N/2+1)])\n",
    "    \n",
    "signals = np.array(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.reshape((2800, 65, 4, 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [01:39<00:00, 28.14it/s]\n",
      "100%|██████████| 2800/2800 [00:02<00:00, 1192.59it/s]\n",
      "100%|██████████| 700/700 [00:25<00:00, 27.15it/s]\n",
      "100%|██████████| 700/700 [00:00<00:00, 1160.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# stats_train = get_stats_features(train_features)\n",
    "# rolling_train= get_rolling_features(train_features)\n",
    "# fre_train= get_frequency_features(train_features)\n",
    "mfcc_train = get_mfcc_features(train_features)\n",
    "# time_train = get_every_s2(train_features)\n",
    "time_train = get_arrival_time_features(train_features)\n",
    "\n",
    "# stats_test = get_stats_features(test_features)\n",
    "# rolling_test= get_rolling_features(test_features)\n",
    "# fre_test= get_frequency_features(test_features)\n",
    "mfcc_test = get_mfcc_features(test_features)\n",
    "# time_test = get_every_s2(test_features)\n",
    "time_test = get_arrival_time_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newc = [c for c in time_train.columns if len(c)==6]\n",
    "oldc = [c for c in time_train.columns if c not in newc]\n",
    "\n",
    "# time_test[newc] /= time_train[newc].max().abs()\n",
    "# time_train[newc] /= time_train[newc].max().abs()\n",
    "\n",
    "time_test[oldc] /= time_train[oldc].max().abs()\n",
    "time_train[oldc] /= time_train[oldc].max().abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summfcc2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summfcc0</th>\n",
       "      <th>summfcc1</th>\n",
       "      <th>summfcc3</th>\n",
       "      <th>summfcc4</th>\n",
       "      <th>summfcc5</th>\n",
       "      <th>summfcc6</th>\n",
       "      <th>summfcc7</th>\n",
       "      <th>summfcc8</th>\n",
       "      <th>summfcc9</th>\n",
       "      <th>summfcc10</th>\n",
       "      <th>...</th>\n",
       "      <th>summfcc22</th>\n",
       "      <th>summfcc23</th>\n",
       "      <th>summfcc24</th>\n",
       "      <th>summfcc25</th>\n",
       "      <th>summfcc26</th>\n",
       "      <th>summfcc27</th>\n",
       "      <th>summfcc28</th>\n",
       "      <th>summfcc29</th>\n",
       "      <th>summfcc30</th>\n",
       "      <th>summfcc31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412495</td>\n",
       "      <td>-0.185278</td>\n",
       "      <td>-0.105264</td>\n",
       "      <td>0.054041</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>-0.158039</td>\n",
       "      <td>-0.069546</td>\n",
       "      <td>0.165552</td>\n",
       "      <td>-0.093065</td>\n",
       "      <td>0.037431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>-0.013455</td>\n",
       "      <td>-0.009239</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>-0.030716</td>\n",
       "      <td>0.040807</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>-0.026201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.428403</td>\n",
       "      <td>-0.193016</td>\n",
       "      <td>0.112847</td>\n",
       "      <td>0.163353</td>\n",
       "      <td>0.128408</td>\n",
       "      <td>-0.134335</td>\n",
       "      <td>-0.012366</td>\n",
       "      <td>0.132453</td>\n",
       "      <td>-0.272094</td>\n",
       "      <td>0.048642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>-0.014744</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>-0.032641</td>\n",
       "      <td>0.062836</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>-0.046446</td>\n",
       "      <td>0.051808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420741</td>\n",
       "      <td>-0.301935</td>\n",
       "      <td>0.259475</td>\n",
       "      <td>0.189514</td>\n",
       "      <td>-0.116479</td>\n",
       "      <td>-0.040612</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>-0.174352</td>\n",
       "      <td>0.167865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>-0.026531</td>\n",
       "      <td>0.024633</td>\n",
       "      <td>0.027110</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>-0.056827</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.389785</td>\n",
       "      <td>-0.387673</td>\n",
       "      <td>0.194345</td>\n",
       "      <td>0.058999</td>\n",
       "      <td>-0.098376</td>\n",
       "      <td>-0.048043</td>\n",
       "      <td>0.065378</td>\n",
       "      <td>-0.062923</td>\n",
       "      <td>-0.126855</td>\n",
       "      <td>0.087885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.019212</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>-0.013621</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>-0.035715</td>\n",
       "      <td>0.032174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.441815</td>\n",
       "      <td>-0.112607</td>\n",
       "      <td>-0.106618</td>\n",
       "      <td>0.080004</td>\n",
       "      <td>0.066730</td>\n",
       "      <td>-0.194693</td>\n",
       "      <td>-0.149091</td>\n",
       "      <td>0.124902</td>\n",
       "      <td>-0.142856</td>\n",
       "      <td>-0.154909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>-0.008747</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>0.030447</td>\n",
       "      <td>0.037405</td>\n",
       "      <td>-0.014775</td>\n",
       "      <td>-0.002822</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>-0.080422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   summfcc0  summfcc1  summfcc3  summfcc4  summfcc5  summfcc6  summfcc7  \\\n",
       "0  0.412495 -0.185278 -0.105264  0.054041  0.047784 -0.158039 -0.069546   \n",
       "1  0.428403 -0.193016  0.112847  0.163353  0.128408 -0.134335 -0.012366   \n",
       "2  0.420741 -0.301935  0.259475  0.189514 -0.116479 -0.040612  0.036970   \n",
       "3  0.389785 -0.387673  0.194345  0.058999 -0.098376 -0.048043  0.065378   \n",
       "4  0.441815 -0.112607 -0.106618  0.080004  0.066730 -0.194693 -0.149091   \n",
       "\n",
       "   summfcc8  summfcc9  summfcc10  ...  summfcc22  summfcc23  summfcc24  \\\n",
       "0  0.165552 -0.093065   0.037431  ...   0.003289   0.004101  -0.013455   \n",
       "1  0.132453 -0.272094   0.048642  ...  -0.000653   0.001649  -0.014744   \n",
       "2  0.016508 -0.174352   0.167865  ...   0.009216   0.000094   0.001332   \n",
       "3 -0.062923 -0.126855   0.087885  ...   0.007122   0.001814  -0.000087   \n",
       "4  0.124902 -0.142856  -0.154909  ...   0.011096   0.002494  -0.008747   \n",
       "\n",
       "   summfcc25  summfcc26  summfcc27  summfcc28  summfcc29  summfcc30  summfcc31  \n",
       "0  -0.009239   0.011622   0.007005  -0.030716   0.040807   0.026494  -0.026201  \n",
       "1   0.012564   0.015587  -0.032641   0.062836   0.018460  -0.046446   0.051808  \n",
       "2  -0.026531   0.024633   0.027110   0.003344   0.027999  -0.056827   0.000971  \n",
       "3  -0.019212   0.035761  -0.013621  -0.009270   0.056205  -0.035715   0.032174  \n",
       "4  -0.002032   0.030447   0.037405  -0.014775  -0.002822   0.018688  -0.080422  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mfcc\n",
    "a = np.zeros_like(mfcc_train.values)\n",
    "for i in mfcc_train.index:\n",
    "    temp = mfcc_train.loc[i]\n",
    "    a[i] = temp /np.max(abs(temp))\n",
    "mfcc_train.iloc[:,:] = a\n",
    "\n",
    "b = np.zeros_like(mfcc_test.values)\n",
    "for i in mfcc_test.index:\n",
    "    temp = mfcc_test.loc[i]\n",
    "    b[i-mfcc_test.index[0]] = temp / np.max(np.abs(temp))\n",
    "mfcc_test.iloc[:,:] = b\n",
    "\n",
    "ctd = []\n",
    "for c in mfcc_train.columns:\n",
    "    if mfcc_train[c].std()==0 or mfcc_test[c].std()==0:\n",
    "        print(c)\n",
    "        ctd.append(c)\n",
    "mfcc_train = mfcc_train.drop(ctd, axis=1)\n",
    "mfcc_test = mfcc_test.drop(ctd, axis=1)\n",
    "mfcc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_feat = pd.concat([time_train, mfcc_train], axis=1)\n",
    "\n",
    "test_X_feat = pd.concat([time_test.reset_index().drop('index', axis=1),\n",
    "                    mfcc_test.reset_index().drop('index', axis=1),\n",
    "                   ], axis=1)\n",
    "\n",
    "train_X_feat = train_X_feat.T.drop_duplicates().T\n",
    "# ctd = [c for c in test_X.columns if c not in train_X.columns]\n",
    "test_X_feat = test_X_feat[train_X_feat.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_features.iloc[:,2:].values.reshape((2800,375,4,1))\n",
    "test_X = test_features.iloc[:,2:].values.reshape((700,375,4,1))\n",
    "train_y = train_target.iloc[:,1:].values\n",
    "\n",
    "# tr_X, te_X, tr_y, te_y = train_test_split(train_X, train_y, test_size=0.3, random_state=42)\n",
    "tr_X, te_X, tr_feat_X, te_feat_X, tr_y, te_y = train_test_split(train_X, train_X_feat, train_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 = np.array([1,1,0,0])\n",
    "weight2 = np.array([0,0,1,1])\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    divResult = Lambda(lambda x: x[0]/x[1])([(y_pred-y_true),(y_true+0.000001)])\n",
    "    return K.mean(K.square(divResult))\n",
    "\n",
    "\n",
    "def my_loss_E1(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true-y_pred)*weight1)/2e+04\n",
    "\n",
    "def my_loss_E2(y_true, y_pred):\n",
    "    divResult = Lambda(lambda x: x[0]/x[1])([(y_pred-y_true),(y_true+0.000001)])\n",
    "    return K.mean(K.square(divResult)*weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def set_model(train_target):  # 0:x,y, 1:m, 2:v\n",
    "    \n",
    "    activation = mish\n",
    "    padding = 'valid'\n",
    "    model = Sequential()\n",
    "    kernel_initializer = 'he_normal'\n",
    "    nf = 16\n",
    "    fs = (2,1)\n",
    "\n",
    "    model.add(Conv2D(nf,fs, padding=padding, activation=activation,input_shape=(375,4,1), kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "    model.add(Conv2D(nf*2,fs, padding=padding, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "    model.add(Conv2D(nf*4,fs, padding=padding, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "    model.add(Conv2D(nf*8,fs, padding=padding, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "    model.add(Conv2D(nf*16,fs, padding=padding, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "    model.add(Conv2D(nf*32,fs, padding=padding, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation =activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(Dense(64, activation =activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(Dense(32, activation =activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(Dense(16, activation =activation, kernel_initializer=kernel_initializer))\n",
    "    \n",
    "    model.add(Dense(4, kernel_initializer=kernel_initializer))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "\n",
    "    global weight2\n",
    "    if train_target == 1: # only for M\n",
    "        weight2 = np.array([0,0,1,0])\n",
    "    else: # only for V\n",
    "        weight2 = np.array([0,0,0,1])\n",
    "       \n",
    "    if train_target==0:\n",
    "        model.compile(loss=my_loss_E1,\n",
    "                  optimizer=optimizer,\n",
    "                 )\n",
    "    else:\n",
    "        model.compile(loss=my_loss_E2,\n",
    "                  optimizer=optimizer,\n",
    "                 )\n",
    "        \n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 374, 4, 16)        48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 374, 4, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 187, 4, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 186, 4, 32)        1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 186, 4, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 93, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 92, 4, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 92, 4, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 46, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 45, 4, 128)        16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 45, 4, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 22, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 4, 256)        65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 21, 4, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 4, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 9, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 1,413,892\n",
      "Trainable params: 1,411,876\n",
      "Non-trainable params: 2,016\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x28bb9ed7fc8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def build_model(train_target):\n",
    "    activation = tf.nn.swish\n",
    "    padding = 'valid'\n",
    "    model = Sequential()\n",
    "    kernel_initializer = 'he_normal'\n",
    "    nf = 16\n",
    "    fs1 = (2, 1)\n",
    "    \n",
    "    inputs = Input(shape=(375,4,1))\n",
    "    \n",
    "    sub_inputs = Input(shape = (59, ))\n",
    "    s = Dense(64, activation=activation, kernel_initializer=kernel_initializer)(sub_inputs)\n",
    "    \n",
    "    x = Conv2D(nf,fs1, padding=padding, activation=activation, kernel_initializer=kernel_initializer)(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    \n",
    "    for i in range(5):\n",
    "        x = Conv2D(nf*(2**(i+1)), fs1,  activation=activation, kernel_initializer=kernel_initializer, padding=padding)(x)\n",
    "        x = BatchNormalization(momentum=0.9)(x)\n",
    "        x = MaxPooling2D((2, 1))(x)\n",
    "        \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(128, activation=activation)(x)\n",
    "    x = Concatenate()([x, s])\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Dense(64, activation=activation)(x)\n",
    "    x = Dense(32, activation=activation)(x)\n",
    "    x = Dense(16, activation=activation)(x)\n",
    "    \n",
    "    outputs = Dense(4)(x)\n",
    "    \n",
    "    model = Model([inputs, sub_inputs], outputs)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam()\n",
    "\n",
    "    if train_target == 1: # only for M\n",
    "        weight2 = np.array([0,0,1,0])\n",
    "    else: # only for V\n",
    "        weight2 = np.array([0,0,0,1])\n",
    "       \n",
    "    if train_target==0:\n",
    "        model.compile(loss=my_loss_E1,\n",
    "                  optimizer=optimizer,\n",
    "                 )\n",
    "    else:\n",
    "        model.compile(loss=my_loss_E2,\n",
    "                  optimizer=optimizer,\n",
    "                 )\n",
    "        \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "build_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,X,Y):\n",
    "    MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "    if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "        os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "#     model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "#     best_save = keras.callbacks.ModelCheckpoint('best_m.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "    history = model.fit(X, Y,\n",
    "                  epochs=500,\n",
    "#                   batch_size=256,\n",
    "                  shuffle=True,\n",
    "                  validation_split=0.2,\n",
    "                  verbose = 2,\n",
    "                  callbacks=[es])\n",
    "\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    plt.show()    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(train_target):\n",
    "\n",
    "    if train_target == 0:\n",
    "        model = load_model('best_m.hdf5' , custom_objects={'my_loss_E1': my_loss, 'mish': mish, })\n",
    "    else:\n",
    "        model = load_model('best_m.hdf5' , custom_objects={'my_loss_E2': my_loss, 'mish': mish,})\n",
    "\n",
    "    score = model.evaluate(te_X, te_y, verbose=0)\n",
    "    print('loss:', score)\n",
    "\n",
    "    pred = model.predict(te_X)\n",
    "\n",
    "    i=0\n",
    "\n",
    "    print('정답(original):', te_y[i])\n",
    "    print('예측값(original):', pred[i])\n",
    "\n",
    "    print(E1(pred, te_y))\n",
    "    print(E2(pred, te_y))\n",
    "#     print(E2M(pred, te_y))\n",
    "#     print(E2V(pred, te_y))    \n",
    "    \n",
    "#     if train_target ==0:\n",
    "#         plot_error(4,pred,te_y)\n",
    "#     elif train_target ==1:\n",
    "#         plot_error(2,pred,te_y)\n",
    "#     elif train_target ==2:\n",
    "#         plot_error(3,pred,te_y)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 375, 4, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 374, 4, 16)   48          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 374, 4, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 187, 4, 16)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 186, 4, 32)   1056        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 186, 4, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 93, 4, 32)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 92, 4, 64)    4160        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 92, 4, 64)    256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 46, 4, 64)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 45, 4, 128)   16512       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 45, 4, 128)   512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 22, 4, 128)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 21, 4, 256)   65792       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 21, 4, 256)   1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 10, 4, 256)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 4, 512)    262656      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 4, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8192)         0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 59)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          1048704     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           3840        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192)          0           dense_8[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           12352       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           528         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4)            68          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,421,828\n",
      "Trainable params: 1,419,812\n",
      "Non-trainable params: 2,016\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1568 samples, validate on 392 samples\n",
      "Epoch 1/500\n",
      " - 4s - loss: 0.6746 - val_loss: 0.0462\n",
      "Epoch 2/500\n",
      " - 1s - loss: 0.0179 - val_loss: 0.0503\n",
      "Epoch 3/500\n",
      " - 1s - loss: 0.0069 - val_loss: 0.0195\n",
      "Epoch 4/500\n",
      " - 1s - loss: 0.0039 - val_loss: 0.0091\n",
      "Epoch 5/500\n",
      " - 1s - loss: 0.0023 - val_loss: 0.0084\n",
      "Epoch 6/500\n",
      " - 1s - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 7/500\n",
      " - 1s - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 8/500\n",
      " - 1s - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 9/500\n",
      " - 1s - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 10/500\n",
      " - 1s - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 11/500\n",
      " - 1s - loss: 0.0026 - val_loss: 0.0187\n",
      "Epoch 12/500\n",
      " - 1s - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 13/500\n",
      " - 1s - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 14/500\n",
      " - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 15/500\n",
      " - 1s - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 16/500\n",
      " - 1s - loss: 0.0024 - val_loss: 0.0150\n",
      "Epoch 17/500\n",
      " - 1s - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 18/500\n",
      " - 1s - loss: 0.0018 - val_loss: 0.0075\n",
      "Epoch 19/500\n",
      " - 1s - loss: 0.0018 - val_loss: 0.0100\n",
      "Epoch 20/500\n",
      " - 1s - loss: 0.0014 - val_loss: 0.0079\n",
      "Epoch 21/500\n",
      " - 1s - loss: 9.0819e-04 - val_loss: 0.0042\n",
      "Epoch 22/500\n",
      " - 1s - loss: 9.0300e-04 - val_loss: 0.0024\n",
      "Epoch 23/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 24/500\n",
      " - 1s - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 25/500\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 26/500\n",
      " - 1s - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 27/500\n",
      " - 1s - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 28/500\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 29/500\n",
      " - 1s - loss: 0.0010 - val_loss: 0.0058\n",
      "Epoch 30/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 31/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 32/500\n",
      " - 1s - loss: 9.6105e-04 - val_loss: 0.0129\n",
      "Epoch 33/500\n",
      " - 1s - loss: 8.5353e-04 - val_loss: 0.0041\n",
      "Epoch 34/500\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 35/500\n",
      " - 1s - loss: 8.1898e-04 - val_loss: 0.0018\n",
      "Epoch 36/500\n",
      " - 1s - loss: 8.1060e-04 - val_loss: 0.0023\n",
      "Epoch 37/500\n",
      " - 1s - loss: 9.1930e-04 - val_loss: 0.0051\n",
      "Epoch 38/500\n",
      " - 1s - loss: 8.6895e-04 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/500\n",
      " - 1s - loss: 7.3429e-04 - val_loss: 0.0061\n",
      "Epoch 40/500\n",
      " - 1s - loss: 7.1372e-04 - val_loss: 0.0054\n",
      "Epoch 41/500\n",
      " - 1s - loss: 6.8622e-04 - val_loss: 0.0021\n",
      "Epoch 42/500\n",
      " - 1s - loss: 9.1179e-04 - val_loss: 0.0013\n",
      "Epoch 43/500\n",
      " - 1s - loss: 8.7122e-04 - val_loss: 0.0016\n",
      "Epoch 44/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0120\n",
      "Epoch 45/500\n",
      " - 1s - loss: 0.0010 - val_loss: 0.0063\n",
      "Epoch 46/500\n",
      " - 1s - loss: 9.3542e-04 - val_loss: 0.0048\n",
      "Epoch 47/500\n",
      " - 1s - loss: 9.6841e-04 - val_loss: 0.0030\n",
      "Epoch 48/500\n",
      " - 1s - loss: 7.1333e-04 - val_loss: 0.0042\n",
      "Epoch 49/500\n",
      " - 1s - loss: 8.4043e-04 - val_loss: 0.0018\n",
      "Epoch 50/500\n",
      " - 1s - loss: 9.4928e-04 - val_loss: 0.0031\n",
      "Epoch 51/500\n",
      " - 1s - loss: 6.9937e-04 - val_loss: 0.0012\n",
      "Epoch 52/500\n",
      " - 1s - loss: 7.4012e-04 - val_loss: 0.0058\n",
      "Epoch 53/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 54/500\n",
      " - 1s - loss: 6.0149e-04 - val_loss: 0.0064\n",
      "Epoch 55/500\n",
      " - 1s - loss: 8.1195e-04 - val_loss: 0.0102\n",
      "Epoch 56/500\n",
      " - 1s - loss: 6.5236e-04 - val_loss: 0.0012\n",
      "Epoch 57/500\n",
      " - 1s - loss: 8.0649e-04 - val_loss: 0.0056\n",
      "Epoch 58/500\n",
      " - 1s - loss: 7.8762e-04 - val_loss: 0.0059\n",
      "Epoch 59/500\n",
      " - 1s - loss: 7.6052e-04 - val_loss: 0.0036\n",
      "Epoch 60/500\n",
      " - 1s - loss: 7.9944e-04 - val_loss: 0.0050\n",
      "Epoch 61/500\n",
      " - 1s - loss: 6.4633e-04 - val_loss: 0.0039\n",
      "Epoch 62/500\n",
      " - 1s - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 63/500\n",
      " - 1s - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 64/500\n",
      " - 1s - loss: 7.2919e-04 - val_loss: 0.0045\n",
      "Epoch 65/500\n",
      " - 1s - loss: 6.2296e-04 - val_loss: 0.0018\n",
      "Epoch 66/500\n",
      " - 1s - loss: 7.9937e-04 - val_loss: 0.0016\n",
      "Epoch 67/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 68/500\n",
      " - 1s - loss: 7.9127e-04 - val_loss: 0.0031\n",
      "Epoch 69/500\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 70/500\n",
      " - 1s - loss: 9.1281e-04 - val_loss: 0.0040\n",
      "Epoch 71/500\n",
      " - 1s - loss: 8.6169e-04 - val_loss: 0.0120\n",
      "Epoch 72/500\n",
      " - 1s - loss: 8.3841e-04 - val_loss: 0.0049\n",
      "Epoch 73/500\n",
      " - 1s - loss: 8.3911e-04 - val_loss: 0.0015\n",
      "Epoch 74/500\n",
      " - 1s - loss: 8.4317e-04 - val_loss: 0.0030\n",
      "Epoch 75/500\n",
      " - 1s - loss: 6.4336e-04 - val_loss: 0.0017\n",
      "Epoch 76/500\n",
      " - 1s - loss: 8.6810e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 375, 4, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 374, 4, 16)   48          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 374, 4, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 187, 4, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 186, 4, 32)   1056        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 186, 4, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 93, 4, 32)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 92, 4, 64)    4160        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 92, 4, 64)    256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 46, 4, 64)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 45, 4, 128)   16512       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 45, 4, 128)   512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 22, 4, 128)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 21, 4, 256)   65792       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 21, 4, 256)   1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 10, 4, 256)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 4, 512)    262656      max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 9, 4, 512)    2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 4, 4, 512)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8192)         0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 59)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          1048704     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           3840        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192)          0           dense_14[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           12352       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 32)           2080        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           528         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 4)            68          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,421,828\n",
      "Trainable params: 1,419,812\n",
      "Non-trainable params: 2,016\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1568 samples, validate on 392 samples\n",
      "Epoch 1/500\n",
      " - 2s - loss: 0.4211 - val_loss: 0.0190\n",
      "Epoch 2/500\n",
      " - 1s - loss: 0.0113 - val_loss: 0.0072\n",
      "Epoch 3/500\n",
      " - 1s - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 4/500\n",
      " - 1s - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 5/500\n",
      " - 1s - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 6/500\n",
      " - 1s - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 7/500\n",
      " - 1s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 8/500\n",
      " - 1s - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 9/500\n",
      " - 1s - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 10/500\n",
      " - 1s - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 11/500\n",
      " - 1s - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 12/500\n",
      " - 1s - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/500\n",
      " - 1s - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 14/500\n",
      " - 1s - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 15/500\n",
      " - 1s - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 16/500\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 17/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 18/500\n",
      " - 1s - loss: 0.0017 - val_loss: 7.2163e-04\n",
      "Epoch 19/500\n",
      " - 1s - loss: 9.1284e-04 - val_loss: 5.3886e-04\n",
      "Epoch 20/500\n",
      " - 1s - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 21/500\n",
      " - 1s - loss: 0.0017 - val_loss: 8.9088e-04\n",
      "Epoch 22/500\n",
      " - 1s - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 23/500\n",
      " - 1s - loss: 0.0023 - val_loss: 8.8937e-04\n",
      "Epoch 24/500\n",
      " - 1s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 25/500\n",
      " - 1s - loss: 0.0014 - val_loss: 5.9543e-04\n",
      "Epoch 26/500\n",
      " - 1s - loss: 8.0259e-04 - val_loss: 9.5181e-04\n",
      "Epoch 27/500\n",
      " - 1s - loss: 0.0010 - val_loss: 7.8039e-04\n",
      "Epoch 28/500\n",
      " - 1s - loss: 0.0010 - val_loss: 4.8054e-04\n",
      "Epoch 29/500\n",
      " - 1s - loss: 0.0015 - val_loss: 7.5946e-04\n",
      "Epoch 30/500\n",
      " - 1s - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 31/500\n",
      " - 1s - loss: 0.0024 - val_loss: 9.1805e-04\n",
      "Epoch 32/500\n",
      " - 1s - loss: 0.0012 - val_loss: 4.6177e-04\n",
      "Epoch 33/500\n",
      " - 1s - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 34/500\n",
      " - 1s - loss: 0.0016 - val_loss: 8.5975e-04\n",
      "Epoch 35/500\n",
      " - 1s - loss: 0.0011 - val_loss: 5.4465e-04\n",
      "Epoch 36/500\n",
      " - 1s - loss: 9.5732e-04 - val_loss: 4.1952e-04\n",
      "Epoch 37/500\n",
      " - 1s - loss: 6.4737e-04 - val_loss: 4.2195e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500\n",
      " - 1s - loss: 5.7218e-04 - val_loss: 7.5502e-04\n",
      "Epoch 39/500\n",
      " - 1s - loss: 0.0011 - val_loss: 4.3823e-04\n",
      "Epoch 40/500\n",
      " - 1s - loss: 7.2549e-04 - val_loss: 7.6754e-04\n",
      "Epoch 41/500\n",
      " - 1s - loss: 0.0015 - val_loss: 6.2463e-04\n",
      "Epoch 42/500\n",
      " - 1s - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 43/500\n",
      " - 1s - loss: 6.3221e-04 - val_loss: 5.4205e-04\n",
      "Epoch 44/500\n",
      " - 1s - loss: 0.0011 - val_loss: 7.2731e-04\n",
      "Epoch 45/500\n",
      " - 1s - loss: 7.5054e-04 - val_loss: 4.7384e-04\n",
      "Epoch 46/500\n",
      " - 1s - loss: 5.3006e-04 - val_loss: 5.0107e-04\n",
      "Epoch 47/500\n",
      " - 1s - loss: 5.2916e-04 - val_loss: 4.3316e-04\n",
      "Epoch 48/500\n",
      " - 1s - loss: 4.4085e-04 - val_loss: 0.0013\n",
      "Epoch 49/500\n",
      " - 1s - loss: 7.2591e-04 - val_loss: 7.8292e-04\n",
      "Epoch 50/500\n",
      " - 1s - loss: 5.6562e-04 - val_loss: 0.0012\n",
      "Epoch 51/500\n",
      " - 1s - loss: 6.0189e-04 - val_loss: 4.2273e-04\n",
      "Epoch 52/500\n",
      " - 1s - loss: 6.4002e-04 - val_loss: 4.9218e-04\n",
      "Epoch 53/500\n",
      " - 1s - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 54/500\n",
      " - 1s - loss: 5.8287e-04 - val_loss: 4.3271e-04\n",
      "Epoch 55/500\n",
      " - 1s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 56/500\n",
      " - 1s - loss: 8.6348e-04 - val_loss: 5.8631e-04\n",
      "Epoch 57/500\n",
      " - 1s - loss: 8.8688e-04 - val_loss: 0.0014\n",
      "Epoch 58/500\n",
      " - 1s - loss: 8.5932e-04 - val_loss: 3.4206e-04\n",
      "Epoch 59/500\n",
      " - 1s - loss: 9.0837e-04 - val_loss: 5.2311e-04\n",
      "Epoch 60/500\n",
      " - 1s - loss: 4.5610e-04 - val_loss: 7.4653e-04\n",
      "Epoch 61/500\n",
      " - 1s - loss: 4.3155e-04 - val_loss: 3.9336e-04\n",
      "Epoch 62/500\n",
      " - 1s - loss: 5.2171e-04 - val_loss: 3.3176e-04\n",
      "Epoch 63/500\n",
      " - 1s - loss: 7.3642e-04 - val_loss: 4.7912e-04\n",
      "Epoch 64/500\n",
      " - 1s - loss: 7.1350e-04 - val_loss: 5.0448e-04\n",
      "Epoch 65/500\n",
      " - 1s - loss: 6.8939e-04 - val_loss: 0.0010\n",
      "Epoch 66/500\n",
      " - 1s - loss: 8.1640e-04 - val_loss: 3.1983e-04\n",
      "Epoch 67/500\n",
      " - 1s - loss: 3.4183e-04 - val_loss: 2.1735e-04\n",
      "Epoch 68/500\n",
      " - 1s - loss: 4.1588e-04 - val_loss: 5.7039e-04\n",
      "Epoch 69/500\n",
      " - 1s - loss: 5.4888e-04 - val_loss: 7.9112e-04\n",
      "Epoch 70/500\n",
      " - 1s - loss: 4.9343e-04 - val_loss: 3.2796e-04\n",
      "Epoch 71/500\n",
      " - 1s - loss: 5.0645e-04 - val_loss: 3.4520e-04\n",
      "Epoch 72/500\n",
      " - 1s - loss: 5.7760e-04 - val_loss: 3.2283e-04\n",
      "Epoch 73/500\n",
      " - 1s - loss: 3.1696e-04 - val_loss: 2.3706e-04\n",
      "Epoch 74/500\n",
      " - 1s - loss: 9.4763e-04 - val_loss: 0.0013\n",
      "Epoch 75/500\n",
      " - 1s - loss: 5.9592e-04 - val_loss: 3.4518e-04\n",
      "Epoch 76/500\n",
      " - 1s - loss: 0.0015 - val_loss: 8.0369e-04\n",
      "Epoch 77/500\n",
      " - 1s - loss: 8.0773e-04 - val_loss: 5.8410e-04\n",
      "Epoch 78/500\n",
      " - 1s - loss: 5.5536e-04 - val_loss: 4.0475e-04\n",
      "Epoch 79/500\n",
      " - 1s - loss: 4.8295e-04 - val_loss: 3.9673e-04\n",
      "Epoch 80/500\n",
      " - 1s - loss: 6.2322e-04 - val_loss: 0.0012\n",
      "Epoch 81/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 82/500\n",
      " - 1s - loss: 0.0011 - val_loss: 7.8620e-04\n",
      "Epoch 83/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 84/500\n",
      " - 1s - loss: 7.2428e-04 - val_loss: 3.5691e-04\n",
      "Epoch 85/500\n",
      " - 1s - loss: 5.7107e-04 - val_loss: 2.5253e-04\n",
      "Epoch 86/500\n",
      " - 1s - loss: 3.3627e-04 - val_loss: 3.8399e-04\n",
      "Epoch 87/500\n",
      " - 1s - loss: 8.2544e-04 - val_loss: 4.3789e-04\n",
      "Epoch 88/500\n",
      " - 1s - loss: 6.2239e-04 - val_loss: 5.3654e-04\n",
      "Epoch 89/500\n",
      " - 1s - loss: 5.9990e-04 - val_loss: 2.8582e-04\n",
      "Epoch 90/500\n",
      " - 1s - loss: 3.3877e-04 - val_loss: 2.3696e-04\n",
      "Epoch 91/500\n",
      " - 1s - loss: 4.8594e-04 - val_loss: 5.4614e-04\n",
      "Epoch 92/500\n",
      " - 1s - loss: 3.4103e-04 - val_loss: 3.2227e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 375, 4, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 374, 4, 16)   48          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 374, 4, 16)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 187, 4, 16)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 186, 4, 32)   1056        max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 186, 4, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 93, 4, 32)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 92, 4, 64)    4160        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 92, 4, 64)    256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 46, 4, 64)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 45, 4, 128)   16512       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 45, 4, 128)   512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 22, 4, 128)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 21, 4, 256)   65792       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 21, 4, 256)   1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 10, 4, 256)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 9, 4, 512)    262656      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 9, 4, 512)    2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 4, 4, 512)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 8192)         0           max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 59)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 128)          1048704     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           3840        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 192)          0           dense_20[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           12352       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           2080        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 16)           528         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 4)            68          dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,421,828\n",
      "Trainable params: 1,419,812\n",
      "Non-trainable params: 2,016\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1568 samples, validate on 392 samples\n",
      "Epoch 1/500\n",
      " - 2s - loss: 0.1484 - val_loss: 0.0167\n",
      "Epoch 2/500\n",
      " - 1s - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 3/500\n",
      " - 1s - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 4/500\n",
      " - 1s - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 5/500\n",
      " - 1s - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 6/500\n",
      " - 1s - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 7/500\n",
      " - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 8/500\n",
      " - 1s - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 9/500\n",
      " - 1s - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 10/500\n",
      " - 1s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 11/500\n",
      " - 1s - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/500\n",
      " - 1s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 13/500\n",
      " - 1s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 14/500\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 15/500\n",
      " - 1s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/500\n",
      " - 1s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 17/500\n",
      " - 1s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/500\n",
      " - 1s - loss: 9.6026e-04 - val_loss: 0.0045\n",
      "Epoch 19/500\n",
      " - 1s - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 20/500\n",
      " - 1s - loss: 0.0014 - val_loss: 8.3709e-04\n",
      "Epoch 21/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/500\n",
      " - 1s - loss: 0.0011 - val_loss: 7.9257e-04\n",
      "Epoch 23/500\n",
      " - 1s - loss: 0.0012 - val_loss: 9.8847e-04\n",
      "Epoch 24/500\n",
      " - 1s - loss: 0.0012 - val_loss: 7.8278e-04\n",
      "Epoch 25/500\n",
      " - 1s - loss: 9.1321e-04 - val_loss: 7.5249e-04\n",
      "Epoch 26/500\n",
      " - 1s - loss: 7.1954e-04 - val_loss: 7.0839e-04\n",
      "Epoch 27/500\n",
      " - 1s - loss: 8.1365e-04 - val_loss: 7.1529e-04\n",
      "Epoch 28/500\n",
      " - 1s - loss: 0.0012 - val_loss: 6.8148e-04\n",
      "Epoch 29/500\n",
      " - 1s - loss: 7.8902e-04 - val_loss: 0.0012\n",
      "Epoch 30/500\n",
      " - 1s - loss: 4.7620e-04 - val_loss: 6.4126e-04\n",
      "Epoch 31/500\n",
      " - 1s - loss: 5.8478e-04 - val_loss: 5.6228e-04\n",
      "Epoch 32/500\n",
      " - 1s - loss: 8.2263e-04 - val_loss: 5.3867e-04\n",
      "Epoch 33/500\n",
      " - 1s - loss: 5.7814e-04 - val_loss: 9.3114e-04\n",
      "Epoch 34/500\n",
      " - 1s - loss: 5.5456e-04 - val_loss: 7.5827e-04\n",
      "Epoch 35/500\n",
      " - 1s - loss: 6.9431e-04 - val_loss: 7.7535e-04\n",
      "Epoch 36/500\n",
      " - 1s - loss: 5.7923e-04 - val_loss: 9.2676e-04\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0015 - val_loss: 8.0568e-04\n",
      "Epoch 38/500\n",
      " - 1s - loss: 0.0010 - val_loss: 4.7961e-04\n",
      "Epoch 39/500\n",
      " - 1s - loss: 0.0015 - val_loss: 7.0091e-04\n",
      "Epoch 40/500\n",
      " - 1s - loss: 0.0015 - val_loss: 7.7874e-04\n",
      "Epoch 41/500\n",
      " - 1s - loss: 5.5965e-04 - val_loss: 4.1648e-04\n",
      "Epoch 42/500\n",
      " - 1s - loss: 7.4714e-04 - val_loss: 5.9544e-04\n",
      "Epoch 43/500\n",
      " - 1s - loss: 4.3854e-04 - val_loss: 0.0012\n",
      "Epoch 44/500\n",
      " - 1s - loss: 6.9828e-04 - val_loss: 6.9840e-04\n",
      "Epoch 45/500\n",
      " - 1s - loss: 6.7763e-04 - val_loss: 6.6799e-04\n",
      "Epoch 46/500\n",
      " - 1s - loss: 5.2389e-04 - val_loss: 5.3478e-04\n",
      "Epoch 47/500\n",
      " - 1s - loss: 4.7004e-04 - val_loss: 5.6968e-04\n",
      "Epoch 48/500\n",
      " - 1s - loss: 3.9775e-04 - val_loss: 4.8891e-04\n",
      "Epoch 49/500\n",
      " - 1s - loss: 7.0287e-04 - val_loss: 8.0939e-04\n",
      "Epoch 50/500\n",
      " - 1s - loss: 4.9962e-04 - val_loss: 8.3037e-04\n",
      "Epoch 51/500\n",
      " - 1s - loss: 7.3488e-04 - val_loss: 3.8624e-04\n",
      "Epoch 52/500\n",
      " - 1s - loss: 9.9816e-04 - val_loss: 7.9134e-04\n",
      "Epoch 53/500\n",
      " - 1s - loss: 8.6109e-04 - val_loss: 4.9399e-04\n",
      "Epoch 54/500\n",
      " - 1s - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 55/500\n",
      " - 1s - loss: 8.1975e-04 - val_loss: 3.9625e-04\n",
      "Epoch 56/500\n",
      " - 1s - loss: 4.0046e-04 - val_loss: 3.5129e-04\n",
      "Epoch 57/500\n",
      " - 1s - loss: 6.3930e-04 - val_loss: 5.9488e-04\n",
      "Epoch 58/500\n",
      " - 1s - loss: 5.5485e-04 - val_loss: 4.7068e-04\n",
      "Epoch 59/500\n",
      " - 1s - loss: 4.5919e-04 - val_loss: 4.1839e-04\n",
      "Epoch 60/500\n",
      " - 1s - loss: 7.0921e-04 - val_loss: 0.0010\n",
      "Epoch 61/500\n",
      " - 1s - loss: 4.2812e-04 - val_loss: 3.3581e-04\n",
      "Epoch 62/500\n",
      " - 1s - loss: 5.6754e-04 - val_loss: 8.6750e-04\n",
      "Epoch 63/500\n",
      " - 1s - loss: 4.1827e-04 - val_loss: 4.2030e-04\n",
      "Epoch 64/500\n",
      " - 1s - loss: 5.1204e-04 - val_loss: 4.2597e-04\n",
      "Epoch 65/500\n",
      " - 1s - loss: 4.5770e-04 - val_loss: 5.5820e-04\n",
      "Epoch 66/500\n",
      " - 1s - loss: 5.3220e-04 - val_loss: 0.0021\n",
      "Epoch 67/500\n",
      " - 1s - loss: 7.5429e-04 - val_loss: 4.5081e-04\n",
      "Epoch 68/500\n",
      " - 1s - loss: 0.0010 - val_loss: 7.7099e-04\n",
      "Epoch 69/500\n",
      " - 1s - loss: 6.2578e-04 - val_loss: 3.5714e-04\n",
      "Epoch 70/500\n",
      " - 1s - loss: 3.9676e-04 - val_loss: 4.8761e-04\n",
      "Epoch 71/500\n",
      " - 1s - loss: 7.3413e-04 - val_loss: 4.1171e-04\n",
      "Epoch 72/500\n",
      " - 1s - loss: 6.7814e-04 - val_loss: 6.3856e-04\n",
      "Epoch 73/500\n",
      " - 1s - loss: 5.7994e-04 - val_loss: 3.7505e-04\n",
      "Epoch 74/500\n",
      " - 1s - loss: 8.2863e-04 - val_loss: 3.9565e-04\n",
      "Epoch 75/500\n",
      " - 1s - loss: 4.3447e-04 - val_loss: 2.5639e-04\n",
      "Epoch 76/500\n",
      " - 1s - loss: 2.8996e-04 - val_loss: 2.7678e-04\n",
      "Epoch 77/500\n",
      " - 1s - loss: 2.6339e-04 - val_loss: 4.3745e-04\n",
      "Epoch 78/500\n",
      " - 1s - loss: 3.1088e-04 - val_loss: 2.6614e-04\n",
      "Epoch 79/500\n",
      " - 1s - loss: 2.3888e-04 - val_loss: 2.5093e-04\n",
      "Epoch 80/500\n",
      " - 1s - loss: 2.2057e-04 - val_loss: 3.1302e-04\n",
      "Epoch 81/500\n",
      " - 1s - loss: 9.1103e-04 - val_loss: 0.0017\n",
      "Epoch 82/500\n",
      " - 1s - loss: 0.0013 - val_loss: 7.2603e-04\n",
      "Epoch 83/500\n",
      " - 1s - loss: 5.3289e-04 - val_loss: 3.2751e-04\n",
      "Epoch 84/500\n",
      " - 1s - loss: 4.0788e-04 - val_loss: 2.7747e-04\n",
      "Epoch 85/500\n",
      " - 1s - loss: 0.0011 - val_loss: 7.3636e-04\n",
      "Epoch 86/500\n",
      " - 1s - loss: 5.2687e-04 - val_loss: 4.9058e-04\n",
      "Epoch 87/500\n",
      " - 1s - loss: 4.4152e-04 - val_loss: 0.0013\n",
      "Epoch 88/500\n",
      " - 1s - loss: 6.5118e-04 - val_loss: 5.9682e-04\n",
      "Epoch 89/500\n",
      " - 1s - loss: 7.1875e-04 - val_loss: 5.3362e-04\n",
      "Epoch 90/500\n",
      " - 1s - loss: 4.1174e-04 - val_loss: 3.8977e-04\n",
      "Epoch 91/500\n",
      " - 1s - loss: 2.9917e-04 - val_loss: 3.1534e-04\n",
      "Epoch 92/500\n",
      " - 1s - loss: 4.7765e-04 - val_loss: 4.9703e-04\n",
      "Epoch 93/500\n",
      " - 1s - loss: 2.4704e-04 - val_loss: 1.6659e-04\n",
      "Epoch 94/500\n",
      " - 1s - loss: 2.7722e-04 - val_loss: 2.3533e-04\n",
      "Epoch 95/500\n",
      " - 1s - loss: 3.7591e-04 - val_loss: 1.7974e-04\n",
      "Epoch 96/500\n",
      " - 1s - loss: 2.3716e-04 - val_loss: 4.5168e-04\n",
      "Epoch 97/500\n",
      " - 1s - loss: 1.6057e-04 - val_loss: 1.4255e-04\n",
      "Epoch 98/500\n",
      " - 1s - loss: 1.9754e-04 - val_loss: 2.8125e-04\n",
      "Epoch 99/500\n",
      " - 1s - loss: 2.8637e-04 - val_loss: 3.1140e-04\n",
      "Epoch 100/500\n",
      " - 1s - loss: 5.4316e-04 - val_loss: 4.2838e-04\n",
      "Epoch 101/500\n",
      " - 1s - loss: 4.2418e-04 - val_loss: 2.0054e-04\n",
      "Epoch 102/500\n",
      " - 1s - loss: 2.6400e-04 - val_loss: 1.5837e-04\n",
      "Epoch 103/500\n",
      " - 1s - loss: 2.0788e-04 - val_loss: 1.9385e-04\n",
      "Epoch 104/500\n",
      " - 1s - loss: 2.2179e-04 - val_loss: 1.9937e-04\n",
      "Epoch 105/500\n",
      " - 1s - loss: 1.9449e-04 - val_loss: 1.3456e-04\n",
      "Epoch 106/500\n",
      " - 1s - loss: 1.2862e-04 - val_loss: 2.5109e-04\n",
      "Epoch 107/500\n",
      " - 1s - loss: 1.7876e-04 - val_loss: 5.1030e-04\n",
      "Epoch 108/500\n",
      " - 1s - loss: 1.7784e-04 - val_loss: 2.3806e-04\n",
      "Epoch 109/500\n",
      " - 1s - loss: 1.1257e-04 - val_loss: 1.2224e-04\n",
      "Epoch 110/500\n",
      " - 1s - loss: 4.9365e-04 - val_loss: 3.8887e-04\n",
      "Epoch 111/500\n",
      " - 1s - loss: 4.3071e-04 - val_loss: 2.7886e-04\n",
      "Epoch 112/500\n",
      " - 1s - loss: 3.8119e-04 - val_loss: 1.4454e-04\n",
      "Epoch 113/500\n",
      " - 1s - loss: 2.2115e-04 - val_loss: 1.6180e-04\n",
      "Epoch 114/500\n",
      " - 1s - loss: 2.7473e-04 - val_loss: 1.3714e-04\n",
      "Epoch 115/500\n",
      " - 1s - loss: 4.1223e-04 - val_loss: 2.6473e-04\n",
      "Epoch 116/500\n",
      " - 1s - loss: 2.5507e-04 - val_loss: 3.1887e-04\n",
      "Epoch 117/500\n",
      " - 1s - loss: 0.0012 - val_loss: 6.9243e-04\n",
      "Epoch 118/500\n",
      " - 1s - loss: 0.0011 - val_loss: 0.0634\n",
      "Epoch 119/500\n",
      " - 1s - loss: 3.6952 - val_loss: 0.2538\n",
      "Epoch 120/500\n",
      " - 1s - loss: 0.0667 - val_loss: 0.0241\n",
      "Epoch 121/500\n",
      " - 1s - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 122/500\n",
      " - 1s - loss: 0.0105 - val_loss: 0.0074\n",
      "Epoch 123/500\n",
      " - 1s - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 124/500\n",
      " - 1s - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 125/500\n",
      " - 1s - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 126/500\n",
      " - 1s - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 127/500\n",
      " - 1s - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 128/500\n",
      " - 1s - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 129/500\n",
      " - 1s - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 130/500\n",
      " - 1s - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 131/500\n",
      " - 1s - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 132/500\n",
      " - 1s - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 133/500\n",
      " - 1s - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 134/500\n",
      " - 1s - loss: 0.0036 - val_loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEKCAYAAADAVygjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5QcdZn/8fdnLsmQCwQSETZBE36iAiGZQMiGjUtQWExAE/jBahDkIkvW9Yp6WEBWRDi/o6KuLhrFuKJBkcsG0KxEWXHBwC6BhBhiQkACihmC5gIJuZOZeX5/VE3odHpmeqa7pmemP69z+kxX1bern6mk+5nv96n6liICMzOzLNRUOgAzM+u/nGTMzCwzTjJmZpYZJxkzM8uMk4yZmWXGScbMzDLjJGNmZki6RdJ6SSvb2S5JN0laI2mFpOOL2a+TjJmZAfwQmNbB9unAUeljNvCdYnbqJGNmZkTEIuDlDprMBG6NxGJgmKTDO9tvXbkC7Ck1NTVxwAEHVDoMM7M+ZceOHQEsy1k1NyLmdmEXI4G1OctN6bqXOnpRn0syBxxwANu3b690GGZmfYqknRExsZRdFFjX6bxkHi4zM7NiNAFH5CyPAtZ19iInGTMzK8YC4ML0LLPJwJaI6HCoDPrgcJmZmZWfpNuBU4ARkpqAzwP1ABFxM7AQOANYA+wALilqv31tqv/BgwdHfk1mz549NDU1sWvXrgpF1fc1NDQwatQo6uvrKx2KmWVA0o6IGNzT79svejJNTU0MHTqU0aNHIxWqTVlHIoJNmzbR1NTEmDFjKh2OmfUj/aIms2vXLoYPH+4E002SGD58uHuCZlZ2/SLJAE4wJfLxM7Ms9JskY2ZWbq2tr/HSSz+gr9WuexMnmTLYvHkz3/72t7v12jPOOIPNmzcX3f66667jq1/9arfey8y65pVXfs0zz3yIbduWVzqUPstJpgw6SjItLS0dvnbhwoUMGzYsi7DMrEStrbv3+Wld5yRTBldddRXPPfccjY2NXHHFFTz00EO8853v5AMf+ADHHXccAGeddRYnnHACxx57LHPnvj5d0OjRo9m4cSN//OMfOfroo7nssss49thjOf3009m5c2eH77t8+XImT57MuHHjOPvss3nllVcAuOmmmzjmmGMYN24cs2bNAuA3v/kNjY2NNDY2MmHCBLZu3ZrR0TDrT1ryflpX9YtTmHM9++zlZe/aDhnSyFFHfaPd7V/60pdYuXIly5cn7/vQQw/x+OOPs3Llyr2nBN9yyy0ccsgh7Ny5kxNPPJFzzjmH4cOH58X+LLfffjvf+973eN/73sfdd9/NBRdc0O77XnjhhXzzm99k6tSpXHvttXzhC1/gG9/4Bl/60pf4wx/+wMCBA/cOxX31q19lzpw5TJkyhW3bttHQ0FDqYTHr9yJa9vlpXeeeTEYmTZq0zzUnN910E+PHj2fy5MmsXbuWZ599dr/XjBkzhsbGRgBOOOEE/vjHP7a7/y1btrB582amTp0KwEUXXcSiRYsAGDduHOeffz4//vGPqatL/o6YMmUKn/70p7npppvYvHnz3vVm1j4nmdL1u2+ajnocPWnw4NcvrH3ooYd44IEHePTRRxk0aBCnnHJKwWtSBg4cuPd5bW1tp8Nl7bnvvvtYtGgRCxYs4IYbbmDVqlVcddVVnHnmmSxcuJDJkyfzwAMP8Pa3v71b+zerFk4ypXNPpgyGDh3aYY1jy5YtHHzwwQwaNIinn36axYsXl/yeBx10EAcffDAPP/wwAD/60Y+YOnUqra2trF27lne+853ceOONbN68mW3btvHcc89x3HHHceWVVzJx4kSefvrpkmMw6/9ckylVv+vJVMLw4cOZMmUKY8eOZfr06Zx55pn7bJ82bRo333wz48aN421vexuTJ08uy/vOmzePD3/4w+zYsYMjjzySH/zgB7S0tHDBBRewZcsWIoJPfepTDBs2jM997nM8+OCD1NbWcswxxzB9+vSyxGDWn7knU7rMJsiU1AAsAgaSJLP5EfH5vDYXA18BXkxXfSsi/r2j/RaaIHP16tUcffTRZYq8evk4mu1r3brv8fvfz2bs2AWMGPHeSodTkv44QeZu4F0RsU1SPfCIpF+k94bOdWdEfCzDOMzMuqkVcE+mFJklmUi6SNvSxfr04bkZzKzPeD25OMl0V6aFf0m1kpYD64FfRcRjBZqdI2mFpPmSjiiwHUmzJS2VtLS5uTnLkM3M9nJNpnSZJpmIaImIRpJ7QU+SNDavyX8CoyNiHPAAMK+d/cyNiIkRMdHXd5hZT3GSKV2PnMIcEZuBh4Bpees3RUTbpEDfA07oiXjMzIrjJFOqzJKMpDdIGpY+PwA4DXg6r83hOYszgNVZxWNm1lWuyZQuy7Gnw4F5kmpJktldEfFzSdcDSyNiAfAJSTOAZuBl4OIM4+lVhgwZwrZt24peb2Y9z8Nlpcvy7LIVwIQC66/NeX41cHVWMZiZlcJJpnSeVqYMrrzyyn3uJ3Pdddfxta99jW3btnHqqady/PHHc9xxx/Gzn/2s6H1GBFdccQVjx47luOOO48477wTgpZde4uSTT6axsZGxY8fy8MMP09LSwsUXX7y37de//vWy/45m1clJplT971Styy+H5WW+i11jI3yj/Yk3Z82axeWXX85HPvIRAO666y5++ctf0tDQwL333suBBx7Ixo0bmTx5MjNmzEBSp295zz33sHz5cp588kk2btzIiSeeyMknn8xPfvIT3v3ud3PNNdfQ0tLCjh07WL58OS+++CIrV64E6NKdNs2sfa7JlK7/JZkKmDBhAuvXr2fdunVs2LCBgw8+mDe96U3s2bOHz372syxatIiamhpefPFF/vKXv3DYYYd1us9HHnmE8847j9raWt74xjcydepUlixZwoknnsiHPvQh9uzZw1lnnUVjYyNHHnkkzz//PB//+Mc588wzOf3003vgtzbr/zxcVrr+l2Q66HFk6dxzz2X+/Pn8+c9/3ns3yttuu40NGzbwxBNPUF9fz+jRowtO8V9Ie3PKnXzyySxatIj77ruPD37wg1xxxRVceOGFPPnkk9x///3MmTOHu+66i1tuuaVsv5tZtXKSKZ1rMmUya9Ys7rjjDubPn8+5554LJFP8H3roodTX1/Pggw/ywgsvFL2/k08+mTvvvJOWlhY2bNjAokWLmDRpEi+88AKHHnool112GZdeeinLli1j48aNtLa2cs4553DDDTewbNmyrH5NsyrjJFOq/teTqZBjjz2WrVu3MnLkSA4/PLn85/zzz+e9730vEydOpLGxsUs3CTv77LN59NFHGT9+PJK48cYbOeyww5g3bx5f+cpXqK+vZ8iQIdx66628+OKLXHLJJbS2JpP5ffGLX8zkdzSrNq7JlC6zqf6z4qn+s+PjaLavZ5/9JC++eBNjxvw/3vzmz1Y6nJJUaqp/D5eZmbXDNZnSOcmYmbXLSaZU/SbJ9LVhv97Gx89sf67JlK5fJJmGhgY2bdrkL8puigg2bdpEQ0NDpUMx61U8XFa6fnF22ahRo2hqamLDhg2VDqXPamhoYNSoUZUOw6xXcZIpXb9IMvX19YwZM6bSYZhZv+MkU6p+MVxmZpYF12RK5yRjZtaO14fLmiscSc+QNE3SM5LWSLqqwPY3SXpQ0m8lrZB0Rmf7dJIxM2tHNdVk0htMzgGmA8cA50k6Jq/Zv5DcgHICMAv4Np1wkjEza1f1JBlgErAmIp6PiNeAO4CZeW0CODB9fhCwrrOdZpZkJDVIelzSk5JWSfpCgTYDJd2Zds0ekzQ6q3jMzLqqn/Vk6iQtzXnMzts+Elibs9yUrst1HXCBpCZgIfDxTt+0hIA7sxt4V0Rsk1QPPCLpFxGxOKfNpcArEfEWSbOALwPvzzAmM7Oi9bPCf3NETOxge6G7KeZffHge8MOI+Jqkk4AfSRobEa3t7TSznkwktqWL9ekjP+CZwLz0+XzgVBVz20gzsx7Qz3oynWkCjshZHsX+w2GXAncBRMSjQAMwoqOdZlqTkVQraTmwHvhVRDyW12Rv9yyS0ze2AMML7Gd2Wxevubk6zvIws96gqpLMEuAoSWMkDSAp7C/Ia/Mn4FQASUeTJJkOr4LPNMlEREtENJJkxEmSxuY1KaZ7RkTMjYiJETGxrq5fXD9qZn1A2yhQNSSZ9A/9jwH3A6tJziJbJel6STPSZp8BLpP0JHA7cHF0Mp9Xj3xjR8RmSQ8B04CVOZvaumdNkupIzlZ4uSdiMjPrTD+ryXQqIhaSFPRz112b8/wpYEpX9pnl2WVvkDQsfX4AcBrwdF6zBcBF6fNzgf/uLCuamfWcqhouy0SWPZnDgXnpBT41JF2vn0u6HlgaEQuA75OcnbCGpAczK8N4zMy6pMoK/5nILMlExApgQoH1uV2vXcDfZxWDmVkpnGRK5yv+zczaUW01mSw4yZiZtcs9mVI5yZiZtcPDZaVzkjEza4eTTOmcZMzM2uGaTOmcZMzM2uWeTKmcZMzM2uHhstI5yZiZtcNJpnROMmZm7XBNpnROMmZm7XJPplROMmZm7fBwWemcZMzM2uEkUzonGTOzdrgmUzonGTOzdrknUyonGTOzdni4rHROMmZm7XCSKZ2TjJlZO1yTKZ2TjJlZu9yTKVVmSUbSEZIelLRa0ipJnyzQ5hRJWyQtTx/XFtqXmVlPi2jNee4k0111Ge67GfhMRCyTNBR4QtKvIuKpvHYPR8R7MozDzKzLchOLk0z3ZdaTiYiXImJZ+nwrsBoYmdX7mZmV076JxUmmu3qkJiNpNDABeKzA5pMkPSnpF5KObef1syUtlbS0ubk5w0jNzNq4J1MOWQ6XASBpCHA3cHlEvJq3eRnw5ojYJukM4KfAUfn7iIi5wFyAwYMHR8Yhm5ntTSxSvZNMCTLtyUiqJ0kwt0XEPfnbI+LViNiWPl8I1EsakWVMZmbFeD3JDHCSKUGWZ5cJ+D6wOiL+tZ02h6XtkDQpjWdTVjGZmRWrLbHU1AzANZnuy3K4bArwQeB3kpan6z4LvAkgIm4GzgX+SVIzsBOYFREeDjOzXiA5hVkaACSnNEu+tLCrMksyEfEIoE7afAv4VlYxmJl11749mWTZSabrfMTMzArIrcnkLlvXOMmYmRW0b0/GdZnucZIxMyvAPZnycJIxMyugUE3Gus5JxsysgGrsyUiaJukZSWskXdVOm/dJeiqd+Pgnne0z8yv+zcz6pvyeTP+e0kpSLTAH+DugCVgiaUHupMaSjgKuBqZExCuSDu1sv+7JmJkVkN+TqYLC/yRgTUQ8HxGvAXcAM/PaXAbMiYhXACJifWc7dZIxMyugH9Zk6tomGk4fs/O2jwTW5iw3sf/M+W8F3irpfyQtljSt0zctLWYzs/6pH9ZkmiNiYgfbC108nz8DSx3JJManAKOAhyWNjYjN7e3UPRkzs4L6XU+mM03AETnLo4B1Bdr8LCL2RMQfgGcoMHN+LicZM7MCqrAmswQ4StIYJb/0LGBBXpufAu8ESGfMfyvwfEc7dZIxMyvg9ZpM/T7L/VUkp899DLif5E7Gd0XEKknXS5qRNrsf2CTpKeBB4IqI6HDmfNdkzMwK6Ic1mU6l9/VamLfu2pznAXw6fRTFPRkzs4LaejIDgepIMllwkjEzK6AKazKZcJIxMyugH14nUxFOMmZmBVRjTSYLTjJmZgW5J1MOmSUZSUdIelDS6nS2zk8WaCNJN6Uzfq6QdHxW8ZiZdYVrMuWR5SnMzcBnImKZpKHAE5J+lTujJzCd5GrRo4C/Br6T/jQzqyjXZMojs55MRLwUEcvS51tJLu7Jn2xtJnBrJBYDwyQdnlVMZmbFck2mPHqkJiNpNDABeCxvUzGzfiJpdtvMoc3N/fueDmbWW7gnUw6ZJxlJQ4C7gcsj4tX8zQVekj/rJxExNyImRsTEujpPUmBm2XNNpjyKSjKSPinpwLRQ/31JyySdXsTr6kkSzG0RcU+BJsXM+mlm1uNckymPYnsyH0p7IacDbwAuAb7U0QskCfg+sDoi/rWdZguAC9PkNRnYEhEvFRmTmVlmXJMpj2LHntqGtc4AfhART6ZJpCNTgA8Cv5O0PF33WeBNABFxM8lEbGcAa4AdJMnLzKwXcE+mHIpNMk9I+i9gDHB1ekpya0cviIhHKFxzyW0TwEeLjMHMrMe4JlMexSaZS4FG4PmI2CHpENzrMLN+zDWZ8ii2JnMS8ExEbJZ0AfAvwJbswjIzq7RksMY1mdIUm2S+A+yQNB74Z+AF4NbMojIzqzD3ZMqj2CTTnNZPZgL/FhH/BgzNLiwzs8pyTaY8iq3JbJV0NcnZYn8rqRaozy4sM7PKck+mPIrtybwf2E1yvcyfSaZ++UpmUZmZVZyvkymHopJMmlhuAw6S9B5gV0S4JmNm/ZZ7MuVR7LQy7wMeB/4eeB/wmKRzswzMzKySXq/JtFUVnGS6o9iazDXAiRGxHkDSG4AHgPlZBWZmVklJkqklKUG7J9NdxdZkatoSTGpTF15rZtYHtaQJxkmmFMX2ZH4p6X7g9nT5/STzjpmZ9UsRSZJxT6Y0RSWZiLhC0jkkk14KmBsR92YamZlZBSVJpWZvknFNpnuKvgNYRNxNcm8YM7N+zz2Z8ugwyUjaSoE7VZL0ZiIiDswkKjOzimurySTlZyeZ7ukwyUSEp44xs6r0ek9GQI2TTDf5DDEzswLaTmEG0h6Nk0x3OMmYmRXQ1pOBJMm4J9M9TjJmZgW15JxZ5iTTXZklGUm3SFovaWU720+RtEXS8vRxbVaxmJl1lXsy5VH0Kczd8EPgW3R8c7OHI+I9GcZgZtYtrsmUR2Y9mYhYBLyc1f7NzLLknkx5VLomc5KkJyX9QtKx7TWSNFvSUklLm5ubezI+M6ta+TWZ/v/dI2mapGckrZF0VQftzpUUkiZ2ts9KJpllwJsjYjzwTeCn7TWMiLkRMTEiJtbVZTnCZ2aWqLaeTHrH4znAdOAY4DxJxxRoNxT4BPBYMfutWJKJiFcjYlv6fCFQL2lEpeIxM8uVX5Pp70kGmASsiYjnI+I14A5gZoF2NwA3AruK2WnFkoykw5RcSoukSWksmyoVj5lZrvyeTD8o/Ne1lR3Sx+y87SOBtTnLTem6vSRNAI6IiJ8X/abdDrcTkm4HTgFGSGoCPg/UA0TEzcC5wD9JagZ2ArMiotA8aWZmFdDvrpNpjoiOaigqsG7vd7KkGuDrwMVdedPMkkxEnNfJ9m+RnOJsZtbrVFtNhqTnckTO8ihgXc7yUGAs8FA6CHUYsEDSjIhY2t5OK312mZlZr1SFNZklwFGSxkgaAMwCFrRtjIgtETEiIkZHxGhgMdBhggEnGTOzgvphTaZDkZyj/THgfmA1cFdErJJ0vaQZ3d2vzwc2MyuoBak+fV4VPZm2M30X5q0rOOVXRJxSzD7dkzEzKyCitdpqMplwkjEzK6AKazKZcJIxMyuoumoyWXGSMTMrILfwXy01mSw4yZiZFVCF18lkwknGzKwA12TKw0nGzKygFpKZVFyTKYWTjJlZAa7JlIeTjJlZAR4uKw8nGTOzAlz4Lw8nGTOzgnydTDk4yZiZFeCaTHk4yZiZFeCaTHk4yZiZFbBvTabOSaabMksykm6RtF7Syna2S9JNktZIWiHp+KxiMTPrOtdkyiHLnswPgWkdbJ8OHJU+ZgPfyTAWM7Mu8dll5ZFZkomIRcDLHTSZCdwaicXAMEmHZxWPmVlX5NZkXPjvvkrWZEYCa3OWm9J1+5E0W9JSSUubm5t7JDgzq27uyZRHJZOMCqyLQg0jYm5ETIyIiXV1vmO0mfUE12TKoZJJpgk4Imd5FLCuQrGYme3DPZnyqGSSWQBcmJ5lNhnYEhEvVTAeMzMAIoJkYMU1mVJlNvYk6XbgFGCEpCbg80A9QETcDCwEzgDWADuAS7KKxcysK9oSinsypcssyUTEeZ1sD+CjWb2/mVn37Z9kXJPpHl/xb2aWxz2Z8nGSMTPL83pCcU2mVE4yZmZ5CvVkoDU9IcC6wknGzGw/hZIMQGuF4um7nGTMzPIU7sngIbNucJIxM8tTqCaz73orlpOMmVke92TKx0nGzGw/Se1l/5qMk0xXOcmYmeV5vceSfEW6J9N9TjJmZnnyh8tck+k+Jxkzs/24JlMuTjJmZnnaL/z375smSpom6RlJayRdVWD7pyU9JWmFpF9LenNn+3SSMTPLk38KczUU/pX8knOA6cAxwHmSjslr9ltgYkSMA+YDN3a2XycZM7M8VVqTmQSsiYjnI+I14A5gZm6DiHgwInaki4tJbjbZIScZM7P99MuaTJ2kpTmP2XnbRwJrc5ab0nXtuRT4Radv2vU4zcz6t356MWZzREzsYLsKrCs4I6ikC4CJwNTO3tRJxswsTzXWZEh6LkfkLI8C1uU3knQacA0wNSJ2d7ZTD5eZmeWp0prMEuAoSWMkDQBmAQtyG0iaAHwXmBER64vZaaZJpojT4S6WtEHS8vTxD1nGY2ZWnH45XNahSM7P/hhwP7AauCsiVkm6XtKMtNlXgCHAf6Tf2Qva2d1emQ2X5ZwO93ck3bAlkhZExFN5Te+MiI9lFYeZWVf105pMpyJiIbAwb921Oc9P6+o+s+zJdHo6nJlZb1SlNZlMZJlkij0d7pz06tH5ko4osB1Js9tOu2tu7t9X3JpZ5VVpTSYTWSaZYk6H+09gdHr16APAvEI7ioi5ETExIibW1fmEODPLWnUOl2UhyyTT6elwEbEp5xS47wEnZBiPmVlRqrUmk4Usk0wxp8MdnrM4g+SMBjOzinJNpnwyG3uKiGZJbafD1QK3tJ0OByyNiAXAJ9JT45qBl4GLs4rHzKxYrsmUT6YFjiJOh7sauDrLGMzMus7DZeXiK/7NzPK4JlM+TjJmZnlckykfJxkzszyuyZSPk4yZ2X48XFYuTjJmZnlckykfJxkzszyuyZSPk4yZWZ69PZnWgIULIWr2WW/Fc5IxM9tPkkxq7rkPzjyT2sW/BZxkusNJxswsz96ezP8+DkDN8tX7rLfiOcmYmeVpSyY1jy5Jfq5om1bRSaarnGTMzPbTSs1OYMXvANCKVYB7Mt3hJGNmlieihQOfAbW0wNix6Knfo2Ynme6omiTz8su/YsmS8ezZs6nSoZhZLxfRwoEr04V//Ef02msM+pOTTHdUTZKpqxvG9u0r2LTp55UOxcx6uYgWDnwK4u1vh3e9C4Aha8A1ma6rmiQzdOhEBg4cxYYN91Y6FDPr7aKZg1aBTjoJ3vpWoqGBIWvck+mOqkkykhgx4mxeeeV+Wlq2VzocM+vF6v6wgfpXgb/5G6irg7HHMuQ5J5nuqJokAzBixP+ltXUXL7/8y0qHYma92MAn1iZPTjop+Tl+fNKTaW2uXFB9VFUlmYMOegd1dcPZsOGeSodiZr1VBEN+too9BwJHH52sa5xA/auw5ak7aWnZUdHw+ppMk4ykaZKekbRG0lUFtg+UdGe6/TFJo7OMp6amjhEjZrJp089pbX0ty7cys77qu99l0P/+iRf+YSDUJF+RmjABgJoVq3j66UuIiEpG2Kcoq4OlZNrS3wN/BzQBS4DzIuKpnDYfAcZFxIclzQLOjoj3d7TfwYMHx/bt3aip/M//wA03sGtUHU0D72PQuBkcMPZ06kYdjQYNQQcMQTX1SPXUpD+luvRn27razt+nO5qbYft2GDQI6uuzeQ8z69xzz8H48WxvPITffvFV3vG3m5P1W7fC8OG0DGtg3dSttL7jr2kYcTS1g95A7Ws1aHfA8OHwV4ehoQdTUzMAaSA1tQ3U1AwEpX/PS8nPGkHdAFRXB3X1qH7A3u+f1x+1QBCv7YadO2DHdmgYRM0hI7r1q0naERGDSz9IXVOX4b4nAWsi4nkASXcAM4GnctrMBK5Ln88HviVJkUXm274dNm5k4OI1vGULwIL08bqWAdA6gH36d5E+WnPahUBon+W9lLsA5C3mLoegZndQv/X1X7e1DloPEC0DRdTnv7iLinp5ie9RTr0olM5oT1CzO1ALRC1ErYhaoFZtE/amDfd9XbT9/+jB31Vl+jR1tBv1xF/2XX6LrsdUt7UVBL+7vBXV5HwfDx0KCxdSM2cOo372n2j+Y8BjXd5/R6ImfdRCa5JfqN0NNTlfPq/842QOvvnRsr5v1rJMMiOBtTnLTcBft9cmIpolbQGGAxtzG0maDcwGGDBgQPeiOf10OP305MPw8ss0P/1bXnvqYVrXr4NdO2HHTti1C+3anZxBEq1AEK0tBK3pcisRra+fYRJtKSiS53uXU/n/xyP2Wxf1NbQc0kDroHq0u5maHc3U7GxGO/eg5lI+uPlx7L+v2D/Adp73gL40+hDJv1sMrCXqalBLQEsragm0J+cboe2LN/2x98s+8v5tOkw4UeBZ5/bbZf4fP93W/n6SP76699qi37dbuyj+RbsFW855K8PGHs7QoSfuu/G009Bpp8GWLfD887Rs2UTL9r/Q2lBDa72IjevRupdg53ZaYw/RuodobSZa9ySvz/l3V2sL0dKKmluIlhbU3JyMaDQ3Ey3N0LwHIoiGeuKAAcnPhnrqJ0/rzgGoqCyTTKF/2fzPSTFtiIi5wFxIhstKi0owfDh1U06jbsppJe3KzPqfgzptcBBMmEAtbbc0s45kWfhvAo7IWR4FrGuvjaQ6kn/flzOMyczMelCWSWYJcJSkMZIGALPIL4Ikyxelz88F/juTeoyZmVVEZsNlaY3lY8D9JL3KWyJilaTrgaURsQD4PvAjSWtIejCzsorHzMx6XmanMGel26cwm5lVsUqdwlxVV/ybmVnPcpIxMzMgm1lanGTMzKxtlpY5wHTgGOA8ScfkNbsUeCUi3gJ8HfhyZ/t1kjEzM8iZpSUiXgPaZmnJNROYlz6fD5wqdXylb5YXY2Zix44dIWlnN19eB/TFubodd8/qi3H3xZjBcfekAyQtzVmem17o3qZss7Tk6nNJJiK63fuStDQiJpYznp7guHtWX4y7L8YMjruXKdssLbk8XGZmZpDRLC1OMmZmBhnN0tLnhstKNLfzJr2S4+5ZfTHuvhgzOO5eI6tZWvrcFf9mZtZ3eLjMzMwy4yRjZmaZqZok09l0CXozEKgAAAV8SURBVL2FpCMkPShptaRVkj6Zrj9E0q8kPZv+PLjSseaTVCvpt5J+ni6PSaeeeDadiqKbtzXNjqRhkuZLejo95if1kWP9qfT/x0pJt0tq6I3HW9ItktZLWpmzruDxVeKm9DO6QtLxvSzur6T/T1ZIulfSsJxtV6dxPyPp3ZWJuneqiiRT5HQJvUUz8JmIOBqYDHw0jfUq4NcRcRTw63S5t/kksDpn+cvA19OYXyGZkqK3+TfglxHxdmA8Sfy9+lhLGgl8ApgYEWNJirSz6J3H+4dA/j2D2zu+04Gj0sds4Ds9FGMhP2T/uH8FjI2IccDvgasB0s/nLODY9DXfTr9zjCpJMhQ3XUKvEBEvRcSy9PlWki+9kew7ncM84KzKRFiYpFHAmcC/p8sC3kUy9QT0zpgPBE4mOWOGiHgtIjbTy491qo7kCu46YBDwEr3weEfEIva/jqK94zsTuDUSi4Fhkg7vmUj3VSjuiPiviGi7yn8xyXUkkMR9R0Tsjog/AGtIvnOM6kkyhaZLGFmhWIqWznA6AXgMeGNEvARJIgIOrVxkBX0D+GegNV0eDmzO+VD2xmN+JLAB+EE6zPfvkgbTy491RLwIfBX4E0ly2QI8Qe8/3m3aO7596XP6IeAX6fO+FHePq5Yk0+WpECpN0hDgbuDyiHi10vF0RNJ7gPUR8UTu6gJNe9sxrwOOB74TEROA7fSyobFC0hrGTGAM8FfAYJKhpny97Xh3pi/8n0HSNSTD2re1rSrQrNfFXSnVkmSKmS6h15BUT5JgbouIe9LVf2kbOkh/rq9UfAVMAWZI+iPJUOS7SHo2w9LhHOidx7wJaIqIx9Ll+SRJpzcfa4DTgD9ExIaI2APcA/wNvf94t2nv+Pb6z6mki4D3AOfnXOne6+OupGpJMsVMl9ArpLWM7wOrI+JfczblTudwEfCzno6tPRFxdUSMiojRJMf2vyPifOBBkqknoJfFDBARfwbWSnpbuupU4Cl68bFO/QmYLGlQ+v+lLe5efbxztHd8FwAXpmeZTQa2tA2r9QaSpgFXAjMiYkfOpgXALCU39BpDcuLC45WIsVeKiKp4AGeQnBHyHHBNpePpIM53kHS1VwDL08cZJDWOXwPPpj8PqXSs7cR/CvDz9PmRJB+2NcB/AAMrHV+BeBuBpenx/ilwcF841sAXgKeBlcCPgIG98XgDt5PUjfaQ/MV/aXvHl2TYaU76Gf0dydlzvSnuNSS1l7bP5c057a9J434GmF7p496bHp5WxszMMlMtw2VmZlYBTjJmZpYZJxkzM8uMk4yZmWXGScbMzDLjJGPWgySd0jZLtVk1cJIxM7PMOMmYFSDpAkmPS1ou6bvpvXK2SfqapGWSfi3pDWnbRkmLc+4z0nZ/lLdIekDSk+lr/k+6+yE597C5Lb1q36xfcpIxyyPpaOD9wJSIaARagPNJJqJcFhHHA78BPp++5FbgykjuM/K7nPW3AXMiYjzJ3GJtU6RMAC4nubfRkSRzv5n1S3WdNzGrOqcCJwBL0k7GASSTOLYCd6ZtfgzcI+kgYFhE/CZdPw/4D0lDgZERcS9AROwCSPf3eEQ0pcvLgdHAI9n/WmY9z0nGbH8C5kXE1fuslD6X166jOZk6GgLbnfO8BX8OrR/zcJnZ/n4NnCvpUNh7T/o3k3xe2mY5/gDwSERsAV6R9Lfp+g8Cv4nkHkBNks5K9zFQ0qAe/S3MegH/BWWWJyKekvQvwH9JqiGZifejJDc1O1bSEyR3o3x/+pKLgJvTJPI8cEm6/oPAdyVdn+7j73vw1zDrFTwLs1mRJG2LiCGVjsOsL/FwmZmZZcY9GTMzy4x7MmZmlhknGTMzy4yTjJmZZcZJxszMMuMkY2Zmmfn//1ztUsjVw2AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44671040312704746\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "te_ys = pd.DataFrame(np.zeros_like(te_y), columns=['X', 'Y', 'M', 'V'])\n",
    "\n",
    "models = [None for _ in range(3)]\n",
    "for train_target in range(3):\n",
    "#     model = set_model(train_target)\n",
    "    model = build_model(train_target)\n",
    "    models[train_target] = train(model,[tr_X, tr_feat_X], tr_y)    \n",
    "#     best_model = load_best_model(train_target)\n",
    "\n",
    "    pred_data_test = models[train_target].predict([test_X, test_X_feat])\n",
    "    val_pred =  models[train_target].predict([te_X, te_feat_X])\n",
    "\n",
    "    \n",
    "    if train_target == 0: # x,y 학습\n",
    "        sub.iloc[:,1] = pred_data_test[:,0]\n",
    "        sub.iloc[:,2] = pred_data_test[:,1]\n",
    "        te_ys.iloc[:,0] = val_pred[:,0]\n",
    "        te_ys.iloc[:,1] = val_pred[:,1]\n",
    "\n",
    "    elif train_target == 1: # m 학습\n",
    "        sub.iloc[:,3] = np.clip(pred_data_test[:,2], 0, 1)\n",
    "        te_ys.iloc[:,2] = val_pred[:,2]\n",
    "\n",
    "    elif train_target == 2: # v 학습\n",
    "        sub.iloc[:,4] = np.clip(pred_data_test[:,3], 0, 1)\n",
    "        te_ys.iloc[:,3] = val_pred[:,3]\n",
    "        \n",
    "val_score = kaeri_metric(te_y, te_ys)\n",
    "print(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model/{round(val_score, 5)}'\n",
    "os.mkdir(model_path)\n",
    "for i in range(3):\n",
    "    models[i].save(model_path+f'/model_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./sub/cnn_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
