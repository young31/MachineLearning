{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Data processing, metrics and modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# Lgbm\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# Suppr warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "from scipy import interp\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import pystacknet\n",
    "from functools import partial\n",
    "from utils import reduce_mem_usage\n",
    "\n",
    "# from mem import reduce_mem_usage\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed cols: ['TransactionID', 'TransactionDT', 'DT', 'DT_W', 'DT_D', 'DT_day_week', 'DT_day_month', 'DT_M_total', 'DT_W_total', 'DT_D_total', 'uid', 'uid2', 'uid3', 'uid4', 'uid5', 'bank_type']\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset and feature selection\n",
    "\n",
    "f = open('train_ori.bin', 'rb')\n",
    "train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('test_ori.bin', 'rb')\n",
    "test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "ctd = pd.read_pickle('remove_features.pkl')\n",
    "\n",
    "cols_to_drop = []\n",
    "for f in ctd.values:\n",
    "    cols_to_drop.append(list(f)[0])\n",
    "    \n",
    "# cols_to_drop.remove('DT_M')\n",
    "# cols_to_drop.remove('DT_hour')\n",
    "cols_to_drop.remove('isFraud')\n",
    "\n",
    "print('removed cols:', cols_to_drop)\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col='TransactionID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('imp_col.bin', 'rb')\n",
    "imp_cols = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[imp_cols]\n",
    "imp_cols.remove('isFraud')\n",
    "test = test[imp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use only for initial feature selection\n",
    "# for f in train.columns:\n",
    "#     if sum(pd.isna(train[f]))/len(train) > 0.9:\n",
    "#         train = train.drop(f, axis=1)\n",
    "#         test = test.drop(f, axis=1)\n",
    "#         print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 646)\n",
      "(506691, 645)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide variable type\n",
    "\n",
    "numerical = [\"TransactionAmt\", \"nulls1\", \"dist1\", \"dist2\"] + [\"C\" + str(i) for i in range(1, 15)] + \\\n",
    "            [\"D\" + str(i) for i in range(1, 16)] + \\\n",
    "            [\"V\" + str(i) for i in range(1, 340)] + [\"id_0\" + str(i) for i in range(1, 10)] + [\"id_\" + str(i) for i in range(10, 12)]\n",
    "\n",
    "categorical = [\"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n",
    "               \"P_emaildomain_bin\", \"P_emaildomain_suffix\", \"R_emaildomain_bin\", \"R_emaildomain_suffix\",\n",
    "               \"P_emaildomain\", \"R_emaildomain\",\n",
    "              \"DeviceInfo\", \"DeviceType\"] + \\\n",
    "                [\"id_\" + str(i) for i in range(12, 39)] + \\\n",
    "                 [\"M\" + str(i) for i in range(1, 10)] +['Transaction_day_of_week', 'Transaction_hour_of_day', 'DT', 'DT_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negativedownsampling(train, ratio) :\n",
    "    \n",
    "\n",
    "    # Number of data points in the minority class\n",
    "    number_records_fraud = len(train[train.isFraud == 1])\n",
    "    fraud_indices = np.array(train[train.isFraud == 1].index)\n",
    "\n",
    "    # Picking the indices of the normal classes\n",
    "    normal_indices = train[train.isFraud == 0].index\n",
    "\n",
    "    # Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\n",
    "    random_normal_indices = np.random.choice(normal_indices, number_records_fraud*ratio, replace = False)\n",
    "    random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "    # Appending the 2 indices\n",
    "    under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "    # Under sample dataset\n",
    "    under_sample_data = train.iloc[under_sample_indices,:]\n",
    "    \n",
    "    # Showing ratio\n",
    "    print(\"Percentage of normal transactions: \", round(len(under_sample_data[under_sample_data.isFraud == 0])/len(under_sample_data),2)* 100,\"%\")\n",
    "    print(\"Percentage of fraud transactions: \", round(len(under_sample_data[under_sample_data.isFraud == 1])/len(under_sample_data),2)* 100,\"%\")\n",
    "    print(\"Total number of transactions in resampled data: \", len(under_sample_data))\n",
    "    \n",
    "    return under_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to downsampling or upsampling\n",
    "## see details in utils.py\n",
    "train = Negativedownsampling(train, 9)\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes-opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_LGB = {\n",
    "    'num_leaves': (300, 1000), \n",
    "    'min_data_in_leaf': (0, 150),\n",
    "    'bagging_fraction' : (0.3, 0.7),\n",
    "    'feature_fraction' : (0.6, 0.9),\n",
    "#     'learning_rate': (0.01, 0.3),\n",
    "    'min_child_weight': (0.001, 3),   \n",
    "    'reg_alpha': (0.25, 0.7), \n",
    "    'reg_lambda': (0.25, 0.7),\n",
    "    'max_depth':(10, 30),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    #learning_rate,\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    feature_fraction,\n",
    "    min_child_weight, \n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda\n",
    "     ):\n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'feature_fraction' : feature_fraction,\n",
    "#               'learning_rate' : 0.03,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'objective': 'binary',\n",
    "              'save_binary': True,\n",
    "              'seed': 12,\n",
    "              'feature_fraction_seed': 12,\n",
    "              'bagging_seed': 12,\n",
    "              'drop_seed': 12,\n",
    "              'data_random_seed': 12,\n",
    "              'boosting_type': 'gdbt', ## some get better result using 'dart'\n",
    "              'verbose': 1,\n",
    "              'is_unbalance': False,\n",
    "              'boost_from_average': True,\n",
    "              'metric':'auc'}    \n",
    "    \n",
    "    oof = np.zeros(len(train))\n",
    "    trn_data= lgb.Dataset(train.iloc[bayesian_tr_idx][features].values, label=train.iloc[bayesian_tr_idx][target].values)\n",
    "    val_data= lgb.Dataset(train.iloc[bayesian_val_idx][features].values, label=train.iloc[bayesian_val_idx][target].values)\n",
    "    \n",
    "    ## set clf options\n",
    "    clf = lgb.train(param, trn_data,  num_boost_round=150, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 50)\n",
    "    \n",
    "    oof[bayesian_val_idx]  = clf.predict(train.iloc[bayesian_val_idx][features].values, num_iteration=clf.best_iteration) \n",
    "    \n",
    "    score = roc_auc_score(train.iloc[bayesian_val_idx][target].values, oof[bayesian_val_idx])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=12)\n",
    "features = list(train.columns)\n",
    "features.remove('isFraud')\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut tr and val\n",
    "bayesian_tr_idx, bayesian_val_idx = train_test_split(train, test_size = 0.3, random_state = 19, stratify = train[target])\n",
    "bayesian_tr_idx = bayesian_tr_idx.index\n",
    "bayesian_val_idx = bayesian_val_idx.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_points = 10\n",
    "n_iter = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_da... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 0.3617  \u001b[0m | \u001b[0m 0.822   \u001b[0m | \u001b[0m 15.27   \u001b[0m | \u001b[0m 1.602   \u001b[0m | \u001b[0m 2.186   \u001b[0m | \u001b[0m 759.4   \u001b[0m | \u001b[0m 0.6553  \u001b[0m | \u001b[0m 0.265   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9611  \u001b[0m | \u001b[0m 0.6828  \u001b[0m | \u001b[0m 0.6412  \u001b[0m | \u001b[0m 15.68   \u001b[0m | \u001b[0m 1.819   \u001b[0m | \u001b[0m 141.6   \u001b[0m | \u001b[0m 726.4   \u001b[0m | \u001b[0m 0.251   \u001b[0m | \u001b[0m 0.4846  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9574  \u001b[0m | \u001b[0m 0.5208  \u001b[0m | \u001b[0m 0.7456  \u001b[0m | \u001b[0m 25.36   \u001b[0m | \u001b[0m 0.483   \u001b[0m | \u001b[0m 114.7   \u001b[0m | \u001b[0m 310.4   \u001b[0m | \u001b[0m 0.3108  \u001b[0m | \u001b[0m 0.3023  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9645  \u001b[0m | \u001b[0m 0.424   \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 19.42   \u001b[0m | \u001b[0m 2.449   \u001b[0m | \u001b[0m 43.44   \u001b[0m | \u001b[0m 666.6   \u001b[0m | \u001b[0m 0.5662  \u001b[0m | \u001b[0m 0.3974  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9628  \u001b[0m | \u001b[0m 0.4339  \u001b[0m | \u001b[0m 0.8934  \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 2.851   \u001b[0m | \u001b[0m 115.1   \u001b[0m | \u001b[0m 712.5   \u001b[0m | \u001b[0m 0.433   \u001b[0m | \u001b[0m 0.4531  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9616  \u001b[0m | \u001b[0m 0.4603  \u001b[0m | \u001b[0m 0.8985  \u001b[0m | \u001b[0m 13.55   \u001b[0m | \u001b[0m 2.888   \u001b[0m | \u001b[0m 62.89   \u001b[0m | \u001b[0m 512.0   \u001b[0m | \u001b[0m 0.4584  \u001b[0m | \u001b[0m 0.4182  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9529  \u001b[0m | \u001b[0m 0.4862  \u001b[0m | \u001b[0m 0.6106  \u001b[0m | \u001b[0m 11.69   \u001b[0m | \u001b[0m 2.198   \u001b[0m | \u001b[0m 95.43   \u001b[0m | \u001b[0m 314.0   \u001b[0m | \u001b[0m 0.3851  \u001b[0m | \u001b[0m 0.3494  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9653  \u001b[0m | \u001b[0m 0.322   \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 18.33   \u001b[0m | \u001b[0m 0.1456  \u001b[0m | \u001b[0m 85.86   \u001b[0m | \u001b[0m 701.8   \u001b[0m | \u001b[0m 0.3011  \u001b[0m | \u001b[0m 0.3747  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.961   \u001b[0m | \u001b[0m 0.5567  \u001b[0m | \u001b[0m 0.7478  \u001b[0m | \u001b[0m 20.13   \u001b[0m | \u001b[0m 1.385   \u001b[0m | \u001b[0m 134.2   \u001b[0m | \u001b[0m 602.9   \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.4497  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9642  \u001b[0m | \u001b[0m 0.492   \u001b[0m | \u001b[0m 0.8665  \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 11.02   \u001b[0m | \u001b[0m 597.6   \u001b[0m | \u001b[0m 0.264   \u001b[0m | \u001b[0m 0.5494  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9659  \u001b[0m | \u001b[0m 0.6249  \u001b[0m | \u001b[0m 0.7971  \u001b[0m | \u001b[0m 29.55   \u001b[0m | \u001b[0m 2.056   \u001b[0m | \u001b[0m 1.796   \u001b[0m | \u001b[0m 797.8   \u001b[0m | \u001b[0m 0.5552  \u001b[0m | \u001b[0m 0.6029  \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.9676  \u001b[0m | \u001b[95m 0.6209  \u001b[0m | \u001b[95m 0.8161  \u001b[0m | \u001b[95m 26.31   \u001b[0m | \u001b[95m 1.149   \u001b[0m | \u001b[95m 1.553   \u001b[0m | \u001b[95m 799.9   \u001b[0m | \u001b[95m 0.2759  \u001b[0m | \u001b[95m 0.5599  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9659  \u001b[0m | \u001b[0m 0.3374  \u001b[0m | \u001b[0m 0.8069  \u001b[0m | \u001b[0m 27.73   \u001b[0m | \u001b[0m 1.336   \u001b[0m | \u001b[0m 1.206   \u001b[0m | \u001b[0m 799.3   \u001b[0m | \u001b[0m 0.629   \u001b[0m | \u001b[0m 0.4583  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9589  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 0.7368  \u001b[0m | \u001b[0m 11.25   \u001b[0m | \u001b[0m 1.611   \u001b[0m | \u001b[0m 1.348   \u001b[0m | \u001b[0m 797.9   \u001b[0m | \u001b[0m 0.3923  \u001b[0m | \u001b[0m 0.5924  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9622  \u001b[0m | \u001b[0m 0.3267  \u001b[0m | \u001b[0m 0.6297  \u001b[0m | \u001b[0m 29.98   \u001b[0m | \u001b[0m 0.2705  \u001b[0m | \u001b[0m 0.7226  \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 0.2785  \u001b[0m | \u001b[0m 0.3221  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9653  \u001b[0m | \u001b[0m 0.4941  \u001b[0m | \u001b[0m 0.8317  \u001b[0m | \u001b[0m 29.8    \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 7.118   \u001b[0m | \u001b[0m 644.4   \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 0.3347  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.965   \u001b[0m | \u001b[0m 0.645   \u001b[0m | \u001b[0m 0.6527  \u001b[0m | \u001b[0m 29.95   \u001b[0m | \u001b[0m 0.1541  \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 666.2   \u001b[0m | \u001b[0m 0.472   \u001b[0m | \u001b[0m 0.4495  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9654  \u001b[0m | \u001b[0m 0.6077  \u001b[0m | \u001b[0m 0.6393  \u001b[0m | \u001b[0m 29.89   \u001b[0m | \u001b[0m 2.698   \u001b[0m | \u001b[0m 0.3531  \u001b[0m | \u001b[0m 666.2   \u001b[0m | \u001b[0m 0.4177  \u001b[0m | \u001b[0m 0.2735  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9651  \u001b[0m | \u001b[0m 0.595   \u001b[0m | \u001b[0m 0.7774  \u001b[0m | \u001b[0m 29.94   \u001b[0m | \u001b[0m 2.894   \u001b[0m | \u001b[0m 1.059   \u001b[0m | \u001b[0m 791.7   \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.6692  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9658  \u001b[0m | \u001b[0m 0.4539  \u001b[0m | \u001b[0m 0.6571  \u001b[0m | \u001b[0m 29.99   \u001b[0m | \u001b[0m 0.01953 \u001b[0m | \u001b[0m 3.313   \u001b[0m | \u001b[0m 702.3   \u001b[0m | \u001b[0m 0.4338  \u001b[0m | \u001b[0m 0.6259  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9659  \u001b[0m | \u001b[0m 0.67    \u001b[0m | \u001b[0m 0.7171  \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 0.07862 \u001b[0m | \u001b[0m 0.5879  \u001b[0m | \u001b[0m 733.4   \u001b[0m | \u001b[0m 0.5365  \u001b[0m | \u001b[0m 0.5063  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9647  \u001b[0m | \u001b[0m 0.384   \u001b[0m | \u001b[0m 0.8576  \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 2.959   \u001b[0m | \u001b[0m 0.0963  \u001b[0m | \u001b[0m 733.4   \u001b[0m | \u001b[0m 0.6303  \u001b[0m | \u001b[0m 0.3446  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 0.3619  \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 29.58   \u001b[0m | \u001b[0m 0.03507 \u001b[0m | \u001b[0m 0.1387  \u001b[0m | \u001b[0m 793.2   \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 0.6249  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 0.5363  \u001b[0m | \u001b[0m 0.8784  \u001b[0m | \u001b[0m 29.97   \u001b[0m | \u001b[0m 0.03447 \u001b[0m | \u001b[0m 4.005   \u001b[0m | \u001b[0m 676.2   \u001b[0m | \u001b[0m 0.4851  \u001b[0m | \u001b[0m 0.6782  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9658  \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.8374  \u001b[0m | \u001b[0m 29.55   \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.1378  \u001b[0m | \u001b[0m 689.5   \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 0.3155  \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('-' * 120)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676037042273492"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\n",
    "        'min_data_in_leaf': int(LGB_BO.max['params']['min_data_in_leaf']), \n",
    "        'num_leaves': int(LGB_BO.max['params']['num_leaves']), \n",
    "        #'learning_rate': LGB_BO.max['params']['learning_rate'],\n",
    "        'min_child_weight': LGB_BO.max['params']['min_child_weight'],\n",
    "        'bagging_fraction': LGB_BO.max['params']['bagging_fraction'], \n",
    "        'feature_fraction': LGB_BO.max['params']['feature_fraction'],\n",
    "        'reg_lambda': LGB_BO.max['params']['reg_lambda'],\n",
    "        'reg_alpha': LGB_BO.max['params']['reg_alpha'],\n",
    "        'max_depth': int(LGB_BO.max['params']['max_depth']), \n",
    "        'objective': 'binary',\n",
    "        'save_binary': True,\n",
    "        'seed': 12,\n",
    "        'feature_fraction_seed': 12,\n",
    "        'bagging_seed': 12,\n",
    "        'drop_seed': 12,\n",
    "        'data_random_seed': 12,\n",
    "        'boosting_type': 'gdbt',  # also consider 'dart'\n",
    "        'verbose': 1,\n",
    "        'is_unbalance': False,\n",
    "        'boost_from_average': True,\n",
    "        'metric':'auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold 1\n",
      "[100]\ttraining's auc: 0.993784\tvalid_1's auc: 0.957035\n",
      "[200]\ttraining's auc: 0.999987\tvalid_1's auc: 0.9706\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.973165\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.973642\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.974178\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.974052\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.973806\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.973646\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.97386\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.973901\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.974071\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.974307\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.97418\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.974127\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.974116\n",
      "\n",
      "fold 2\n",
      "[100]\ttraining's auc: 0.993243\tvalid_1's auc: 0.961109\n",
      "[200]\ttraining's auc: 0.999984\tvalid_1's auc: 0.974157\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.976579\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.976618\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.977061\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.977399\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.977499\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.977263\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.977184\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.977229\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.977234\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.977191\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.977281\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.977189\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.977097\n",
      "\n",
      "fold 3\n",
      "[100]\ttraining's auc: 0.993638\tvalid_1's auc: 0.958233\n",
      "[200]\ttraining's auc: 0.999981\tvalid_1's auc: 0.971041\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.973456\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.973776\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.974463\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.974689\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.974946\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.974526\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.974635\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.974521\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.974566\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.974346\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.974345\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.974285\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.974361\n",
      "\n",
      "fold 4\n",
      "[100]\ttraining's auc: 0.993195\tvalid_1's auc: 0.957254\n",
      "[200]\ttraining's auc: 0.999984\tvalid_1's auc: 0.973415\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.975709\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.976338\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.976563\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.976423\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.976811\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.976782\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.976951\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.976802\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.976909\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.976842\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.976882\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.97679\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.976642\n",
      "\n",
      "CV roc score        : 0.9756, std: 0.0013. \n",
      "CV accuracy score   : 0.9891, std: 0.0004. \n",
      "CV recall score     : 0.7074, std: 0.0084. \n",
      "CV precision score  : 0.9730, std: 0.0046. \n",
      "CV f1 score         : 0.8192, std: 0.0067.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "nfold = 4\n",
    "skf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "cms= []\n",
    "tprs = []\n",
    "aucs = []\n",
    "y_real = []\n",
    "y_proba = []\n",
    "recalls = []\n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "predictions = np.zeros(len(test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "n_estimator = 0\n",
    "\n",
    "\n",
    "bayes = np.zeros(len(train))\n",
    "\n",
    "i = 1\n",
    "for train_idx, valid_idx in skf.split(train, train.isFraud.values):\n",
    "    print(\"\\nfold {}\".format(i))\n",
    "    trn_data = lgb.Dataset(train.iloc[train_idx][features].values,\n",
    "                                   label=train.iloc[train_idx][target].values\n",
    "                                   )\n",
    "    val_data = lgb.Dataset(train.iloc[valid_idx][features].values,\n",
    "                                   label=train.iloc[valid_idx][target].values\n",
    "                                   )   \n",
    "    ## clf setting\n",
    "    clf = lgb.train(param_lgb, trn_data, num_boost_round = 150, valid_sets = [trn_data, val_data], verbose_eval = 100, early_stopping_rounds = 100)\n",
    "    oof[valid_idx] = clf.predict(train.iloc[valid_idx][features].values) \n",
    "    \n",
    "    predictions += clf.predict(test[features]) / nfold\n",
    "    bayes += clf.predict(train[features]) / nfold\n",
    "    \n",
    "    # Scores \n",
    "    roc_aucs.append(roc_auc_score(train.iloc[valid_idx][target].values, oof[valid_idx]))\n",
    "    accuracies.append(accuracy_score(train.iloc[valid_idx][target].values, oof[valid_idx].round()))\n",
    "    recalls.append(recall_score(train.iloc[valid_idx][target].values, oof[valid_idx].round()))\n",
    "    precisions.append(precision_score(train.iloc[valid_idx][target].values ,oof[valid_idx].round()))\n",
    "    f1_scores.append(f1_score(train.iloc[valid_idx][target].values, oof[valid_idx].round()))\n",
    "    \n",
    "    # Roc curve by folds\n",
    "    f = plt.figure(1)\n",
    "    fpr, tpr, t = roc_curve(train.iloc[valid_idx][target].values, oof[valid_idx])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (i,roc_auc))\n",
    "    \n",
    "    # Precion recall by folds\n",
    "    g = plt.figure(2)\n",
    "    precision, recall, _ = precision_recall_curve(train.iloc[valid_idx][target].values, oof[valid_idx])\n",
    "    y_real.append(train.iloc[valid_idx][target].values)\n",
    "    y_proba.append(oof[valid_idx])\n",
    "    plt.plot(recall, precision, lw=2, alpha=0.3, label='P|R fold %d' % (i))  \n",
    "    \n",
    "    i= i+1\n",
    "    \n",
    "    # Confusion matrix by folds\n",
    "    cms.append(confusion_matrix(train.iloc[valid_idx][target].values, oof[valid_idx].round()))\n",
    "    \n",
    "    # Features imp\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = nfold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "# Metrics\n",
    "print(\n",
    "        '\\nCV roc score        : {0:.4f}, std: {1:.4f}.'.format(np.mean(roc_aucs), np.std(roc_aucs)),\n",
    "        '\\nCV accuracy score   : {0:.4f}, std: {1:.4f}.'.format(np.mean(accuracies), np.std(accuracies)),\n",
    "        '\\nCV recall score     : {0:.4f}, std: {1:.4f}.'.format(np.mean(recalls), np.std(recalls)),\n",
    "        '\\nCV precision score  : {0:.4f}, std: {1:.4f}.'.format(np.mean(precisions), np.std(precisions)),\n",
    "        '\\nCV f1 score         : {0:.4f}, std: {1:.4f}.'.format(np.mean(f1_scores), np.std(f1_scores))\n",
    ")\n",
    "\n",
    "### below is for visualization\n",
    "# #ROC \n",
    "# f = plt.figure(1)\n",
    "# plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'grey')\n",
    "# mean_tpr = np.mean(tprs, axis=0)\n",
    "# mean_auc = auc(mean_fpr, mean_tpr)\n",
    "# plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "#          label=r'Mean ROC (AUC = %0.4f)' % (np.mean(roc_aucs)),lw=2, alpha=1)\n",
    "\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('LGB ROC curve by folds')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "# # PR plt\n",
    "# g = plt.figure(2)\n",
    "# plt.plot([0,1],[1,0],linestyle = '--',lw = 2,color = 'grey')\n",
    "# y_real = np.concatenate(y_real)\n",
    "# y_proba = np.concatenate(y_proba)\n",
    "# precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
    "# plt.plot(recall, precision, color='blue',\n",
    "#          label=r'Mean P|R')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('P|R curve by folds')\n",
    "# plt.legend(loc=\"lower left\")\n",
    "\n",
    "# # Confusion maxtrix & metrics\n",
    "# plt.rcParams[\"axes.grid\"] = False\n",
    "# cm = np.average(cms, axis=0)\n",
    "# class_names = [0,1]\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm, \n",
    "#                       classes=class_names, \n",
    "#                       title= 'LGB Confusion matrix [averaged/folds]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['isFraud'] = predictions\n",
    "sample_submission.to_csv('preds/bayes_lgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['isFraud'].copy()\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 645)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.6208557761807184,\n",
       " 'bagging_seed': 12,\n",
       " 'boost_from_average': True,\n",
       " 'boosting_type': 'dart',\n",
       " 'data_random_seed': 12,\n",
       " 'drop_seed': 12,\n",
       " 'feature_fraction': 0.8161334733057637,\n",
       " 'feature_fraction_seed': 12,\n",
       " 'is_unbalance': False,\n",
       " 'max_depth': 26,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 1.1487246317328306,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'num_leaves': 799,\n",
       " 'objective': 'binary',\n",
       " 'reg_alpha': 0.2759381261875936,\n",
       " 'reg_lambda': 0.5598769107896939,\n",
       " 'save_binary': True,\n",
       " 'seed': 12,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=5)\n"
     ]
    }
   ],
   "source": [
    "## for fold options - KFold or GroupKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit,KFold, GroupKFold\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold,shuffle=True)\n",
    "# folds = GroupKFold(n_splits=n_fold)\n",
    "# split_gruops = train['DT_M']\n",
    "\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "finish train\n",
      "finish pred\n",
      "ROC accuracy: 0.9070130465760226\n",
      "1\n",
      "finish train\n",
      "finish pred\n",
      "ROC accuracy: 0.9447442576724936\n",
      "2\n",
      "finish train\n",
      "finish pred\n",
      "ROC accuracy: 0.9430777885480857\n",
      "3\n",
      "finish train\n",
      "finish pred\n",
      "ROC accuracy: 0.9389094823261478\n",
      "4\n",
      "finish train\n",
      "finish pred\n",
      "ROC accuracy: 0.9509038568646326\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "lgb_submission=sample_submission.copy()\n",
    "lgb_submission['isFraud'] = 0\n",
    "lgb_tr = np.zeros(len(train))\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n",
    "#    replace for groupkfold: folds.split(X_train, y_train, groups=split_gruops)\n",
    "    print(fold_n)\n",
    "    \n",
    "    X_train_, X_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    y_train_, y_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    lgbclf = lgb.LGBMClassifier(\n",
    "                        **params,\n",
    "                        n_estimators=500\n",
    "    )\n",
    "    \n",
    "    X_train_, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    lgbclf.fit(X_train_,y_train_)\n",
    "    \n",
    "    del X_train_,y_train_\n",
    "    print('finish train')\n",
    "    pred=lgbclf.predict_proba(X_test)[:,1]\n",
    "    lgb_tr += lgbclf.predict_proba(X_train)[:,1]/n_fold\n",
    "    val=lgbclf.predict_proba(X_valid)[:,1]\n",
    "    print('finish pred')  \n",
    "    if n_fold != 3:\n",
    "        del lgbclf\n",
    "    del X_valid\n",
    "    print('ROC accuracy: {}'.format(roc_auc_score(y_valid, val)))\n",
    "    del val,y_valid\n",
    "    lgb_submission['isFraud'] = lgb_submission['isFraud']+pred/n_fold\n",
    "    del pred\n",
    "    gc.collect()\n",
    "    \n",
    "lgb_submission.to_csv('preds/lgb_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('params.bin', 'rb')\n",
    "params = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.6208557761807184,\n",
       " 'bagging_seed': 12,\n",
       " 'boost_from_average': True,\n",
       " 'boosting_type': 'dart',\n",
       " 'data_random_seed': 12,\n",
       " 'drop_seed': 12,\n",
       " 'feature_fraction': 0.8161334733057637,\n",
       " 'feature_fraction_seed': 12,\n",
       " 'is_unbalance': False,\n",
       " 'max_depth': 26,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 1.1487246317328306,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'num_leaves': 799,\n",
       " 'objective': 'binary',\n",
       " 'reg_alpha': 0.2759381261875936,\n",
       " 'reg_lambda': 0.5598769107896939,\n",
       " 'save_binary': True,\n",
       " 'seed': 12,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_fx = {'min_data_in_leaf': params['min_data_in_leaf'],\n",
    " 'num_leaves': params['num_leaves'],\n",
    " 'min_child_weight': params['min_child_weight'],\n",
    " 'bagging_fraction': params['bagging_fraction'],\n",
    " 'feature_fraction': params['feature_fraction'],\n",
    " 'reg_lambda': params['reg_lambda'],\n",
    " 'reg_alpha': params['reg_alpha'],\n",
    " 'max_depth': params['max_depth'],\n",
    "\n",
    "}\n",
    "\n",
    "col = []\n",
    "for f in train.columns:\n",
    "    if f in categorical:\n",
    "        \n",
    "            train[f] = train[f].replace(\"nan\", \"other\")\n",
    "            train[f] = train[f].replace(np.nan, \"other\")\n",
    "            test[f] = test[f].replace(\"nan\", \"other\")\n",
    "            test[f] = test[f].replace(np.nan, \"other\")\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "            train[f] = lbl.transform(list(train[f].values))\n",
    "            test[f] = lbl.transform(list(test[f].values))\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "            train[f] = lbl.transform(list(train[f].values))\n",
    "            test[f] = lbl.transform(list(test[f].values)) \n",
    "            col.append(f)\n",
    "            \n",
    "y_train = train['isFraud'].copy()\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.6208557761807184,\n",
       " 'feature_fraction': 0.8161334733057637,\n",
       " 'max_depth': 26,\n",
       " 'min_child_weight': 1.1487246317328306,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'num_leaves': 799,\n",
       " 'reg_alpha': 0.2759381261875936,\n",
       " 'reg_lambda': 0.5598769107896939}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fx['max_depth'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ROC accuracy: 0.9052945832066803\n",
      "1\n",
      "ROC accuracy: 0.941635351643685\n",
      "2\n",
      "ROC accuracy: 0.9381577110140165\n",
      "3\n",
      "ROC accuracy: 0.9364709408817641\n",
      "4\n",
      "ROC accuracy: 0.9470379147664763\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "xgb_submission=sample_submission.copy()\n",
    "\n",
    "xgb_submission['isFraud'] = 0\n",
    "xgb_tr = np.zeros(len(train))\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# folds.split(X_train)\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train, y_train, groups=split_gruops)):\n",
    "    print(fold_n)\n",
    "    xgbclf = xgb.XGBClassifier(\n",
    "            **params_fx,\n",
    "#             n_estimators=500,\n",
    "            tree_method = 'hist'\n",
    "    )\n",
    "    \n",
    "    X_train_, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    xgbclf.fit(X_train_,y_train_)\n",
    "    del X_train_,y_train_\n",
    "    pred=xgbclf.predict_proba(X_test)[:,1]\n",
    "    xgb_tr+=xgbclf.predict_proba(X_train)[:,1]/n_fold\n",
    "    val=xgbclf.predict_proba(X_valid)[:,1]\n",
    "    if fold_n != 3:\n",
    "        del xgbclf\n",
    "    del X_valid\n",
    "    print('ROC accuracy: {}'.format(roc_auc_score(y_valid, val)))\n",
    "    del val,y_valid\n",
    "    xgb_submission['isFraud'] = xgb_submission['isFraud']+pred/n_fold\n",
    "    del pred\n",
    "    gc.collect()\n",
    "    \n",
    "xgb_submission.to_csv('preds/xgb_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 645)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.6208557761807184,\n",
       " 'feature_fraction': 0.8161334733057637,\n",
       " 'max_depth': 26,\n",
       " 'min_child_weight': 1.1487246317328306,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'num_leaves': 799,\n",
       " 'reg_alpha': 0.2759381261875936,\n",
       " 'reg_lambda': 0.5598769107896939}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lgbclf = lgb.LGBMRegressor(**params,\n",
    "                          n_estimators=500)\n",
    "\n",
    "xgbclf = xgb.XGBRegressor(\n",
    "            **params_fx,\n",
    "            n_estimators=500,\n",
    "            tree_method = 'hist'\n",
    "    )\n",
    "\n",
    "rfclf = RandomForestRegressor(n_estimators=150,\n",
    "                              max_depth=9, \n",
    "                                max_features='sqrt', \n",
    "                                random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[lgbclf, xgbclf], # Level 1\n",
    "          [rfclf]] # Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.replace(np.inf,-999)\n",
    "X_train=X_train.replace(-np.inf,-999)\n",
    "X_test=X_test.replace(np.inf,-999)\n",
    "X_test=X_test.replace(-np.inf,-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "Input Dimensionality 645 at Level 0 \n",
      "2 models included in Level 0 \n"
     ]
    }
   ],
   "source": [
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n",
    "# Specify parameters for stacked model and begin training\n",
    "model = StackNetClassifier(models, \n",
    "                           metric=\"auc\", \n",
    "                           folds=4,\n",
    "                           restacking=False,\n",
    "                           use_retraining=True,\n",
    "                           use_proba=True, # To use predict_proba after training\n",
    "                           random_state=12,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "model.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack_submission = sample_submission.copy()\n",
    "preds = model.predict_proba(X_test.values)[:, 1]\n",
    "stack = model.predict_proba(X_train.values)[:,1]\n",
    "stack_submission['isFraud'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for ensemble parameter use this with nn or something\n",
    "\n",
    "# meaning_set = pd.DataFrame()\n",
    "\n",
    "# meaning_set['m1'] = lgb_tr\n",
    "# meaning_set['m2'] = xgb_tr\n",
    "# meaning_set['m3'] = stack\n",
    "# # meaning_set['m4'] = lgb_tr\n",
    "\n",
    "# y_mean = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble=sample_submission.copy()\n",
    "ensemble.isFraud=lgb_submission*0.4+xgb_submission*0.2+stack_submission*0.4\n",
    "#ensemble.isFraud=lgb_submission*0.5+xgb_submission*0.5\n",
    "\n",
    "ensemble.to_csv('preds/xgb_lgb_stacking.csv')\n",
    "lgb_submission.to_csv('preds/lgb_submission.csv')\n",
    "xgb_submission.to_csv('preds/xgb_submission.csv')\n",
    "stack_submission.to_csv('preds/ens_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgbclf = lgb.LGBMClassifier(\n",
    "    **params,\n",
    "    n_estimator = 200,\n",
    ")\n",
    "    \n",
    "lgbclf.fit(X_train, y_train)\n",
    "\n",
    "lgb_imp = lgbclf.feature_importances_\n",
    "\n",
    "lgb_imp_idx = []\n",
    "cols = X_train.columns\n",
    "for i, imp in enumerate(lgb_imp):\n",
    "    if imp > 0:\n",
    "        lgb_imp_idx.append(i)\n",
    "        \n",
    "new_cols_imp = cols[lgb_imp_idx]\n",
    "\n",
    "# print(len(cols_imp)  ,len(new_cols_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_imp = list(new_cols_imp)\n",
    "new_cols_imp.append('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645 643\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns), len(new_cols_imp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
