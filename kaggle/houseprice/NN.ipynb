{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "import datawig\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('./train_X.csv')\n",
    "test_X = pd.read_csv('./test_X.csv')\n",
    "\n",
    "train_y = pd.read_csv('./train_y.csv')\n",
    "\n",
    "sub = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = train_X.columns.sort_values()\n",
    "\n",
    "rain_X = train_X[cc]\n",
    "test_X = test_X[cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (train_y - np.mean(train_y))/np.std(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 256\n",
    "n_node = 4\n",
    "\n",
    "inputs = layers.Input(shape =(train_X.shape[1], ))\n",
    "\n",
    "x = layers.Dense(n_layers)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "for i in range(n_node):\n",
    "    x = layers.Dense(n_layers//(2**(i+1)), kernel_regularizer=L1L2(l2=0.001), kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "m = models.Model(inputs, outputs)\n",
    "\n",
    "m.compile(optimizer = 'adam',\n",
    "            loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 275)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               70656     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 116,417\n",
      "Trainable params: 115,425\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1021 samples, validate on 439 samples\n",
      "Epoch 1/1000\n",
      "1021/1021 [==============================] - 1s 1ms/step - loss: 1.0960 - val_loss: 0.9474\n",
      "Epoch 2/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.7040 - val_loss: 0.8445\n",
      "Epoch 3/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.6514 - val_loss: 0.7942\n",
      "Epoch 4/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.6284 - val_loss: 0.7545\n",
      "Epoch 5/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.6212 - val_loss: 0.7578\n",
      "Epoch 6/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.5914 - val_loss: 0.6935\n",
      "Epoch 7/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.5677 - val_loss: 0.6928\n",
      "Epoch 8/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.5390 - val_loss: 0.6807\n",
      "Epoch 9/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.5480 - val_loss: 0.6556\n",
      "Epoch 10/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.5474 - val_loss: 0.6196\n",
      "Epoch 11/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.5227 - val_loss: 0.6022\n",
      "Epoch 12/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.5061 - val_loss: 0.6205\n",
      "Epoch 13/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.5092 - val_loss: 0.6222\n",
      "Epoch 14/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.5009 - val_loss: 0.6576\n",
      "Epoch 15/1000\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.485 - 0s 307us/step - loss: 0.4868 - val_loss: 0.5955\n",
      "Epoch 16/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.4774 - val_loss: 0.6074\n",
      "Epoch 17/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.4846 - val_loss: 0.5960\n",
      "Epoch 18/1000\n",
      "1021/1021 [==============================] - 0s 321us/step - loss: 0.4865 - val_loss: 0.5913\n",
      "Epoch 19/1000\n",
      "1021/1021 [==============================] - 0s 341us/step - loss: 0.4679 - val_loss: 0.5740\n",
      "Epoch 20/1000\n",
      "1021/1021 [==============================] - 0s 384us/step - loss: 0.4462 - val_loss: 0.5805\n",
      "Epoch 21/1000\n",
      "1021/1021 [==============================] - 0s 377us/step - loss: 0.4424 - val_loss: 0.5562\n",
      "Epoch 22/1000\n",
      "1021/1021 [==============================] - 0s 371us/step - loss: 0.4254 - val_loss: 0.5630\n",
      "Epoch 23/1000\n",
      "1021/1021 [==============================] - 0s 326us/step - loss: 0.4248 - val_loss: 0.5463\n",
      "Epoch 24/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.4192 - val_loss: 0.5269\n",
      "Epoch 25/1000\n",
      "1021/1021 [==============================] - 0s 297us/step - loss: 0.4004 - val_loss: 0.5104\n",
      "Epoch 26/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.3988 - val_loss: 0.5111\n",
      "Epoch 27/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.3633 - val_loss: 0.5019\n",
      "Epoch 28/1000\n",
      "1021/1021 [==============================] - 0s 296us/step - loss: 0.3772 - val_loss: 0.4999\n",
      "Epoch 29/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.3609 - val_loss: 0.5343\n",
      "Epoch 30/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.3618 - val_loss: 0.5001\n",
      "Epoch 31/1000\n",
      "1021/1021 [==============================] - 0s 318us/step - loss: 0.3509 - val_loss: 0.4835\n",
      "Epoch 32/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.3395 - val_loss: 0.4630\n",
      "Epoch 33/1000\n",
      "1021/1021 [==============================] - 0s 302us/step - loss: 0.3311 - val_loss: 0.4867\n",
      "Epoch 34/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.3230 - val_loss: 0.4473\n",
      "Epoch 35/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.3227 - val_loss: 0.4486\n",
      "Epoch 36/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.3114 - val_loss: 0.4466\n",
      "Epoch 37/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.3022 - val_loss: 0.4268\n",
      "Epoch 38/1000\n",
      "1021/1021 [==============================] - 0s 318us/step - loss: 0.3036 - val_loss: 0.4397\n",
      "Epoch 39/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.3066 - val_loss: 0.4267\n",
      "Epoch 40/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.3065 - val_loss: 0.4405\n",
      "Epoch 41/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.2997 - val_loss: 0.4385\n",
      "Epoch 42/1000\n",
      "1021/1021 [==============================] - 0s 299us/step - loss: 0.2785 - val_loss: 0.4266\n",
      "Epoch 43/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.2782 - val_loss: 0.4379\n",
      "Epoch 44/1000\n",
      "1021/1021 [==============================] - 0s 299us/step - loss: 0.2562 - val_loss: 0.4067\n",
      "Epoch 45/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.2566 - val_loss: 0.4004\n",
      "Epoch 46/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.2575 - val_loss: 0.4266\n",
      "Epoch 47/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.2502 - val_loss: 0.4331\n",
      "Epoch 48/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.2300 - val_loss: 0.3870\n",
      "Epoch 49/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.2352 - val_loss: 0.4092\n",
      "Epoch 50/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.2284 - val_loss: 0.3984\n",
      "Epoch 51/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.2252 - val_loss: 0.4002\n",
      "Epoch 52/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.2170 - val_loss: 0.3820\n",
      "Epoch 53/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.2071 - val_loss: 0.4037\n",
      "Epoch 54/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.2135 - val_loss: 0.3962\n",
      "Epoch 55/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.2047 - val_loss: 0.3549\n",
      "Epoch 56/1000\n",
      "1021/1021 [==============================] - 0s 323us/step - loss: 0.1886 - val_loss: 0.3617\n",
      "Epoch 57/1000\n",
      "1021/1021 [==============================] - 0s 318us/step - loss: 0.1873 - val_loss: 0.3454\n",
      "Epoch 58/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.2074 - val_loss: 0.3553\n",
      "Epoch 59/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.1883 - val_loss: 0.3580\n",
      "Epoch 60/1000\n",
      "1021/1021 [==============================] - 0s 327us/step - loss: 0.1941 - val_loss: 0.3233\n",
      "Epoch 61/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.1860 - val_loss: 0.4559\n",
      "Epoch 62/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.1885 - val_loss: 0.3850\n",
      "Epoch 63/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.1913 - val_loss: 0.3542\n",
      "Epoch 64/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.1730 - val_loss: 0.3843\n",
      "Epoch 65/1000\n",
      "1021/1021 [==============================] - 0s 321us/step - loss: 0.1747 - val_loss: 0.3749\n",
      "Epoch 66/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.1647 - val_loss: 0.3321\n",
      "Epoch 67/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.1683 - val_loss: 0.3682\n",
      "Epoch 68/1000\n",
      "1021/1021 [==============================] - 0s 320us/step - loss: 0.1572 - val_loss: 0.3807\n",
      "Epoch 69/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.1641 - val_loss: 0.3742\n",
      "Epoch 70/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.1624 - val_loss: 0.3405\n",
      "Epoch 71/1000\n",
      "1021/1021 [==============================] - 0s 300us/step - loss: 0.1496 - val_loss: 0.3369\n",
      "Epoch 72/1000\n",
      "1021/1021 [==============================] - 0s 302us/step - loss: 0.1426 - val_loss: 0.3553\n",
      "Epoch 73/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.1393 - val_loss: 0.3313\n",
      "Epoch 74/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.1367 - val_loss: 0.3370\n",
      "Epoch 75/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.1402 - val_loss: 0.3555\n",
      "Epoch 76/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.1384 - val_loss: 0.3231\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 320us/step - loss: 0.1324 - val_loss: 0.3458\n",
      "Epoch 78/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.1383 - val_loss: 0.3576\n",
      "Epoch 79/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.1371 - val_loss: 0.2999\n",
      "Epoch 80/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.1351 - val_loss: 0.3764\n",
      "Epoch 81/1000\n",
      "1021/1021 [==============================] - 0s 319us/step - loss: 0.1330 - val_loss: 0.3667\n",
      "Epoch 82/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.1175 - val_loss: 0.3526\n",
      "Epoch 83/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.1270 - val_loss: 0.3438\n",
      "Epoch 84/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.1255 - val_loss: 0.3365\n",
      "Epoch 85/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.1198 - val_loss: 0.3932\n",
      "Epoch 86/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.1191 - val_loss: 0.3672\n",
      "Epoch 87/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.1142 - val_loss: 0.3638\n",
      "Epoch 88/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.1130 - val_loss: 0.3330\n",
      "Epoch 89/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.1101 - val_loss: 0.3211\n",
      "Epoch 90/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.1122 - val_loss: 0.3450\n",
      "Epoch 91/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.1065 - val_loss: 0.3195\n",
      "Epoch 92/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.1037 - val_loss: 0.3306\n",
      "Epoch 93/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.1103 - val_loss: 0.3644\n",
      "Epoch 94/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.1125 - val_loss: 0.3489\n",
      "Epoch 95/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.1036 - val_loss: 0.3295\n",
      "Epoch 96/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.1021 - val_loss: 0.3233\n",
      "Epoch 97/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.0984 - val_loss: 0.3067\n",
      "Epoch 98/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.1002 - val_loss: 0.3344\n",
      "Epoch 99/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0955 - val_loss: 0.3414\n",
      "Epoch 100/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.0987 - val_loss: 0.3286\n",
      "Epoch 101/1000\n",
      "1021/1021 [==============================] - 0s 299us/step - loss: 0.0834 - val_loss: 0.3330\n",
      "Epoch 102/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0889 - val_loss: 0.3308\n",
      "Epoch 103/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0853 - val_loss: 0.2954\n",
      "Epoch 104/1000\n",
      "1021/1021 [==============================] - 0s 299us/step - loss: 0.0847 - val_loss: 0.2714\n",
      "Epoch 105/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0877 - val_loss: 0.2880\n",
      "Epoch 106/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.0842 - val_loss: 0.2930\n",
      "Epoch 107/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0908 - val_loss: 0.2884\n",
      "Epoch 108/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0815 - val_loss: 0.2709\n",
      "Epoch 109/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0805 - val_loss: 0.2911\n",
      "Epoch 110/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0924 - val_loss: 0.2981\n",
      "Epoch 111/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0814 - val_loss: 0.3030\n",
      "Epoch 112/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0799 - val_loss: 0.3045\n",
      "Epoch 113/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0766 - val_loss: 0.3009\n",
      "Epoch 114/1000\n",
      "1021/1021 [==============================] - 0s 322us/step - loss: 0.0909 - val_loss: 0.3268\n",
      "Epoch 115/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0812 - val_loss: 0.2599\n",
      "Epoch 116/1000\n",
      "1021/1021 [==============================] - 0s 301us/step - loss: 0.0871 - val_loss: 0.3045\n",
      "Epoch 117/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.0957 - val_loss: 0.2671\n",
      "Epoch 118/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.0942 - val_loss: 0.2695\n",
      "Epoch 119/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0801 - val_loss: 0.2634\n",
      "Epoch 120/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.0782 - val_loss: 0.2337\n",
      "Epoch 121/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0806 - val_loss: 0.2464\n",
      "Epoch 122/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0772 - val_loss: 0.2762\n",
      "Epoch 123/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.0798 - val_loss: 0.2514\n",
      "Epoch 124/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.0766 - val_loss: 0.2575\n",
      "Epoch 125/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0766 - val_loss: 0.2800\n",
      "Epoch 126/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.0778 - val_loss: 0.2978\n",
      "Epoch 127/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0754 - val_loss: 0.2668\n",
      "Epoch 128/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.0709 - val_loss: 0.2813\n",
      "Epoch 129/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.0792 - val_loss: 0.2736\n",
      "Epoch 130/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.0729 - val_loss: 0.2977\n",
      "Epoch 131/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.0785 - val_loss: 0.2892\n",
      "Epoch 132/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0746 - val_loss: 0.2819\n",
      "Epoch 133/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0696 - val_loss: 0.2630\n",
      "Epoch 134/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0708 - val_loss: 0.3147\n",
      "Epoch 135/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0679 - val_loss: 0.2802\n",
      "Epoch 136/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.0742 - val_loss: 0.3069\n",
      "Epoch 137/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.0675 - val_loss: 0.2748\n",
      "Epoch 138/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0763 - val_loss: 0.2786\n",
      "Epoch 139/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0640 - val_loss: 0.2522\n",
      "Epoch 140/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.0766 - val_loss: 0.2564\n",
      "Epoch 141/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.0834 - val_loss: 0.2693\n",
      "Epoch 142/1000\n",
      "1021/1021 [==============================] - 0s 300us/step - loss: 0.0816 - val_loss: 0.2491\n",
      "Epoch 143/1000\n",
      "1021/1021 [==============================] - 0s 307us/step - loss: 0.0695 - val_loss: 0.2403\n",
      "Epoch 144/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0604 - val_loss: 0.2512\n",
      "Epoch 145/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.0569 - val_loss: 0.2514\n",
      "Epoch 146/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0537 - val_loss: 0.2586\n",
      "Epoch 147/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0626 - val_loss: 0.2673\n",
      "Epoch 148/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0713 - val_loss: 0.2510\n",
      "Epoch 149/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0617 - val_loss: 0.2560\n",
      "Epoch 150/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0579 - val_loss: 0.2710\n",
      "Epoch 151/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.0650 - val_loss: 0.2605\n",
      "Epoch 152/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0646 - val_loss: 0.2675\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0550 - val_loss: 0.2551\n",
      "Epoch 154/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.0611 - val_loss: 0.2728\n",
      "Epoch 155/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0629 - val_loss: 0.2763\n",
      "Epoch 156/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.0742 - val_loss: 0.2608\n",
      "Epoch 157/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0675 - val_loss: 0.2670\n",
      "Epoch 158/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0642 - val_loss: 0.3029\n",
      "Epoch 159/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0736 - val_loss: 0.2463\n",
      "Epoch 160/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0582 - val_loss: 0.2642\n",
      "Epoch 161/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.0638 - val_loss: 0.2603\n",
      "Epoch 162/1000\n",
      "1021/1021 [==============================] - 0s 322us/step - loss: 0.0597 - val_loss: 0.2509\n",
      "Epoch 163/1000\n",
      "1021/1021 [==============================] - 0s 322us/step - loss: 0.0645 - val_loss: 0.2640\n",
      "Epoch 164/1000\n",
      "1021/1021 [==============================] - 0s 325us/step - loss: 0.0715 - val_loss: 0.2339\n",
      "Epoch 165/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0664 - val_loss: 0.2631\n",
      "Epoch 166/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0618 - val_loss: 0.2860\n",
      "Epoch 167/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0717 - val_loss: 0.2235\n",
      "Epoch 168/1000\n",
      "1021/1021 [==============================] - 0s 329us/step - loss: 0.0631 - val_loss: 0.2544\n",
      "Epoch 169/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.0559 - val_loss: 0.2301\n",
      "Epoch 170/1000\n",
      "1021/1021 [==============================] - 0s 305us/step - loss: 0.0569 - val_loss: 0.2209\n",
      "Epoch 171/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.0581 - val_loss: 0.2615\n",
      "Epoch 172/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0673 - val_loss: 0.2645\n",
      "Epoch 173/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.0618 - val_loss: 0.2488\n",
      "Epoch 174/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.0667 - val_loss: 0.2440\n",
      "Epoch 175/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0617 - val_loss: 0.2595\n",
      "Epoch 176/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.0520 - val_loss: 0.2896\n",
      "Epoch 177/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.0568 - val_loss: 0.2375\n",
      "Epoch 178/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0566 - val_loss: 0.2439\n",
      "Epoch 179/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.0518 - val_loss: 0.2443\n",
      "Epoch 180/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0575 - val_loss: 0.2560\n",
      "Epoch 181/1000\n",
      "1021/1021 [==============================] - 0s 323us/step - loss: 0.0507 - val_loss: 0.2451\n",
      "Epoch 182/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.0522 - val_loss: 0.2452\n",
      "Epoch 183/1000\n",
      "1021/1021 [==============================] - 0s 317us/step - loss: 0.0590 - val_loss: 0.2366\n",
      "Epoch 184/1000\n",
      "1021/1021 [==============================] - 0s 313us/step - loss: 0.0502 - val_loss: 0.2598\n",
      "Epoch 185/1000\n",
      "1021/1021 [==============================] - 0s 322us/step - loss: 0.0472 - val_loss: 0.2459\n",
      "Epoch 186/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0538 - val_loss: 0.2508\n",
      "Epoch 187/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.0503 - val_loss: 0.2673\n",
      "Epoch 188/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.0462 - val_loss: 0.2520\n",
      "Epoch 189/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0456 - val_loss: 0.2320\n",
      "Epoch 190/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0507 - val_loss: 0.2418\n",
      "Epoch 191/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0549 - val_loss: 0.2674\n",
      "Epoch 192/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0525 - val_loss: 0.2602\n",
      "Epoch 193/1000\n",
      "1021/1021 [==============================] - 0s 326us/step - loss: 0.0511 - val_loss: 0.2606\n",
      "Epoch 194/1000\n",
      "1021/1021 [==============================] - 0s 320us/step - loss: 0.0588 - val_loss: 0.2434\n",
      "Epoch 195/1000\n",
      "1021/1021 [==============================] - 0s 304us/step - loss: 0.0563 - val_loss: 0.2511\n",
      "Epoch 196/1000\n",
      "1021/1021 [==============================] - 0s 316us/step - loss: 0.0548 - val_loss: 0.2569\n",
      "Epoch 197/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0458 - val_loss: 0.2617\n",
      "Epoch 198/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0526 - val_loss: 0.2686\n",
      "Epoch 199/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0506 - val_loss: 0.2480\n",
      "Epoch 200/1000\n",
      "1021/1021 [==============================] - 0s 325us/step - loss: 0.0444 - val_loss: 0.2571\n",
      "Epoch 201/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0483 - val_loss: 0.2777\n",
      "Epoch 202/1000\n",
      "1021/1021 [==============================] - 0s 323us/step - loss: 0.0484 - val_loss: 0.2831\n",
      "Epoch 203/1000\n",
      "1021/1021 [==============================] - 0s 330us/step - loss: 0.0472 - val_loss: 0.2705\n",
      "Epoch 204/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0524 - val_loss: 0.2928\n",
      "Epoch 205/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0554 - val_loss: 0.2757\n",
      "Epoch 206/1000\n",
      "1021/1021 [==============================] - 0s 346us/step - loss: 0.0516 - val_loss: 0.2564\n",
      "Epoch 207/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0472 - val_loss: 0.2571\n",
      "Epoch 208/1000\n",
      "1021/1021 [==============================] - 0s 320us/step - loss: 0.0450 - val_loss: 0.2439\n",
      "Epoch 209/1000\n",
      "1021/1021 [==============================] - 0s 314us/step - loss: 0.0451 - val_loss: 0.2464\n",
      "Epoch 210/1000\n",
      "1021/1021 [==============================] - 0s 312us/step - loss: 0.0525 - val_loss: 0.2688\n",
      "Epoch 211/1000\n",
      "1021/1021 [==============================] - 0s 303us/step - loss: 0.0517 - val_loss: 0.2540\n",
      "Epoch 212/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0450 - val_loss: 0.2556\n",
      "Epoch 213/1000\n",
      "1021/1021 [==============================] - 0s 310us/step - loss: 0.0478 - val_loss: 0.2667\n",
      "Epoch 214/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0478 - val_loss: 0.2416\n",
      "Epoch 215/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0515 - val_loss: 0.2718\n",
      "Epoch 216/1000\n",
      "1021/1021 [==============================] - 0s 308us/step - loss: 0.0483 - val_loss: 0.2558\n",
      "Epoch 217/1000\n",
      "1021/1021 [==============================] - 0s 306us/step - loss: 0.0556 - val_loss: 0.2592\n",
      "Epoch 218/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0478 - val_loss: 0.2355\n",
      "Epoch 219/1000\n",
      "1021/1021 [==============================] - 0s 311us/step - loss: 0.0437 - val_loss: 0.2504\n",
      "Epoch 220/1000\n",
      "1021/1021 [==============================] - 0s 315us/step - loss: 0.0420 - val_loss: 0.2383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28e8b80d3c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(train_X, target, \n",
    "      epochs = 1000,\n",
    "     validation_split=0.3,\n",
    "     callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = m.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = (k * np.std(train_y)[0]) + np.mean(train_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['SalePrice'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>96352.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>134897.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>185500.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>196634.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>181895.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>78717.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>82346.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>181107.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>110471.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>215491.046875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461   96352.843750\n",
       "1     1462  134897.718750\n",
       "2     1463  185500.015625\n",
       "3     1464  196634.281250\n",
       "4     1465  181895.328125\n",
       "...    ...            ...\n",
       "1454  2915   78717.148438\n",
       "1455  2916   82346.812500\n",
       "1456  2917  181107.375000\n",
       "1457  2918  110471.937500\n",
       "1458  2919  215491.046875\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./sub/sub10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
