{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "import datawig\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('./train_X.csv')\n",
    "test_X = pd.read_csv('./test_X.csv')\n",
    "\n",
    "train_y = pd.read_csv('./train_y.csv')\n",
    "\n",
    "sub = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = train_X.columns.sort_values()\n",
    "\n",
    "rain_X = train_X[cc]\n",
    "test_X = test_X[cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (train_y - np.mean(train_y))/np.std(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 256\n",
    "n_node = 3\n",
    "\n",
    "inputs = layers.Input(shape =(train_X.shape[1], ))\n",
    "\n",
    "x = layers.Dense(n_layers)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "for i in range(n_node):\n",
    "    x = layers.Dense(n_layers//(2**(i+1)), kernel_regularizer=L1L2(l2=0.001), kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "m = models.Model(inputs, outputs)\n",
    "\n",
    "m.compile(optimizer = 'adam',\n",
    "            loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 275)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               70656     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 115,841\n",
      "Trainable params: 114,881\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1021 samples, validate on 439 samples\n",
      "Epoch 1/1000\n",
      "1021/1021 [==============================] - 1s 1ms/step - loss: 1.5352 - val_loss: 0.9014\n",
      "Epoch 2/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.8754 - val_loss: 0.8508\n",
      "Epoch 3/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.8593 - val_loss: 0.7840\n",
      "Epoch 4/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.7817 - val_loss: 0.7604\n",
      "Epoch 5/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.7512 - val_loss: 0.7273\n",
      "Epoch 6/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.6970 - val_loss: 0.7248\n",
      "Epoch 7/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.6938 - val_loss: 0.7539\n",
      "Epoch 8/1000\n",
      "1021/1021 [==============================] - 0s 278us/step - loss: 0.6234 - val_loss: 0.6976\n",
      "Epoch 9/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.6495 - val_loss: 0.6560\n",
      "Epoch 10/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.6590 - val_loss: 0.6622\n",
      "Epoch 11/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.6247 - val_loss: 0.6839\n",
      "Epoch 12/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.6062 - val_loss: 0.6572\n",
      "Epoch 13/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.5823 - val_loss: 0.6711\n",
      "Epoch 14/1000\n",
      "1021/1021 [==============================] - 0s 288us/step - loss: 0.5826 - val_loss: 0.6826\n",
      "Epoch 15/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.5726 - val_loss: 0.6324\n",
      "Epoch 16/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.5719 - val_loss: 0.6316\n",
      "Epoch 17/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.5479 - val_loss: 0.6443\n",
      "Epoch 18/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.5211 - val_loss: 0.6091\n",
      "Epoch 19/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.5306 - val_loss: 0.6184\n",
      "Epoch 20/1000\n",
      "1021/1021 [==============================] - 0s 265us/step - loss: 0.5473 - val_loss: 0.6020\n",
      "Epoch 21/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.5011 - val_loss: 0.6079\n",
      "Epoch 22/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.4975 - val_loss: 0.6041\n",
      "Epoch 23/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.4948 - val_loss: 0.5711\n",
      "Epoch 24/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.4868 - val_loss: 0.5715\n",
      "Epoch 25/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.5039 - val_loss: 0.5759\n",
      "Epoch 26/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.4931 - val_loss: 0.5647\n",
      "Epoch 27/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.4691 - val_loss: 0.5690\n",
      "Epoch 28/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.4709 - val_loss: 0.5399\n",
      "Epoch 29/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.4454 - val_loss: 0.5317\n",
      "Epoch 30/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.4286 - val_loss: 0.5551\n",
      "Epoch 31/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.4329 - val_loss: 0.5419\n",
      "Epoch 32/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.4501 - val_loss: 0.5315\n",
      "Epoch 33/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.4389 - val_loss: 0.5376\n",
      "Epoch 34/1000\n",
      "1021/1021 [==============================] - 0s 264us/step - loss: 0.4257 - val_loss: 0.5020\n",
      "Epoch 35/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.4218 - val_loss: 0.5317\n",
      "Epoch 36/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.3830 - val_loss: 0.5060\n",
      "Epoch 37/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.3748 - val_loss: 0.4992\n",
      "Epoch 38/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.3900 - val_loss: 0.4880\n",
      "Epoch 39/1000\n",
      "1021/1021 [==============================] - 0s 278us/step - loss: 0.3650 - val_loss: 0.4793\n",
      "Epoch 40/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.3734 - val_loss: 0.4810\n",
      "Epoch 41/1000\n",
      "1021/1021 [==============================] - 0s 278us/step - loss: 0.3763 - val_loss: 0.4912\n",
      "Epoch 42/1000\n",
      "1021/1021 [==============================] - 0s 262us/step - loss: 0.3662 - val_loss: 0.4780\n",
      "Epoch 43/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.3624 - val_loss: 0.4785\n",
      "Epoch 44/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.3610 - val_loss: 0.4531\n",
      "Epoch 45/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.3550 - val_loss: 0.4613\n",
      "Epoch 46/1000\n",
      "1021/1021 [==============================] - 0s 262us/step - loss: 0.3309 - val_loss: 0.4613\n",
      "Epoch 47/1000\n",
      "1021/1021 [==============================] - 0s 263us/step - loss: 0.3468 - val_loss: 0.4672\n",
      "Epoch 48/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.3376 - val_loss: 0.4842\n",
      "Epoch 49/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.3217 - val_loss: 0.4870\n",
      "Epoch 50/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.3059 - val_loss: 0.4879\n",
      "Epoch 51/1000\n",
      "1021/1021 [==============================] - 0s 290us/step - loss: 0.2942 - val_loss: 0.4585\n",
      "Epoch 52/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.3008 - val_loss: 0.4564\n",
      "Epoch 53/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.3067 - val_loss: 0.4604\n",
      "Epoch 54/1000\n",
      "1021/1021 [==============================] - 0s 282us/step - loss: 0.2970 - val_loss: 0.4645\n",
      "Epoch 55/1000\n",
      "1021/1021 [==============================] - 0s 263us/step - loss: 0.2992 - val_loss: 0.4478\n",
      "Epoch 56/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.2609 - val_loss: 0.4275\n",
      "Epoch 57/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.2822 - val_loss: 0.4148\n",
      "Epoch 58/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.2925 - val_loss: 0.4095\n",
      "Epoch 59/1000\n",
      "1021/1021 [==============================] - 0s 284us/step - loss: 0.2896 - val_loss: 0.4258\n",
      "Epoch 60/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.2731 - val_loss: 0.4228\n",
      "Epoch 61/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.2660 - val_loss: 0.3858\n",
      "Epoch 62/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.2626 - val_loss: 0.4017\n",
      "Epoch 63/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.2497 - val_loss: 0.4043\n",
      "Epoch 64/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.2624 - val_loss: 0.3622\n",
      "Epoch 65/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.2328 - val_loss: 0.3983\n",
      "Epoch 66/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.2633 - val_loss: 0.3957\n",
      "Epoch 67/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.2389 - val_loss: 0.3962\n",
      "Epoch 68/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.2257 - val_loss: 0.3940\n",
      "Epoch 69/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.2276 - val_loss: 0.4293\n",
      "Epoch 70/1000\n",
      "1021/1021 [==============================] - 0s 287us/step - loss: 0.2168 - val_loss: 0.3970\n",
      "Epoch 71/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.2052 - val_loss: 0.3938\n",
      "Epoch 72/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.2084 - val_loss: 0.3627\n",
      "Epoch 73/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.2111 - val_loss: 0.3703\n",
      "Epoch 74/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.1853 - val_loss: 0.3572\n",
      "Epoch 75/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.1994 - val_loss: 0.3580\n",
      "Epoch 76/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.2062 - val_loss: 0.3752\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.1830 - val_loss: 0.3652\n",
      "Epoch 78/1000\n",
      "1021/1021 [==============================] - 0s 281us/step - loss: 0.1953 - val_loss: 0.3637\n",
      "Epoch 79/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.1846 - val_loss: 0.3643\n",
      "Epoch 80/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.1996 - val_loss: 0.4723\n",
      "Epoch 81/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.1793 - val_loss: 0.3602\n",
      "Epoch 82/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.1811 - val_loss: 0.3975\n",
      "Epoch 83/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.1747 - val_loss: 0.3364\n",
      "Epoch 84/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.1579 - val_loss: 0.3396\n",
      "Epoch 85/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.1800 - val_loss: 0.3562\n",
      "Epoch 86/1000\n",
      "1021/1021 [==============================] - 0s 285us/step - loss: 0.1834 - val_loss: 0.3420\n",
      "Epoch 87/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.1668 - val_loss: 0.3172\n",
      "Epoch 88/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.1647 - val_loss: 0.3202\n",
      "Epoch 89/1000\n",
      "1021/1021 [==============================] - 0s 264us/step - loss: 0.1688 - val_loss: 0.3063\n",
      "Epoch 90/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.1614 - val_loss: 0.3142\n",
      "Epoch 91/1000\n",
      "1021/1021 [==============================] - 0s 278us/step - loss: 0.1497 - val_loss: 0.3073\n",
      "Epoch 92/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.1520 - val_loss: 0.3082\n",
      "Epoch 93/1000\n",
      "1021/1021 [==============================] - 0s 284us/step - loss: 0.1469 - val_loss: 0.3069\n",
      "Epoch 94/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1457 - val_loss: 0.3202\n",
      "Epoch 95/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.1497 - val_loss: 0.3100\n",
      "Epoch 96/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1625 - val_loss: 0.2962\n",
      "Epoch 97/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.1312 - val_loss: 0.3056\n",
      "Epoch 98/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1244 - val_loss: 0.2941\n",
      "Epoch 99/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1221 - val_loss: 0.3140\n",
      "Epoch 100/1000\n",
      "1021/1021 [==============================] - 0s 282us/step - loss: 0.1265 - val_loss: 0.3357\n",
      "Epoch 101/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.1323 - val_loss: 0.3009\n",
      "Epoch 102/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.1328 - val_loss: 0.2891\n",
      "Epoch 103/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.1327 - val_loss: 0.3147\n",
      "Epoch 104/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1408 - val_loss: 0.3216\n",
      "Epoch 105/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.1378 - val_loss: 0.2933\n",
      "Epoch 106/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.1183 - val_loss: 0.2821\n",
      "Epoch 107/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.1236 - val_loss: 0.2945\n",
      "Epoch 108/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1313 - val_loss: 0.3021\n",
      "Epoch 109/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.1227 - val_loss: 0.2935\n",
      "Epoch 110/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.1263 - val_loss: 0.2903\n",
      "Epoch 111/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.1101 - val_loss: 0.3062\n",
      "Epoch 112/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1208 - val_loss: 0.2751\n",
      "Epoch 113/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.1143 - val_loss: 0.2773\n",
      "Epoch 114/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.1145 - val_loss: 0.2833\n",
      "Epoch 115/1000\n",
      "1021/1021 [==============================] - 0s 261us/step - loss: 0.1228 - val_loss: 0.2700\n",
      "Epoch 116/1000\n",
      "1021/1021 [==============================] - 0s 262us/step - loss: 0.1098 - val_loss: 0.2811\n",
      "Epoch 117/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.1069 - val_loss: 0.2914\n",
      "Epoch 118/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.1120 - val_loss: 0.2951\n",
      "Epoch 119/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.1044 - val_loss: 0.3004\n",
      "Epoch 120/1000\n",
      "1021/1021 [==============================] - 0s 276us/step - loss: 0.1221 - val_loss: 0.2647\n",
      "Epoch 121/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.0990 - val_loss: 0.2629\n",
      "Epoch 122/1000\n",
      "1021/1021 [==============================] - 0s 289us/step - loss: 0.1041 - val_loss: 0.2550\n",
      "Epoch 123/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0916 - val_loss: 0.2920\n",
      "Epoch 124/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0927 - val_loss: 0.2835\n",
      "Epoch 125/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.0924 - val_loss: 0.2852\n",
      "Epoch 126/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0941 - val_loss: 0.2618\n",
      "Epoch 127/1000\n",
      "1021/1021 [==============================] - 0s 286us/step - loss: 0.1072 - val_loss: 0.2624\n",
      "Epoch 128/1000\n",
      "1021/1021 [==============================] - 0s 285us/step - loss: 0.1058 - val_loss: 0.2871\n",
      "Epoch 129/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.1135 - val_loss: 0.2686\n",
      "Epoch 130/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1043 - val_loss: 0.2667\n",
      "Epoch 131/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.1009 - val_loss: 0.2616\n",
      "Epoch 132/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.1004 - val_loss: 0.2545\n",
      "Epoch 133/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.0950 - val_loss: 0.2702\n",
      "Epoch 134/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.1008 - val_loss: 0.2879\n",
      "Epoch 135/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.0960 - val_loss: 0.2659\n",
      "Epoch 136/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0877 - val_loss: 0.2487\n",
      "Epoch 137/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.1141 - val_loss: 0.2745\n",
      "Epoch 138/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0914 - val_loss: 0.2698\n",
      "Epoch 139/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.0928 - val_loss: 0.2809\n",
      "Epoch 140/1000\n",
      "1021/1021 [==============================] - 0s 288us/step - loss: 0.0870 - val_loss: 0.2560\n",
      "Epoch 141/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.1065 - val_loss: 0.2780\n",
      "Epoch 142/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.1034 - val_loss: 0.2758\n",
      "Epoch 143/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.0933 - val_loss: 0.2846\n",
      "Epoch 144/1000\n",
      "1021/1021 [==============================] - 0s 287us/step - loss: 0.0885 - val_loss: 0.2623\n",
      "Epoch 145/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.0900 - val_loss: 0.2933\n",
      "Epoch 146/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.0981 - val_loss: 0.2616\n",
      "Epoch 147/1000\n",
      "1021/1021 [==============================] - 0s 276us/step - loss: 0.0924 - val_loss: 0.2719\n",
      "Epoch 148/1000\n",
      "1021/1021 [==============================] - 0s 276us/step - loss: 0.0830 - val_loss: 0.2719\n",
      "Epoch 149/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.0770 - val_loss: 0.2501\n",
      "Epoch 150/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.0833 - val_loss: 0.2608\n",
      "Epoch 151/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0809 - val_loss: 0.2629\n",
      "Epoch 152/1000\n",
      "1021/1021 [==============================] - 0s 281us/step - loss: 0.0880 - val_loss: 0.2826\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.0835 - val_loss: 0.2778\n",
      "Epoch 154/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0802 - val_loss: 0.2834\n",
      "Epoch 155/1000\n",
      "1021/1021 [==============================] - 0s 282us/step - loss: 0.0911 - val_loss: 0.2864\n",
      "Epoch 156/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.0777 - val_loss: 0.2986\n",
      "Epoch 157/1000\n",
      "1021/1021 [==============================] - 0s 267us/step - loss: 0.0782 - val_loss: 0.2670\n",
      "Epoch 158/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.0835 - val_loss: 0.2522\n",
      "Epoch 159/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.0744 - val_loss: 0.2476\n",
      "Epoch 160/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.0861 - val_loss: 0.2632\n",
      "Epoch 161/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.0943 - val_loss: 0.2584\n",
      "Epoch 162/1000\n",
      "1021/1021 [==============================] - 0s 284us/step - loss: 0.0811 - val_loss: 0.2532\n",
      "Epoch 163/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.0787 - val_loss: 0.2655\n",
      "Epoch 164/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0808 - val_loss: 0.2429\n",
      "Epoch 165/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.0800 - val_loss: 0.2570\n",
      "Epoch 166/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.0834 - val_loss: 0.2693\n",
      "Epoch 167/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.0867 - val_loss: 0.2628\n",
      "Epoch 168/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.0785 - val_loss: 0.2715\n",
      "Epoch 169/1000\n",
      "1021/1021 [==============================] - 0s 262us/step - loss: 0.0839 - val_loss: 0.2793\n",
      "Epoch 170/1000\n",
      "1021/1021 [==============================] - 0s 276us/step - loss: 0.1061 - val_loss: 0.3386\n",
      "Epoch 171/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0851 - val_loss: 0.3257\n",
      "Epoch 172/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.0992 - val_loss: 0.2853\n",
      "Epoch 173/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.0825 - val_loss: 0.2735\n",
      "Epoch 174/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.0845 - val_loss: 0.2661\n",
      "Epoch 175/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.0815 - val_loss: 0.2809\n",
      "Epoch 176/1000\n",
      "1021/1021 [==============================] - 0s 277us/step - loss: 0.0841 - val_loss: 0.3248\n",
      "Epoch 177/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.0850 - val_loss: 0.2879\n",
      "Epoch 178/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.0779 - val_loss: 0.2701\n",
      "Epoch 179/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.0764 - val_loss: 0.2974\n",
      "Epoch 180/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0726 - val_loss: 0.2903\n",
      "Epoch 181/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.0793 - val_loss: 0.2718\n",
      "Epoch 182/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.0844 - val_loss: 0.2849\n",
      "Epoch 183/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.0706 - val_loss: 0.2770\n",
      "Epoch 184/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0945 - val_loss: 0.2682\n",
      "Epoch 185/1000\n",
      "1021/1021 [==============================] - 0s 275us/step - loss: 0.0913 - val_loss: 0.2379\n",
      "Epoch 186/1000\n",
      "1021/1021 [==============================] - 0s 279us/step - loss: 0.0913 - val_loss: 0.2591\n",
      "Epoch 187/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.0828 - val_loss: 0.2551\n",
      "Epoch 188/1000\n",
      "1021/1021 [==============================] - 0s 268us/step - loss: 0.0692 - val_loss: 0.2571\n",
      "Epoch 189/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.0864 - val_loss: 0.2779\n",
      "Epoch 190/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.0721 - val_loss: 0.2696\n",
      "Epoch 191/1000\n",
      "1021/1021 [==============================] - 0s 282us/step - loss: 0.0748 - val_loss: 0.2454\n",
      "Epoch 192/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.0739 - val_loss: 0.2575\n",
      "Epoch 193/1000\n",
      "1021/1021 [==============================] - 0s 276us/step - loss: 0.0728 - val_loss: 0.2590\n",
      "Epoch 194/1000\n",
      "1021/1021 [==============================] - 0s 273us/step - loss: 0.0810 - val_loss: 0.2588\n",
      "Epoch 195/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.0783 - val_loss: 0.2863\n",
      "Epoch 196/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.0961 - val_loss: 0.2663\n",
      "Epoch 197/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.0744 - val_loss: 0.2613\n",
      "Epoch 198/1000\n",
      "1021/1021 [==============================] - 0s 274us/step - loss: 0.0766 - val_loss: 0.2560\n",
      "Epoch 199/1000\n",
      "1021/1021 [==============================] - 0s 266us/step - loss: 0.0838 - val_loss: 0.2625\n",
      "Epoch 200/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0682 - val_loss: 0.2554\n",
      "Epoch 201/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.0611 - val_loss: 0.2614\n",
      "Epoch 202/1000\n",
      "1021/1021 [==============================] - 0s 272us/step - loss: 0.0719 - val_loss: 0.2505\n",
      "Epoch 203/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.0662 - val_loss: 0.2529\n",
      "Epoch 204/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.0608 - val_loss: 0.2590\n",
      "Epoch 205/1000\n",
      "1021/1021 [==============================] - 0s 270us/step - loss: 0.0721 - val_loss: 0.2612\n",
      "Epoch 206/1000\n",
      "1021/1021 [==============================] - 0s 280us/step - loss: 0.0744 - val_loss: 0.2500\n",
      "Epoch 207/1000\n",
      "1021/1021 [==============================] - 0s 309us/step - loss: 0.0702 - val_loss: 0.2471\n",
      "Epoch 208/1000\n",
      "1021/1021 [==============================] - 0s 293us/step - loss: 0.0762 - val_loss: 0.2694\n",
      "Epoch 209/1000\n",
      "1021/1021 [==============================] - 0s 287us/step - loss: 0.0661 - val_loss: 0.2711\n",
      "Epoch 210/1000\n",
      "1021/1021 [==============================] - 0s 271us/step - loss: 0.0708 - val_loss: 0.2654\n",
      "Epoch 211/1000\n",
      "1021/1021 [==============================] - 0s 264us/step - loss: 0.0680 - val_loss: 0.2672\n",
      "Epoch 212/1000\n",
      "1021/1021 [==============================] - 0s 269us/step - loss: 0.0574 - val_loss: 0.2696\n",
      "Epoch 213/1000\n",
      "1021/1021 [==============================] - 0s 283us/step - loss: 0.0757 - val_loss: 0.2696\n",
      "Epoch 214/1000\n",
      "1021/1021 [==============================] - 0s 289us/step - loss: 0.0714 - val_loss: 0.2710\n",
      "Epoch 215/1000\n",
      "1021/1021 [==============================] - 0s 291us/step - loss: 0.0711 - val_loss: 0.2503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23773cc6cc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(train_X, target, \n",
    "      epochs = 1000,\n",
    "     validation_split=0.3,\n",
    "     callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = m.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = (k * np.std(train_y)[0]) + np.mean(train_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['SalePrice'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>138737.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>107663.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>157574.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>160758.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>155979.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>226571.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>185687.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>144073.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>165054.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>154051.765625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  138737.906250\n",
       "1     1462  107663.804688\n",
       "2     1463  157574.984375\n",
       "3     1464  160758.687500\n",
       "4     1465  155979.546875\n",
       "...    ...            ...\n",
       "1454  2915  226571.421875\n",
       "1455  2916  185687.859375\n",
       "1456  2917  144073.437500\n",
       "1457  2918  165054.062500\n",
       "1458  2919  154051.765625\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./sub/sub13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
