{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "## 딥러닝 맛보기\n",
    "\n",
    "- 추후 사용할 RNN을 위하여 딥러닝 즉 신경망에 대해 맛보기하는 시간을 가저보자\n",
    "- 이전 다른 분류기도 그랬지만 분류와 회귀 모두에서 사용할 수 있다.\n",
    "- 수학적 원리는 정확히 설명하고 구현하기 어려우므로 다른 자료를 참조하기를 권장함\n",
    "- 기본 구조 외에 다양한 architecture에 대한 것은 [여기](https://github.com/young31/Deep-Learning/tree/master/Architecture)\n",
    "  \n",
    "    \n",
    "- keras를 사용하여 구현할 예정\n",
    "    - keras는 쉽게 사용하게 해주는 툴\n",
    "    - tensorflow 등을 백으로 가질 수 있음\n",
    "    \n",
    "- 순차모형과 이름을 달아 연결하는 방법이 있음\n",
    "    - 순차모형이 시작하기는 쉬움\n",
    "    - 나중에 복잡한 망을 짜려면 개별 망에 연결하는 방법을 사용\n",
    "    \n",
    "- 신경망은 greedy하게 해를 찾는 경사하강법을 사용해서 답을 찾아가므로 정규화를 무조건 해줘야함!!!\n",
    "    - 해당 절에서는 편의를 위해 카테고리변수를 따로 설정하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('../1.clustering/titanic.csv')\n",
    "\n",
    "target = data['Survived']\n",
    "data = data.drop(['PassengerId', 'Survived'], axis=1)\n",
    "\n",
    "def sex(a):\n",
    "    if a == 'male':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def emb(a):\n",
    "    if a == 'S':\n",
    "        return 0\n",
    "    elif a == 'Q':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "data['Sex'] = data['Sex'].map(sex)\n",
    "data['Embarked'] = data['Embarked'].map(emb)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, target, test_size=0.3, random_state=2019, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "tt = std.fit_transform(train_X)\n",
    "te = std.fit_transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 층을 만든다\n",
    "from keras import models, layers, optimizers\n",
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "input_layer = layers.Input(shape=train_X.shape[1:])\n",
    "\n",
    "layer1 = layers.Dense(32, activation='relu')(input_layer)\n",
    "layer2 = layers.Dense(16, activation='relu')(layer1)\n",
    "\n",
    "out_layer = layers.Dense(1, activation='sigmoid')(layer2)\n",
    "\n",
    "model = models.Model(input_layer, out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile 한다.\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(lr=0.01),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## custom loss\n",
    "# from keras import backend as K\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed\n",
    "# ## cunstom metric\n",
    "\n",
    "# def f1(y_true, y_pred):\n",
    "#     def recall(y_true, y_pred):\n",
    "#         \"\"\"Recall metric.\n",
    "\n",
    "#         Only computes a batch-wise average of recall.\n",
    "\n",
    "#         Computes the recall, a metric for multi-label classification of\n",
    "#         how many relevant items are selected.\n",
    "#         \"\"\"\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#         recall = true_positives / (possible_positives + K.epsilon())\n",
    "#         return recall\n",
    "\n",
    "#     def precision(y_true, y_pred):\n",
    "#         \"\"\"Precision metric.\n",
    "\n",
    "#         Only computes a batch-wise average of precision.\n",
    "\n",
    "#         Computes the precision, a metric for multi-label classification of\n",
    "#         how many selected items are relevant.\n",
    "#         \"\"\"\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#         precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#         return precision\n",
    "#     precision = precision(y_true, y_pred)\n",
    "#     recall = recall(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "# custom_loss = focal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer = optimizers.Adam(lr=0.1),\n",
    "#              loss= custom_loss,\n",
    "#              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## callback 함수를 쓴다면 추가\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cp = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5331 - acc: 0.7586 - val_loss: 0.4402 - val_acc: 0.8200\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.4417 - acc: 0.8103 - val_loss: 0.4445 - val_acc: 0.8133\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.4240 - acc: 0.8190 - val_loss: 0.4505 - val_acc: 0.8133\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.4067 - acc: 0.8391 - val_loss: 0.4309 - val_acc: 0.8133\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.3914 - acc: 0.8506 - val_loss: 0.4380 - val_acc: 0.8067\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.3877 - acc: 0.8391 - val_loss: 0.4396 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3813 - acc: 0.8563 - val_loss: 0.4352 - val_acc: 0.8067\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.3693 - acc: 0.8563 - val_loss: 0.4400 - val_acc: 0.7867\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.3583 - acc: 0.8592 - val_loss: 0.4454 - val_acc: 0.7800\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.3473 - acc: 0.8621 - val_loss: 0.4474 - val_acc: 0.7800\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.3434 - acc: 0.8707 - val_loss: 0.4674 - val_acc: 0.7733\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3419 - acc: 0.8592 - val_loss: 0.4612 - val_acc: 0.7733\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.3277 - acc: 0.8621 - val_loss: 0.4623 - val_acc: 0.7733\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3207 - acc: 0.8534 - val_loss: 0.4642 - val_acc: 0.7533\n",
      "Epoch 15/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.3218 - acc: 0.8678 - val_loss: 0.4664 - val_acc: 0.7733\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.3089 - acc: 0.8678 - val_loss: 0.4947 - val_acc: 0.7600\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3051 - acc: 0.8678 - val_loss: 0.4513 - val_acc: 0.7800\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.3126 - acc: 0.8621 - val_loss: 0.4792 - val_acc: 0.7600\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3101 - acc: 0.8736 - val_loss: 0.5049 - val_acc: 0.7733\n",
      "Epoch 20/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.3007 - acc: 0.8764 - val_loss: 0.5051 - val_acc: 0.7600\n",
      "Epoch 21/100\n",
      "348/348 [==============================] - 0s 99us/step - loss: 0.3068 - acc: 0.8621 - val_loss: 0.5202 - val_acc: 0.7867\n",
      "Epoch 22/100\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3101 - acc: 0.8707 - val_loss: 0.4839 - val_acc: 0.7867\n",
      "Epoch 23/100\n",
      "348/348 [==============================] - 0s 97us/step - loss: 0.2928 - acc: 0.8736 - val_loss: 0.5192 - val_acc: 0.7733\n",
      "Epoch 24/100\n",
      "348/348 [==============================] - 0s 100us/step - loss: 0.2746 - acc: 0.8793 - val_loss: 0.5069 - val_acc: 0.7667\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d3a5133688>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 훈련시킨다.\n",
    "model.fit(tt, train_y,\n",
    "         epochs=100,\n",
    "         validation_split=0.3,\n",
    "         callbacks=[cp, es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7850467289719626\n"
     ]
    }
   ],
   "source": [
    "## 모델 평가\n",
    "res = model.predict(te)\n",
    "def thres(a):\n",
    "    if a < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "res = list(map(thres, res))\n",
    "print(accuracy_score(test_y, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47775495052337646, 0.7850467562675476]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(te, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348 samples, validate on 150 samples\n",
      "Epoch 1/40\n",
      "348/348 [==============================] - 0s 418us/step - loss: 0.6222 - acc: 0.7414 - val_loss: 0.5385 - val_acc: 0.8133\n",
      "Epoch 2/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.4812 - acc: 0.8103 - val_loss: 0.4748 - val_acc: 0.7933\n",
      "Epoch 3/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4620 - acc: 0.8103 - val_loss: 0.4918 - val_acc: 0.7733\n",
      "Epoch 4/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4373 - acc: 0.8132 - val_loss: 0.5039 - val_acc: 0.7933\n",
      "Epoch 5/40\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4298 - acc: 0.8276 - val_loss: 0.5361 - val_acc: 0.7133\n",
      "Epoch 6/40\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4295 - acc: 0.8218 - val_loss: 0.5303 - val_acc: 0.7467\n",
      "Epoch 7/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3911 - acc: 0.8420 - val_loss: 0.5220 - val_acc: 0.7933\n",
      "Epoch 8/40\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3920 - acc: 0.8190 - val_loss: 0.4843 - val_acc: 0.8200\n",
      "Epoch 9/40\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3977 - acc: 0.8247 - val_loss: 0.5621 - val_acc: 0.8333\n",
      "Epoch 10/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3641 - acc: 0.8448 - val_loss: 0.4847 - val_acc: 0.8200\n",
      "Epoch 11/40\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3554 - acc: 0.8448 - val_loss: 0.5769 - val_acc: 0.8133\n",
      "Epoch 12/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3786 - acc: 0.8448 - val_loss: 0.5362 - val_acc: 0.8133\n",
      "Epoch 13/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3540 - acc: 0.8534 - val_loss: 0.4976 - val_acc: 0.8133\n",
      "Epoch 14/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3302 - acc: 0.8649 - val_loss: 0.5484 - val_acc: 0.8267\n",
      "Epoch 15/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3299 - acc: 0.8506 - val_loss: 0.5129 - val_acc: 0.8067\n",
      "Epoch 16/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3199 - acc: 0.8621 - val_loss: 0.6131 - val_acc: 0.8133\n",
      "Epoch 17/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3146 - acc: 0.8678 - val_loss: 0.5669 - val_acc: 0.8067\n",
      "Epoch 18/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3500 - acc: 0.8420 - val_loss: 0.5518 - val_acc: 0.8333\n",
      "Epoch 19/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3396 - acc: 0.8190 - val_loss: 0.5766 - val_acc: 0.8067\n",
      "Epoch 20/40\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3561 - acc: 0.8477 - val_loss: 0.6859 - val_acc: 0.8200\n",
      "Epoch 21/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3552 - acc: 0.8477 - val_loss: 0.5283 - val_acc: 0.7867\n",
      "Epoch 22/40\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.3707 - acc: 0.8534 - val_loss: 0.6606 - val_acc: 0.8267\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d515449488>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모형을 쌓듯이 하는 방법의 같은 코드\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(lr=0.1),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.fit(tt, train_y.values,\n",
    "         epochs=40,\n",
    "         validation_split=0.3,\n",
    "         callbacks=[cp, es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 보충자료\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=[32, 16], \n",
    "                   activation='relu',\n",
    "                   alpha=0.01,\n",
    "                   solver='adam',\n",
    "                   early_stopping=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=[32, 16], learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7149532710280374"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, mlp.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
