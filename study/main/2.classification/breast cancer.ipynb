{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 기본 library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "## model library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from keras import models, layers, optimizers\n",
    "## helper library\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "d = load_breast_cancer()\n",
    "\n",
    "data = pd.DataFrame(d.data, columns=d.feature_names)\n",
    "target = pd.DataFrame(d.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "for c in data.columns:\n",
    "    data[c] = std.fit_transform(data[c].values.reshape(-1, 1))\n",
    "    \n",
    "train_X, test_X, train_y, test_y = train_test_split(data, target, test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reset_index().drop('index', axis=1)\n",
    "train_y = train_y.reset_index().drop('index', axis=1)\n",
    "test_X = test_X.reset_index().drop('index', axis=1)\n",
    "test_y = test_y.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# km = KMeans(n_clusters=5).fit(train_X)\n",
    "# cl = pd.get_dummies(km.labels_, prefix='kmean')\n",
    "# train_X = pd.concat([train_X, cl], axis=1)\n",
    "\n",
    "# # km = KMeans(n_clusters=5).fit(test_X)\n",
    "# # cl = pd.get_dummies(km.labels_, prefix='kmean')\n",
    "# # test_X = pd.concat([test_X, cl], axis=1)\n",
    "\n",
    "# cl = pd.get_dummies(km.predict(test_X), prefix='kmean')\n",
    "# test_X = pd.concat([test_X, cl], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5).fit(train_X)\n",
    "tr_cl = pd.get_dummies(km.labels_, prefix='kmean')\n",
    "\n",
    "te_cl = pd.get_dummies(km.predict(test_X), prefix='kmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9875    , 0.975     , 0.95      , 0.98734177, 0.98734177])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, train_X, train_y, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, lr.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "input_layer = layers.Input(shape=((train_X.shape[1:])))\n",
    "\n",
    "l1 = layers.Dense(32 ,activation='relu')(input_layer)\n",
    "l1 = layers.Dropout(0.3)(l1)\n",
    "l2 = layers.Dense(32, activation='relu')(l1)\n",
    "\n",
    "out_layer = layers.Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "model = models.Model(input_layer, out_layer)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 278 samples, validate on 120 samples\n",
      "Epoch 1/300\n",
      "278/278 [==============================] - 0s 613us/step - loss: 0.7110 - acc: 0.4892 - val_loss: 0.5652 - val_acc: 0.7667\n",
      "Epoch 2/300\n",
      "278/278 [==============================] - 0s 125us/step - loss: 0.5352 - acc: 0.7914 - val_loss: 0.4371 - val_acc: 0.9250\n",
      "Epoch 3/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.4270 - acc: 0.8849 - val_loss: 0.3469 - val_acc: 0.9417\n",
      "Epoch 4/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.3461 - acc: 0.9353 - val_loss: 0.2770 - val_acc: 0.9500\n",
      "Epoch 5/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.2764 - acc: 0.9281 - val_loss: 0.2245 - val_acc: 0.9500\n",
      "Epoch 6/300\n",
      "278/278 [==============================] - 0s 118us/step - loss: 0.2312 - acc: 0.9496 - val_loss: 0.1851 - val_acc: 0.9583\n",
      "Epoch 7/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.2110 - acc: 0.9460 - val_loss: 0.1555 - val_acc: 0.9750\n",
      "Epoch 8/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.1874 - acc: 0.9640 - val_loss: 0.1340 - val_acc: 0.9833\n",
      "Epoch 9/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.1550 - acc: 0.9568 - val_loss: 0.1171 - val_acc: 0.9833\n",
      "Epoch 10/300\n",
      "278/278 [==============================] - 0s 143us/step - loss: 0.1533 - acc: 0.9676 - val_loss: 0.1047 - val_acc: 0.9833\n",
      "Epoch 11/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.1272 - acc: 0.9676 - val_loss: 0.0942 - val_acc: 0.9833\n",
      "Epoch 12/300\n",
      "278/278 [==============================] - 0s 118us/step - loss: 0.1202 - acc: 0.9640 - val_loss: 0.0859 - val_acc: 0.9917\n",
      "Epoch 13/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0999 - acc: 0.9712 - val_loss: 0.0793 - val_acc: 0.9917\n",
      "Epoch 14/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.1096 - acc: 0.9712 - val_loss: 0.0740 - val_acc: 0.9917\n",
      "Epoch 15/300\n",
      "278/278 [==============================] - 0s 143us/step - loss: 0.0938 - acc: 0.9748 - val_loss: 0.0691 - val_acc: 0.9917\n",
      "Epoch 16/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0870 - acc: 0.9784 - val_loss: 0.0656 - val_acc: 0.9917\n",
      "Epoch 17/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.1026 - acc: 0.9712 - val_loss: 0.0622 - val_acc: 0.9917\n",
      "Epoch 18/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0882 - acc: 0.9820 - val_loss: 0.0605 - val_acc: 0.9917\n",
      "Epoch 19/300\n",
      "278/278 [==============================] - 0s 165us/step - loss: 0.0823 - acc: 0.9748 - val_loss: 0.0579 - val_acc: 0.9917\n",
      "Epoch 20/300\n",
      "278/278 [==============================] - 0s 144us/step - loss: 0.0837 - acc: 0.9712 - val_loss: 0.0563 - val_acc: 0.9917\n",
      "Epoch 21/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0793 - acc: 0.9820 - val_loss: 0.0544 - val_acc: 0.9917\n",
      "Epoch 22/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0773 - acc: 0.9748 - val_loss: 0.0527 - val_acc: 0.9917\n",
      "Epoch 23/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0776 - acc: 0.9784 - val_loss: 0.0509 - val_acc: 0.9917\n",
      "Epoch 24/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0792 - acc: 0.9712 - val_loss: 0.0495 - val_acc: 0.9833\n",
      "Epoch 25/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0728 - acc: 0.9784 - val_loss: 0.0484 - val_acc: 0.9833\n",
      "Epoch 26/300\n",
      "278/278 [==============================] - 0s 125us/step - loss: 0.0672 - acc: 0.9820 - val_loss: 0.0472 - val_acc: 0.9833\n",
      "Epoch 27/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0770 - acc: 0.9820 - val_loss: 0.0459 - val_acc: 0.9833\n",
      "Epoch 28/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0635 - acc: 0.9820 - val_loss: 0.0446 - val_acc: 0.9833\n",
      "Epoch 29/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0648 - acc: 0.9820 - val_loss: 0.0440 - val_acc: 0.9833\n",
      "Epoch 30/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0629 - acc: 0.9784 - val_loss: 0.0429 - val_acc: 0.9833\n",
      "Epoch 31/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0653 - acc: 0.9820 - val_loss: 0.0416 - val_acc: 0.9833\n",
      "Epoch 32/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0573 - acc: 0.9784 - val_loss: 0.0412 - val_acc: 0.9833\n",
      "Epoch 33/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0551 - acc: 0.9856 - val_loss: 0.0407 - val_acc: 0.9833\n",
      "Epoch 34/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0592 - acc: 0.9784 - val_loss: 0.0402 - val_acc: 0.9833\n",
      "Epoch 35/300\n",
      "278/278 [==============================] - 0s 140us/step - loss: 0.0625 - acc: 0.9820 - val_loss: 0.0404 - val_acc: 0.9833\n",
      "Epoch 36/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0593 - acc: 0.9784 - val_loss: 0.0402 - val_acc: 0.9833\n",
      "Epoch 37/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0557 - acc: 0.9820 - val_loss: 0.0398 - val_acc: 0.9833\n",
      "Epoch 38/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0556 - acc: 0.9784 - val_loss: 0.0394 - val_acc: 0.9917\n",
      "Epoch 39/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0520 - acc: 0.9748 - val_loss: 0.0392 - val_acc: 0.9917\n",
      "Epoch 40/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0560 - acc: 0.9856 - val_loss: 0.0389 - val_acc: 0.9917\n",
      "Epoch 41/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0492 - acc: 0.9856 - val_loss: 0.0386 - val_acc: 0.9917\n",
      "Epoch 42/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0555 - acc: 0.9820 - val_loss: 0.0385 - val_acc: 0.9917\n",
      "Epoch 43/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0499 - acc: 0.9856 - val_loss: 0.0376 - val_acc: 0.9917\n",
      "Epoch 44/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.0528 - acc: 0.9856 - val_loss: 0.0371 - val_acc: 0.9917\n",
      "Epoch 45/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.0433 - acc: 0.9820 - val_loss: 0.0368 - val_acc: 0.9917\n",
      "Epoch 46/300\n",
      "278/278 [==============================] - 0s 118us/step - loss: 0.0377 - acc: 0.9856 - val_loss: 0.0359 - val_acc: 0.9917\n",
      "Epoch 47/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0382 - acc: 0.9820 - val_loss: 0.0356 - val_acc: 0.9917\n",
      "Epoch 48/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0431 - acc: 0.9856 - val_loss: 0.0365 - val_acc: 0.9917\n",
      "Epoch 49/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0423 - acc: 0.9856 - val_loss: 0.0373 - val_acc: 0.9917\n",
      "Epoch 50/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0423 - acc: 0.9820 - val_loss: 0.0378 - val_acc: 0.9917\n",
      "Epoch 51/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0342 - acc: 0.9928 - val_loss: 0.0369 - val_acc: 0.9917\n",
      "Epoch 52/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0363 - acc: 0.9928 - val_loss: 0.0357 - val_acc: 0.9917\n",
      "Epoch 53/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0512 - acc: 0.9748 - val_loss: 0.0346 - val_acc: 0.9917\n",
      "Epoch 54/300\n",
      "278/278 [==============================] - 0s 140us/step - loss: 0.0422 - acc: 0.9856 - val_loss: 0.0341 - val_acc: 0.9917\n",
      "Epoch 55/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0533 - acc: 0.9748 - val_loss: 0.0340 - val_acc: 0.9917\n",
      "Epoch 56/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.0341 - acc: 0.9892 - val_loss: 0.0337 - val_acc: 0.9917\n",
      "Epoch 57/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0408 - acc: 0.9820 - val_loss: 0.0340 - val_acc: 0.9917\n",
      "Epoch 58/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0443 - acc: 0.9856 - val_loss: 0.0332 - val_acc: 0.9917\n",
      "Epoch 59/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0375 - acc: 0.9856 - val_loss: 0.0329 - val_acc: 0.9917\n",
      "Epoch 60/300\n",
      "278/278 [==============================] - 0s 161us/step - loss: 0.0569 - acc: 0.9784 - val_loss: 0.0329 - val_acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "278/278 [==============================] - 0s 169us/step - loss: 0.0313 - acc: 0.9928 - val_loss: 0.0331 - val_acc: 0.9917\n",
      "Epoch 62/300\n",
      "278/278 [==============================] - 0s 176us/step - loss: 0.0319 - acc: 0.9892 - val_loss: 0.0328 - val_acc: 0.9917\n",
      "Epoch 63/300\n",
      "278/278 [==============================] - 0s 179us/step - loss: 0.0313 - acc: 0.9892 - val_loss: 0.0317 - val_acc: 0.9917\n",
      "Epoch 64/300\n",
      "278/278 [==============================] - 0s 179us/step - loss: 0.0359 - acc: 0.9892 - val_loss: 0.0312 - val_acc: 0.9917\n",
      "Epoch 65/300\n",
      "278/278 [==============================] - 0s 165us/step - loss: 0.0255 - acc: 0.9892 - val_loss: 0.0312 - val_acc: 0.9917\n",
      "Epoch 66/300\n",
      "278/278 [==============================] - 0s 140us/step - loss: 0.0239 - acc: 0.9964 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 67/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.0318 - acc: 0.9928 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 68/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0246 - acc: 0.9964 - val_loss: 0.0313 - val_acc: 0.9917\n",
      "Epoch 69/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0284 - acc: 0.9856 - val_loss: 0.0305 - val_acc: 0.9917\n",
      "Epoch 70/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0331 - acc: 0.9820 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 71/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0297 - acc: 0.9892 - val_loss: 0.0295 - val_acc: 0.9917\n",
      "Epoch 72/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0290 - acc: 0.9928 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 73/300\n",
      "278/278 [==============================] - 0s 118us/step - loss: 0.0275 - acc: 0.9928 - val_loss: 0.0293 - val_acc: 0.9917\n",
      "Epoch 74/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0260 - acc: 0.9964 - val_loss: 0.0284 - val_acc: 0.9917\n",
      "Epoch 75/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0274 - acc: 0.9928 - val_loss: 0.0290 - val_acc: 0.9917\n",
      "Epoch 76/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0301 - acc: 0.9928 - val_loss: 0.0292 - val_acc: 0.9917\n",
      "Epoch 77/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0263 - acc: 0.9892 - val_loss: 0.0290 - val_acc: 0.9917\n",
      "Epoch 78/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0255 - acc: 0.9928 - val_loss: 0.0292 - val_acc: 0.9917\n",
      "Epoch 79/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0360 - acc: 0.9820 - val_loss: 0.0297 - val_acc: 0.9917\n",
      "Epoch 80/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0208 - acc: 0.9964 - val_loss: 0.0290 - val_acc: 0.9917\n",
      "Epoch 81/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0332 - acc: 0.9856 - val_loss: 0.0288 - val_acc: 0.9917\n",
      "Epoch 82/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0242 - acc: 0.9964 - val_loss: 0.0285 - val_acc: 0.9917\n",
      "Epoch 83/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0306 - acc: 0.9892 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 84/300\n",
      "278/278 [==============================] - 0s 140us/step - loss: 0.0296 - acc: 0.9892 - val_loss: 0.0279 - val_acc: 0.9917\n",
      "Epoch 85/300\n",
      "278/278 [==============================] - 0s 172us/step - loss: 0.0263 - acc: 0.9928 - val_loss: 0.0288 - val_acc: 0.9917\n",
      "Epoch 86/300\n",
      "278/278 [==============================] - 0s 179us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9917\n",
      "Epoch 87/300\n",
      "278/278 [==============================] - 0s 187us/step - loss: 0.0189 - acc: 0.9964 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 88/300\n",
      "278/278 [==============================] - 0s 172us/step - loss: 0.0240 - acc: 0.9928 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 89/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0261 - acc: 0.9892 - val_loss: 0.0276 - val_acc: 0.9917\n",
      "Epoch 90/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0182 - acc: 0.9928 - val_loss: 0.0269 - val_acc: 0.9917\n",
      "Epoch 91/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0206 - acc: 0.9928 - val_loss: 0.0263 - val_acc: 0.9917\n",
      "Epoch 92/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0209 - acc: 0.9964 - val_loss: 0.0260 - val_acc: 0.9917\n",
      "Epoch 93/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0192 - acc: 0.9964 - val_loss: 0.0260 - val_acc: 0.9917\n",
      "Epoch 94/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.0193 - acc: 0.9928 - val_loss: 0.0261 - val_acc: 0.9917\n",
      "Epoch 95/300\n",
      "278/278 [==============================] - 0s 118us/step - loss: 0.0191 - acc: 0.9928 - val_loss: 0.0250 - val_acc: 0.9917\n",
      "Epoch 96/300\n",
      "278/278 [==============================] - 0s 115us/step - loss: 0.0157 - acc: 0.9964 - val_loss: 0.0245 - val_acc: 0.9917\n",
      "Epoch 97/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9917\n",
      "Epoch 98/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0165 - acc: 0.9928 - val_loss: 0.0240 - val_acc: 0.9917\n",
      "Epoch 99/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0183 - acc: 0.9928 - val_loss: 0.0253 - val_acc: 0.9917\n",
      "Epoch 100/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0303 - acc: 0.9892 - val_loss: 0.0264 - val_acc: 0.9917\n",
      "Epoch 101/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0258 - acc: 0.9856 - val_loss: 0.0268 - val_acc: 0.9917\n",
      "Epoch 102/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0322 - acc: 0.9820 - val_loss: 0.0275 - val_acc: 0.9917\n",
      "Epoch 103/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0173 - acc: 0.9964 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 104/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0199 - acc: 0.9928 - val_loss: 0.0315 - val_acc: 0.9833\n",
      "Epoch 105/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0171 - acc: 0.9928 - val_loss: 0.0304 - val_acc: 0.9917\n",
      "Epoch 106/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0291 - val_acc: 0.9917\n",
      "Epoch 107/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0183 - acc: 0.9928 - val_loss: 0.0280 - val_acc: 0.9917\n",
      "Epoch 108/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0192 - acc: 0.9964 - val_loss: 0.0279 - val_acc: 0.9917\n",
      "Epoch 109/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0193 - acc: 0.9928 - val_loss: 0.0285 - val_acc: 0.9917\n",
      "Epoch 110/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0297 - acc: 0.9820 - val_loss: 0.0296 - val_acc: 0.9917\n",
      "Epoch 111/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0259 - acc: 0.9856 - val_loss: 0.0290 - val_acc: 0.9917\n",
      "Epoch 112/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0202 - acc: 0.9964 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 113/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0171 - acc: 0.9964 - val_loss: 0.0292 - val_acc: 0.9917\n",
      "Epoch 114/300\n",
      "278/278 [==============================] - 0s 133us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9917\n",
      "Epoch 115/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0216 - acc: 0.9928 - val_loss: 0.0288 - val_acc: 0.9917\n",
      "Epoch 116/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0125 - acc: 0.9964 - val_loss: 0.0286 - val_acc: 0.9917\n",
      "Epoch 117/300\n",
      "278/278 [==============================] - 0s 136us/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0288 - val_acc: 0.9917\n",
      "Epoch 118/300\n",
      "278/278 [==============================] - 0s 137us/step - loss: 0.0134 - acc: 0.9964 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 119/300\n",
      "278/278 [==============================] - 0s 124us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.0303 - val_acc: 0.9917\n",
      "Epoch 120/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0154 - acc: 0.9928 - val_loss: 0.0308 - val_acc: 0.9917\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 0s 129us/step - loss: 0.0151 - acc: 0.9928 - val_loss: 0.0308 - val_acc: 0.9917\n",
      "Epoch 122/300\n",
      "278/278 [==============================] - 0s 129us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 0.9917\n",
      "Epoch 123/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 0.0296 - val_acc: 0.9917\n",
      "Epoch 124/300\n",
      "278/278 [==============================] - 0s 117us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0292 - val_acc: 0.9917\n",
      "Epoch 125/300\n",
      "278/278 [==============================] - 0s 122us/step - loss: 0.0242 - acc: 0.9964 - val_loss: 0.0297 - val_acc: 0.9917\n",
      "Epoch 126/300\n",
      "278/278 [==============================] - 0s 126us/step - loss: 0.0180 - acc: 0.9928 - val_loss: 0.0297 - val_acc: 0.9917\n",
      "Epoch 127/300\n",
      "278/278 [==============================] - 0s 125us/step - loss: 0.0197 - acc: 0.9928 - val_loss: 0.0299 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20524f00dc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, \n",
    "         epochs=300,\n",
    "         validation_split=0.3,\n",
    "         callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 70us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13185035429992958, 0.9649122953414917]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf', random_state=0).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(svc, train_X, train_y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
