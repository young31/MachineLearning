{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter\n",
    "\n",
    "- 복잡한 모형일 수록 결정해야 할 파라미터값이 많아짐\n",
    "- 기본적으로 후보들을 선정해 두고 결과값을 보고 방향성을 결정함\n",
    "- 이를 편하게 해 줄 라이브러리를 소개하도록 함\n",
    "    - 책에서 소개: GridSearchCV\n",
    "    - kaggle에서 본 방법: BayseOpt\n",
    "    \n",
    "# GridSearchCV\n",
    "- 이름에서 알 수 있듯이 grid로 파라미터를 두고 CV도 한번에 하게 해줌\n",
    "- 절차:\n",
    "    1. grdi_param 설정\n",
    "    2. k-fold CV를 위한 k 설정\n",
    "    3. 모형선정 및 customize할 값 적용  \n",
    "\\#### 현재 early_stopping이 적용되지 않아 파악중..\n",
    "\n",
    "# Bayesian Optimization\n",
    "- 이 패키지는 파라미터를 grid로 설정하는 것이 아니라 범위로 설정\n",
    "- 범위내에 값들을 랜덤하게 돌아줌\n",
    "- tree를 위한 패키지가 아니라 general purpose목적임\n",
    "    - 따라서 직접 설정해줘야 할 부분이 많음(CV전략 등)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('../1.clustering/titanic.csv')\n",
    "\n",
    "target = data['Survived']\n",
    "data = data.drop(['PassengerId', 'Survived'], axis=1)\n",
    "\n",
    "def sex(a):\n",
    "    if a == 'male':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def emb(a):\n",
    "    if a == 'S':\n",
    "        return 0\n",
    "    elif a == 'Q':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "data['Sex'] = data['Sex'].map(sex)\n",
    "data['Embarked'] = data['Embarked'].map(emb)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, target, test_size=0.3, random_state=2019, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'tree_method': 'hist',\n",
    "#     'random_state': 0,\n",
    "#     'n_jobs': -1,\n",
    "# #     'max_depth': 9\n",
    "# }\n",
    "# grid_params= {\n",
    "#     'n_estimators': [10, 20, 50],\n",
    "#     'max_depth': [3, 6, 9, 12],\n",
    "#     'subsample': [0.7, 0.8, 0.9],\n",
    "#     'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "# }\n",
    "\n",
    "params= {\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'auc',\n",
    "    'random_state': 0,\n",
    "}\n",
    "\n",
    "grid_params= {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_depth': [6, 9, 12],\n",
    "    'min_child_samples': [10, 20, 50], \n",
    "    'num_leaves': [20, 30, 40], \n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "# clf = XGBClassifier(**params)\n",
    "clf = LGBMClassifier(**params)\n",
    "\n",
    "grid_clf = GridSearchCV(clf, grid_params,verbose=1, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2187 out of 2187 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting='gbdt', boosting_type='gbdt',\n",
       "                                      class_weight=None, colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      metric='auc', min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=0, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.7, 0.8, 0.9],\n",
       "                         'max_depth': [6, 9, 12],\n",
       "                         'min_child_samples': [10, 20, 50],\n",
       "                         'n_estimators': [10, 20, 50],\n",
       "                         'num_leaves': [20, 30, 40],\n",
       "                         'subsample': [0.7, 0.8, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_params = {\n",
    "#     'eval_set': [[test_X, test_y]],\n",
    "#     'early_stopping_rounds': 100, \n",
    "#     'eval_metric': 'mae', \n",
    "# }\n",
    "grid_clf.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8353413654618475\n",
      "LGBMClassifier(boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "               colsample_bytree=0.8, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=6, metric='auc', min_child_samples=10,\n",
      "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=20,\n",
      "               n_jobs=-1, num_leaves=20, objective=None, random_state=0,\n",
      "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=0.7,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_score_)\n",
    "print(grid_clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7897196261682243\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_y, grid_clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = train_X.reset_index()\n",
    "# train_y = train_y.reset_index()\n",
    "# test_X = test_X.reset_index()\n",
    "# test_y = test_y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from lightgbm import LGBMClassifier\n",
    "bounds_LGB = {\n",
    "#     'n_estimators': (10, 100),\n",
    "    'max_depth': (3, 15),\n",
    "    'min_child_samples': (5, 30),\n",
    "    'num_leaves': (10, 50),\n",
    "    'subsample': (0.5, 0.9),\n",
    "    'colsample_bytree': (0.5, 0.9),\n",
    "}\n",
    "\n",
    "init_points = 10\n",
    "n_iter = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "#     n_estimators,\n",
    "    max_depth,\n",
    "    min_child_samples,\n",
    "    num_leaves,\n",
    "    subsample,\n",
    "    colsample_bytree\n",
    "):\n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "#     n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    min_child_samples = int(min_child_samples)\n",
    "    num_leaves = int(num_leaves)\n",
    "\n",
    "#     assert type(num_leaves) == int\n",
    "#     assert type(max_depth) == int\n",
    "    \n",
    "\n",
    "    params = {\n",
    "        'boosting': 'gbdt',\n",
    "        'n_estimators': 400,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': max_depth,\n",
    "        'min_child_samples': min_child_samples,\n",
    "        'num_leaves': num_leaves,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'random_state': 0,\n",
    "    }    \n",
    "    \n",
    "    ## set clf options\n",
    "    clf = LGBMClassifier(**params).fit(train_X, train_y, early_stopping_rounds=100,eval_set=[(test_X, test_y)], eval_metric='auc', verbose=0)\n",
    "    \n",
    "    score = accuracy_score(test_y, clf.predict(test_X))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | max_depth | min_ch... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.7584  \u001b[0m | \u001b[0m 8.251   \u001b[0m | \u001b[0m 27.29   \u001b[0m | \u001b[0m 48.55   \u001b[0m | \u001b[0m 0.6534  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8037  \u001b[0m | \u001b[95m 0.8167  \u001b[0m | \u001b[95m 9.347   \u001b[0m | \u001b[95m 19.2    \u001b[0m | \u001b[95m 47.02   \u001b[0m | \u001b[95m 0.5284  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.5349  \u001b[0m | \u001b[0m 3.243   \u001b[0m | \u001b[0m 25.82   \u001b[0m | \u001b[0m 41.13   \u001b[0m | \u001b[0m 0.848   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.8914  \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 16.54   \u001b[0m | \u001b[0m 41.22   \u001b[0m | \u001b[0m 0.5473  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 0.756   \u001b[0m | \u001b[0m 4.72    \u001b[0m | \u001b[0m 28.62   \u001b[0m | \u001b[0m 30.87   \u001b[0m | \u001b[0m 0.6659  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.6058  \u001b[0m | \u001b[0m 12.29   \u001b[0m | \u001b[0m 16.4    \u001b[0m | \u001b[0m 32.74   \u001b[0m | \u001b[0m 0.5075  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8084  \u001b[0m | \u001b[95m 0.7471  \u001b[0m | \u001b[95m 10.35   \u001b[0m | \u001b[95m 20.42   \u001b[0m | \u001b[95m 47.75   \u001b[0m | \u001b[95m 0.7727  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.6438  \u001b[0m | \u001b[0m 8.244   \u001b[0m | \u001b[0m 22.44   \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 0.7667  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.7683  \u001b[0m | \u001b[0m 5.525   \u001b[0m | \u001b[0m 8.223   \u001b[0m | \u001b[0m 22.62   \u001b[0m | \u001b[0m 0.6455  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 8.263   \u001b[0m | \u001b[0m 29.71   \u001b[0m | \u001b[0m 14.08   \u001b[0m | \u001b[0m 0.5836  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.5645  \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 11.33   \u001b[0m | \u001b[0m 28.65   \u001b[0m | \u001b[0m 0.5978  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8084  \u001b[0m | \u001b[0m 0.5636  \u001b[0m | \u001b[0m 4.325   \u001b[0m | \u001b[0m 21.41   \u001b[0m | \u001b[0m 15.53   \u001b[0m | \u001b[0m 0.5786  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.6475  \u001b[0m | \u001b[0m 12.85   \u001b[0m | \u001b[0m 7.428   \u001b[0m | \u001b[0m 43.52   \u001b[0m | \u001b[0m 0.5384  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.8906  \u001b[0m | \u001b[0m 8.624   \u001b[0m | \u001b[0m 29.42   \u001b[0m | \u001b[0m 34.19   \u001b[0m | \u001b[0m 0.7957  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.5157  \u001b[0m | \u001b[0m 6.394   \u001b[0m | \u001b[0m 8.005   \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 0.5475  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.6272  \u001b[0m | \u001b[0m 7.971   \u001b[0m | \u001b[0m 6.604   \u001b[0m | \u001b[0m 37.7    \u001b[0m | \u001b[0m 0.7266  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7804  \u001b[0m | \u001b[0m 0.6062  \u001b[0m | \u001b[0m 9.279   \u001b[0m | \u001b[0m 7.349   \u001b[0m | \u001b[0m 33.04   \u001b[0m | \u001b[0m 0.8717  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.6274  \u001b[0m | \u001b[0m 11.01   \u001b[0m | \u001b[0m 8.295   \u001b[0m | \u001b[0m 38.65   \u001b[0m | \u001b[0m 0.6158  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7897  \u001b[0m | \u001b[0m 0.5733  \u001b[0m | \u001b[0m 10.04   \u001b[0m | \u001b[0m 5.503   \u001b[0m | \u001b[0m 43.16   \u001b[0m | \u001b[0m 0.5019  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6168  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7897  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 28.69   \u001b[0m | \u001b[0m 22.82   \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m 0.8271  \u001b[0m | \u001b[95m 0.5118  \u001b[0m | \u001b[95m 3.331   \u001b[0m | \u001b[95m 10.99   \u001b[0m | \u001b[95m 49.79   \u001b[0m | \u001b[95m 0.8126  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7664  \u001b[0m | \u001b[0m 0.5422  \u001b[0m | \u001b[0m 14.66   \u001b[0m | \u001b[0m 9.683   \u001b[0m | \u001b[0m 49.9    \u001b[0m | \u001b[0m 0.5318  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 16.86   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.8493  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 0.6551  \u001b[0m | \u001b[0m 3.026   \u001b[0m | \u001b[0m 17.47   \u001b[0m | \u001b[0m 49.94   \u001b[0m | \u001b[0m 0.8866  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8084  \u001b[0m | \u001b[0m 0.5271  \u001b[0m | \u001b[0m 3.118   \u001b[0m | \u001b[0m 15.82   \u001b[0m | \u001b[0m 29.36   \u001b[0m | \u001b[0m 0.8909  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 41.35   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 0.5018  \u001b[0m | \u001b[0m 8.686   \u001b[0m | \u001b[0m 21.71   \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 0.8678  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7804  \u001b[0m | \u001b[0m 0.5186  \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 28.94   \u001b[0m | \u001b[0m 10.42   \u001b[0m | \u001b[0m 0.6756  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 29.99   \u001b[0m | \u001b[0m 38.97   \u001b[0m | \u001b[0m 0.7429  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 24.39   \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8271  \u001b[0m | \u001b[0m 0.521   \u001b[0m | \u001b[0m 3.222   \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 15.09   \u001b[0m | \u001b[0m 0.8915  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.5126  \u001b[0m | \u001b[0m 4.071   \u001b[0m | \u001b[0m 12.73   \u001b[0m | \u001b[0m 43.92   \u001b[0m | \u001b[0m 0.8933  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7991  \u001b[0m | \u001b[0m 0.508   \u001b[0m | \u001b[0m 3.11    \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 18.37   \u001b[0m | \u001b[0m 0.534   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.5088  \u001b[0m | \u001b[0m 3.113   \u001b[0m | \u001b[0m 27.94   \u001b[0m | \u001b[0m 10.31   \u001b[0m | \u001b[0m 0.779   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.8084  \u001b[0m | \u001b[0m 0.8844  \u001b[0m | \u001b[0m 3.065   \u001b[0m | \u001b[0m 5.309   \u001b[0m | \u001b[0m 16.08   \u001b[0m | \u001b[0m 0.7281  \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=init_points, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
