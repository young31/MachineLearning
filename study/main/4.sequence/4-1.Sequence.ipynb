{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence data\n",
    "\n",
    "- 시퀀스 데이터는 순서가 있고 이것이 중요한 데이터로\n",
    "- 자연어, 유전, 시계열 자료 등이 이런 자료형에 속한다.\n",
    "  \n",
    "    \n",
    "- 모델링시 중요한 점은 이 순서의 의미를 반영해주어야 한다는 점이고\n",
    "- 가장 각광받는 RNN과 CNN에 대해서 소개한다.\n",
    "\n",
    "## RNN \n",
    "\n",
    "- 재귀적/순한 신경망을 뜻하며 데이터를 다룰 시에 히든 노드가 다음 히든 노드에 영향을 주는 모형\n",
    "- 마찬가지로 역전파 알고리즘을 이용하여 업데이트하나 생각보다 코드 구현이 쉽지 않음(BPTT)\n",
    "- 심플한 RNN보다는 LSTM이 엄청난 각광을 받았고 한국교수가 제안한 GRU도 유명함\n",
    "- 코드 구성시 얼만큼의 시간을 고려할지를 인풋으로 넣어줘야함\n",
    "    - function만들어서 가능\n",
    "    - 자료형을 변형시켜서 가능\n",
    "    \n",
    "\n",
    "## CNN\n",
    "\n",
    "- 본래 이미지를 대상으로하는 분석에서 엄청난 획을 그은 분석 기법\n",
    "- 이미지관련 분석은 CNN전과 후로 나눌 수 있을 듯\n",
    "- 시퀀스데이터에서도 비슷한 개념을 활요하여 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "d = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = (d.data-np.mean(d.data))/np.std(d.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "lags = 10\n",
    "\n",
    "for i in range(lags, len(temp_data)):\n",
    "    temp = temp_data[max(0, i-lags):i]\n",
    "    data.append(temp)\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_layer = layers.Input(shape=(lags, d.data.shape[1]))\n",
    "\n",
    "l11 = layers.SimpleRNN(32, return_sequences=False )(input_layer)\n",
    "l12 = layers.LSTM(32, return_sequences=False)(input_layer)\n",
    "\n",
    "l2 = layers.concatenate([l11, l12])\n",
    "\n",
    "l3 = layers.Dense(32, activation='relu')(l2)\n",
    "\n",
    "out_layer = layers.Dense(1, activation='linear')(l3)\n",
    "\n",
    "model = models.Model(input_layer, out_layer)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'mse',\n",
    "             metrics=['mae']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 13)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        (None, 32)           1472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           5888        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           simple_rnn_1[0][0]               \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,473\n",
      "Trainable params: 9,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=20, monitor='val_loss', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 347 samples, validate on 149 samples\n",
      "Epoch 1/400\n",
      "347/347 [==============================] - 1s 1ms/step - loss: 621.6038 - mae: 23.4448 - val_loss: 271.0958 - val_mae: 14.3012\n",
      "Epoch 2/400\n",
      "347/347 [==============================] - 0s 217us/step - loss: 523.4302 - mae: 21.2768 - val_loss: 217.0744 - val_mae: 12.3091\n",
      "Epoch 3/400\n",
      "347/347 [==============================] - 0s 210us/step - loss: 431.8189 - mae: 18.9950 - val_loss: 160.2973 - val_mae: 9.8632\n",
      "Epoch 4/400\n",
      "347/347 [==============================] - 0s 224us/step - loss: 335.4144 - mae: 16.2233 - val_loss: 108.2965 - val_mae: 7.2378\n",
      "Epoch 5/400\n",
      "347/347 [==============================] - 0s 213us/step - loss: 240.4238 - mae: 12.9947 - val_loss: 75.0190 - val_mae: 5.6117\n",
      "Epoch 6/400\n",
      "347/347 [==============================] - 0s 198us/step - loss: 162.9591 - mae: 9.7059 - val_loss: 66.7593 - val_mae: 5.7422\n",
      "Epoch 7/400\n",
      "347/347 [==============================] - 0s 187us/step - loss: 109.5975 - mae: 7.1459 - val_loss: 82.0257 - val_mae: 6.9244\n",
      "Epoch 8/400\n",
      "347/347 [==============================] - 0s 204us/step - loss: 80.9653 - mae: 6.0457 - val_loss: 106.5822 - val_mae: 8.5034\n",
      "Epoch 9/400\n",
      "347/347 [==============================] - 0s 196us/step - loss: 73.2148 - mae: 6.0857 - val_loss: 128.7604 - val_mae: 9.7915\n",
      "Epoch 10/400\n",
      "347/347 [==============================] - 0s 215us/step - loss: 71.5987 - mae: 6.3666 - val_loss: 139.1846 - val_mae: 10.3405\n",
      "Epoch 11/400\n",
      "347/347 [==============================] - 0s 218us/step - loss: 71.8733 - mae: 6.5354 - val_loss: 141.8897 - val_mae: 10.4790\n",
      "Epoch 12/400\n",
      "347/347 [==============================] - 0s 193us/step - loss: 71.6970 - mae: 6.4855 - val_loss: 137.0282 - val_mae: 10.2292\n",
      "Epoch 13/400\n",
      "347/347 [==============================] - 0s 175us/step - loss: 71.5227 - mae: 6.4153 - val_loss: 134.4965 - val_mae: 10.0960\n",
      "Epoch 14/400\n",
      "347/347 [==============================] - 0s 178us/step - loss: 71.5162 - mae: 6.3650 - val_loss: 132.0950 - val_mae: 9.9711\n",
      "Epoch 15/400\n",
      "347/347 [==============================] - 0s 187us/step - loss: 71.5567 - mae: 6.3211 - val_loss: 131.0088 - val_mae: 9.9142\n",
      "Epoch 16/400\n",
      "347/347 [==============================] - 0s 175us/step - loss: 71.5399 - mae: 6.3389 - val_loss: 132.3334 - val_mae: 9.9848\n",
      "Epoch 17/400\n",
      "347/347 [==============================] - 0s 181us/step - loss: 71.5148 - mae: 6.3448 - val_loss: 132.8126 - val_mae: 10.0106\n",
      "Epoch 18/400\n",
      "347/347 [==============================] - 0s 181us/step - loss: 71.5499 - mae: 6.3595 - val_loss: 131.9024 - val_mae: 9.9634\n",
      "Epoch 19/400\n",
      "347/347 [==============================] - 0s 181us/step - loss: 71.4954 - mae: 6.3607 - val_loss: 133.5163 - val_mae: 10.0486\n",
      "Epoch 20/400\n",
      "347/347 [==============================] - 0s 178us/step - loss: 71.5184 - mae: 6.3899 - val_loss: 132.9612 - val_mae: 10.0204\n",
      "Epoch 21/400\n",
      "347/347 [==============================] - 0s 178us/step - loss: 71.5375 - mae: 6.3933 - val_loss: 133.5451 - val_mae: 10.0516\n",
      "Epoch 22/400\n",
      "347/347 [==============================] - 0s 181us/step - loss: 71.5881 - mae: 6.3459 - val_loss: 129.0993 - val_mae: 9.8173\n",
      "Epoch 23/400\n",
      "347/347 [==============================] - 0s 181us/step - loss: 71.5781 - mae: 6.3545 - val_loss: 132.5340 - val_mae: 10.0006\n",
      "Epoch 24/400\n",
      "347/347 [==============================] - 0s 181us/step - loss: 71.4788 - mae: 6.3971 - val_loss: 132.7769 - val_mae: 10.0141\n",
      "Epoch 25/400\n",
      "347/347 [==============================] - 0s 175us/step - loss: 71.4345 - mae: 6.3645 - val_loss: 131.0961 - val_mae: 9.9269\n",
      "Epoch 26/400\n",
      "347/347 [==============================] - 0s 178us/step - loss: 71.3689 - mae: 6.3414 - val_loss: 129.1967 - val_mae: 9.8268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13326ab1648>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, d.target[10:],\n",
    "         epochs=400,\n",
    "         validation_split=0.3,\n",
    "         callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data, d.target[lags:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_layer = layers.Input(shape=(lags, d.data.shape[1]))\n",
    "\n",
    "x1 = layers.Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x1 = layers.MaxPooling1D()(x1)\n",
    "\n",
    "x2 = layers.Conv1D(filters=16, kernel_size=5, padding='same')(input_layer)\n",
    "x2 = layers.MaxPooling1D()(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "out_layer = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = models.Model(input_layer, out_layer)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'mse',\n",
    "             metrics=['mae']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.reshape(data, (496, 10, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 347 samples, validate on 149 samples\n",
      "Epoch 1/400\n",
      "347/347 [==============================] - 0s 426us/step - loss: 635.9276 - mae: 23.7645 - val_loss: 273.7583 - val_mae: 14.4208\n",
      "Epoch 2/400\n",
      "347/347 [==============================] - 0s 63us/step - loss: 519.0238 - mae: 21.0810 - val_loss: 177.9767 - val_mae: 10.6652\n",
      "Epoch 3/400\n",
      "347/347 [==============================] - 0s 63us/step - loss: 391.8508 - mae: 17.8494 - val_loss: 101.6320 - val_mae: 6.9895\n",
      "Epoch 4/400\n",
      "347/347 [==============================] - 0s 59us/step - loss: 256.3368 - mae: 13.4617 - val_loss: 65.3730 - val_mae: 5.5638\n",
      "Epoch 5/400\n",
      "347/347 [==============================] - 0s 61us/step - loss: 136.3793 - mae: 8.3722 - val_loss: 120.5859 - val_mae: 9.2711\n",
      "Epoch 6/400\n",
      "347/347 [==============================] - 0s 64us/step - loss: 79.3806 - mae: 6.3803 - val_loss: 234.7483 - val_mae: 14.2264\n",
      "Epoch 7/400\n",
      "347/347 [==============================] - 0s 56us/step - loss: 78.4466 - mae: 7.2048 - val_loss: 256.6180 - val_mae: 14.9848\n",
      "Epoch 8/400\n",
      "347/347 [==============================] - 0s 61us/step - loss: 76.2298 - mae: 6.8599 - val_loss: 199.5290 - val_mae: 12.9102\n",
      "Epoch 9/400\n",
      "347/347 [==============================] - 0s 60us/step - loss: 75.3846 - mae: 6.3953 - val_loss: 175.4120 - val_mae: 11.9184\n",
      "Epoch 10/400\n",
      "347/347 [==============================] - 0s 64us/step - loss: 74.5897 - mae: 6.3565 - val_loss: 188.6457 - val_mae: 12.4806\n",
      "Epoch 11/400\n",
      "347/347 [==============================] - 0s 63us/step - loss: 74.3085 - mae: 6.5540 - val_loss: 193.3927 - val_mae: 12.6775\n",
      "Epoch 12/400\n",
      "347/347 [==============================] - 0s 58us/step - loss: 74.0167 - mae: 6.5638 - val_loss: 183.5584 - val_mae: 12.2789\n",
      "Epoch 13/400\n",
      "347/347 [==============================] - 0s 63us/step - loss: 73.9751 - mae: 6.4329 - val_loss: 170.6784 - val_mae: 11.7294\n",
      "Epoch 14/400\n",
      "347/347 [==============================] - 0s 56us/step - loss: 73.6631 - mae: 6.3771 - val_loss: 168.5043 - val_mae: 11.6371\n",
      "Epoch 15/400\n",
      "347/347 [==============================] - 0s 59us/step - loss: 73.3220 - mae: 6.4487 - val_loss: 172.6505 - val_mae: 11.8246\n",
      "Epoch 16/400\n",
      "347/347 [==============================] - 0s 60us/step - loss: 73.1503 - mae: 6.4886 - val_loss: 167.7447 - val_mae: 11.6112\n",
      "Epoch 17/400\n",
      "347/347 [==============================] - 0s 57us/step - loss: 73.0151 - mae: 6.4507 - val_loss: 162.1213 - val_mae: 11.3596\n",
      "Epoch 18/400\n",
      "347/347 [==============================] - 0s 59us/step - loss: 72.9308 - mae: 6.3658 - val_loss: 150.1117 - val_mae: 10.8060\n",
      "Epoch 19/400\n",
      "347/347 [==============================] - 0s 55us/step - loss: 72.4665 - mae: 6.3685 - val_loss: 154.6110 - val_mae: 11.0206\n",
      "Epoch 20/400\n",
      "347/347 [==============================] - 0s 58us/step - loss: 72.3711 - mae: 6.4360 - val_loss: 148.1723 - val_mae: 10.7233\n",
      "Epoch 21/400\n",
      "347/347 [==============================] - 0s 60us/step - loss: 72.4426 - mae: 6.4870 - val_loss: 146.0422 - val_mae: 10.6262\n",
      "Epoch 22/400\n",
      "347/347 [==============================] - 0s 60us/step - loss: 72.0057 - mae: 6.3753 - val_loss: 135.1406 - val_mae: 10.0954\n",
      "Epoch 23/400\n",
      "347/347 [==============================] - 0s 60us/step - loss: 71.9386 - mae: 6.3418 - val_loss: 133.6783 - val_mae: 10.0240\n",
      "Epoch 24/400\n",
      "347/347 [==============================] - 0s 60us/step - loss: 71.6382 - mae: 6.3517 - val_loss: 132.3382 - val_mae: 9.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28a9b1c1748>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data2, d.target[lags:],\n",
    "         epochs=400,\n",
    "         validation_split=0.3,\n",
    "         callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[147.31325623296922, 9.047750473022461]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data, d.target[lags:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_layer = layers.Input(shape=(lags, d.data.shape[1]))\n",
    "\n",
    "x = layers.Conv1D(filters=32, kernel_size=3)(input_layer)\n",
    "x = layers.AveragePooling1D()(x)\n",
    "x = layers.Conv1D(filters=16, kernel_size=3)(x)\n",
    "x = layers.AveragePooling1D()(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.GRU(16, return_sequences=False))(x)\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "out_layer = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = models.Model(input_layer, out_layer)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'mse',\n",
    "             metrics=['mae']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 347 samples, validate on 149 samples\n",
      "Epoch 1/400\n",
      "347/347 [==============================] - 1s 2ms/step - loss: 666.2963 - mae: 24.3800 - val_loss: 300.8329 - val_mae: 15.2851\n",
      "Epoch 2/400\n",
      "347/347 [==============================] - 0s 111us/step - loss: 607.6659 - mae: 23.1532 - val_loss: 260.6671 - val_mae: 13.9020\n",
      "Epoch 3/400\n",
      "347/347 [==============================] - 0s 103us/step - loss: 544.8543 - mae: 21.7516 - val_loss: 222.5266 - val_mae: 12.4518\n",
      "Epoch 4/400\n",
      "347/347 [==============================] - 0s 106us/step - loss: 477.2533 - mae: 20.1269 - val_loss: 179.8298 - val_mae: 10.6327\n",
      "Epoch 5/400\n",
      "347/347 [==============================] - 0s 106us/step - loss: 398.9569 - mae: 18.0986 - val_loss: 138.1699 - val_mae: 8.6544\n",
      "Epoch 6/400\n",
      "347/347 [==============================] - 0s 105us/step - loss: 324.9789 - mae: 15.9031 - val_loss: 107.1475 - val_mae: 7.1256\n",
      "Epoch 7/400\n",
      "347/347 [==============================] - 0s 103us/step - loss: 259.5157 - mae: 13.6671 - val_loss: 83.0467 - val_mae: 5.9564\n",
      "Epoch 8/400\n",
      "347/347 [==============================] - 0s 118us/step - loss: 197.1598 - mae: 11.2417 - val_loss: 69.3705 - val_mae: 5.5769\n",
      "Epoch 9/400\n",
      "347/347 [==============================] - 0s 112us/step - loss: 149.2962 - mae: 9.1089 - val_loss: 68.0622 - val_mae: 5.8581\n",
      "Epoch 10/400\n",
      "347/347 [==============================] - 0s 113us/step - loss: 117.5656 - mae: 7.5880 - val_loss: 74.3424 - val_mae: 6.4111\n",
      "Epoch 11/400\n",
      "347/347 [==============================] - 0s 109us/step - loss: 96.5528 - mae: 6.5664 - val_loss: 85.4865 - val_mae: 7.1520\n",
      "Epoch 12/400\n",
      "347/347 [==============================] - 0s 104us/step - loss: 83.5051 - mae: 6.0943 - val_loss: 98.2850 - val_mae: 7.9692\n",
      "Epoch 13/400\n",
      "347/347 [==============================] - 0s 111us/step - loss: 77.2652 - mae: 6.0224 - val_loss: 111.7048 - val_mae: 8.7820\n",
      "Epoch 14/400\n",
      "347/347 [==============================] - 0s 108us/step - loss: 73.3497 - mae: 6.0254 - val_loss: 121.3962 - val_mae: 9.3488\n",
      "Epoch 15/400\n",
      "347/347 [==============================] - 0s 111us/step - loss: 72.1158 - mae: 6.1314 - val_loss: 128.8946 - val_mae: 9.7635\n",
      "Epoch 16/400\n",
      "347/347 [==============================] - 0s 106us/step - loss: 71.6141 - mae: 6.2335 - val_loss: 133.0382 - val_mae: 9.9845\n",
      "Epoch 17/400\n",
      "347/347 [==============================] - 0s 102us/step - loss: 71.5186 - mae: 6.2957 - val_loss: 135.7537 - val_mae: 10.1261\n",
      "Epoch 18/400\n",
      "347/347 [==============================] - 0s 113us/step - loss: 71.5545 - mae: 6.3517 - val_loss: 137.8306 - val_mae: 10.2324\n",
      "Epoch 19/400\n",
      "347/347 [==============================] - 0s 111us/step - loss: 71.5372 - mae: 6.3747 - val_loss: 137.9849 - val_mae: 10.2404\n",
      "Epoch 20/400\n",
      "347/347 [==============================] - 0s 109us/step - loss: 71.5520 - mae: 6.3819 - val_loss: 138.8177 - val_mae: 10.2839\n",
      "Epoch 21/400\n",
      "347/347 [==============================] - 0s 111us/step - loss: 71.5734 - mae: 6.3777 - val_loss: 137.3168 - val_mae: 10.2063\n",
      "Epoch 22/400\n",
      "347/347 [==============================] - 0s 112us/step - loss: 71.5339 - mae: 6.3652 - val_loss: 137.6217 - val_mae: 10.2218\n",
      "Epoch 23/400\n",
      "347/347 [==============================] - 0s 109us/step - loss: 71.5221 - mae: 6.3673 - val_loss: 137.6353 - val_mae: 10.2225\n",
      "Epoch 24/400\n",
      "347/347 [==============================] - 0s 112us/step - loss: 71.5673 - mae: 6.3671 - val_loss: 138.2702 - val_mae: 10.2553\n",
      "Epoch 25/400\n",
      "347/347 [==============================] - 0s 110us/step - loss: 71.5456 - mae: 6.3864 - val_loss: 138.2766 - val_mae: 10.2557\n",
      "Epoch 26/400\n",
      "347/347 [==============================] - 0s 109us/step - loss: 71.5814 - mae: 6.3592 - val_loss: 136.5393 - val_mae: 10.1665\n",
      "Epoch 27/400\n",
      "347/347 [==============================] - 0s 115us/step - loss: 71.5545 - mae: 6.3568 - val_loss: 137.9106 - val_mae: 10.2365\n",
      "Epoch 28/400\n",
      "347/347 [==============================] - 0s 116us/step - loss: 71.5287 - mae: 6.3715 - val_loss: 137.9125 - val_mae: 10.2366\n",
      "Epoch 29/400\n",
      "347/347 [==============================] - 0s 113us/step - loss: 71.5267 - mae: 6.3724 - val_loss: 137.8202 - val_mae: 10.2319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28a9f5a7488>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data2, d.target[lags:],\n",
    "         epochs=400,\n",
    "         validation_split=0.3,\n",
    "         callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[111.40012885678199, 7.49119758605957]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data, d.target[lags:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
