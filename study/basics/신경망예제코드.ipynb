{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀문제 예시\n",
    "model = models.Sequential() # 모델 시작\n",
    "\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear')) # output의 차원과 같은 차원으로 출력노드 조정\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'mse') # 분류시 crossentropy 등을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 을 활용한 시계열 예제\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.SimpleRNN(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(16, )) # 사용하는 변수가 16개로 가정\n",
    "\n",
    "l1 = layers.Dense(16, activation='relu')(inputs)\n",
    "outputs = layers.Dense(1, activation='linear')(l1)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer = 'SGD',\n",
    "             loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단하다면 이렇게 줄여 쓸 수도 있습니다.\n",
    "inputs = layers.Input(shape=(16, )) # 사용하는 변수가 16개로 가정\n",
    "\n",
    "x = layers.Dense(16, activation='relu')(inputs)\n",
    "x = layers.Dense(8, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer = 'SGD',\n",
    "             loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 복잡한 층 구성 예시1\n",
    "\n",
    "input1 = layers.Input(shape=(16, )) # 두 종류의 다른 인풋을 함께 받는 경우\n",
    "input2 = layers.Input(shape=(8, 4))\n",
    "\n",
    "x11 = layers.Dense(32, activation='relu')(input1)\n",
    "x21 = layers.LSTM(32, activation='tanh', return_sequences=False)(input2)\n",
    "\n",
    "x12 = layers.Dense(16, activation='relu')(x11)\n",
    "\n",
    "x2 = layers.concatenate([x12, x21])\n",
    "\n",
    "x3 = layers.Dense(8)(x2)\n",
    "\n",
    "output = layers.Dense(1, activation='linear')(x3)\n",
    "\n",
    "model = models.Model([input1, input2], output)\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(lr = 1e-4), # optimizer 세부조정도 가능함\n",
    "             loss = 'mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복잡한 층 구성 예시 2\n",
    "inputs = layers.Input(shape=(16, ))\n",
    "\n",
    "x1 = layers.Dense(16, activation='relu')(inputs) # 하나의 층으로 부터 다수의 층을 만들어서 전개\n",
    "x2 = layers.Dense(8, activation='relu')(inputs)\n",
    "x3 = layers.Dense(16, activation='tanh')(inputs)\n",
    "\n",
    "x = layers.concatenate([x1, x2, x3])\n",
    "\n",
    "x = layers.Dense(16, activation = 'relu')(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import L1L2\n",
    "\n",
    "layers.Dense(16, kernel_regularizer=L1L2(l1=0, l2=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers,Dense(16)(x)\n",
    "x = layers.Dropout(0.3)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(16)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
