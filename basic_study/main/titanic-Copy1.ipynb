{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 기본 library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "## model library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from keras import models, layers, optimizers\n",
    "## helper library\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('./data/titanic/train.csv')\n",
    "d = data.copy()\n",
    "test = pd.read_csv('./data/titanic/test.csv')\n",
    "submission = pd.read_csv('./data/titanic/gender_submission.csv')\n",
    "\n",
    "target = data['Survived']\n",
    "data = data.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1)\n",
    "test = test.drop(['PassengerId', 'Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3       1  female  35.0      1      0  53.1000  C123        S\n",
       "4       3    male  35.0      0      0   8.0500   NaN        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(data['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin_split(a):\n",
    "    if type(a) == np.float:\n",
    "        return np.nan\n",
    "    \n",
    "    if 'A' in a:\n",
    "        return 'A'\n",
    "    elif 'B' in a:\n",
    "        return 'B'\n",
    "    elif 'C' in a:\n",
    "        return 'C'\n",
    "    elif 'D' in a:\n",
    "        return 'D'\n",
    "    elif 'E' in a:\n",
    "        return 'E'\n",
    "    elif 'F' in a:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Cabin'] = data['Cabin'].map(cabin_split)\n",
    "test['Cabin'] = test['Cabin'].map(cabin_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'] = data['Embarked'].replace(np.nan, -999)\n",
    "test['Embarked'] = test['Embarked'].replace(np.nan, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>445.357143</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>1.886905</td>\n",
       "      <td>30.814769</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>59.954144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>417.896104</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>28.089286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.168831</td>\n",
       "      <td>13.276030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>449.527950</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>2.350932</td>\n",
       "      <td>29.445397</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>27.079812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId  Survived    Pclass        Age     SibSp     Parch  \\\n",
       "Embarked                                                                   \n",
       "C          445.357143  0.553571  1.886905  30.814769  0.386905  0.363095   \n",
       "Q          417.896104  0.389610  2.909091  28.089286  0.428571  0.168831   \n",
       "S          449.527950  0.336957  2.350932  29.445397  0.571429  0.413043   \n",
       "\n",
       "               Fare  \n",
       "Embarked             \n",
       "C         59.954144  \n",
       "Q         13.276030  \n",
       "S         27.079812  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby('Embarked').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_map(a):\n",
    "    if a == 'C':\n",
    "        return 0.738462\n",
    "    elif a == 'Q':\n",
    "        return 0.389610\n",
    "    elif a == 'S':\n",
    "        return 0.336957\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'] = data['Embarked'].map(emb_map)\n",
    "test['Embarked'] = test['Embarked'].map(emb_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Cabin'] = d['Cabin'].map(cabin_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>439.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.833333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>39.623887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>521.808511</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.955556</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>113.505764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>406.440678</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.086667</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>100.151341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>475.939394</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>1.121212</td>\n",
       "      <td>39.032258</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>57.244576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>491.121212</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>38.116667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>45.309470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>390.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>19.954545</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>18.391667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>240.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.965000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived    Pclass        Age     SibSp     Parch  \\\n",
       "Cabin                                                                   \n",
       "A       439.600000  0.466667  1.000000  44.833333  0.133333  0.133333   \n",
       "B       521.808511  0.744681  1.000000  34.955556  0.361702  0.574468   \n",
       "C       406.440678  0.593220  1.000000  36.086667  0.644068  0.474576   \n",
       "D       475.939394  0.757576  1.121212  39.032258  0.424242  0.303030   \n",
       "E       491.121212  0.757576  1.363636  38.116667  0.333333  0.333333   \n",
       "F       390.500000  0.583333  2.333333  19.954545  0.500000  0.500000   \n",
       "other   240.800000  0.400000  2.600000  20.800000  0.400000  1.000000   \n",
       "\n",
       "             Fare  \n",
       "Cabin              \n",
       "A       39.623887  \n",
       "B      113.505764  \n",
       "C      100.151341  \n",
       "D       57.244576  \n",
       "E       45.309470  \n",
       "F       18.391667  \n",
       "other   17.965000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby('Cabin').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe = LabelEncoder()\n",
    "\n",
    "data['Sex'] = lbe.fit_transform(data['Sex'])\n",
    "test['Sex'] = lbe.fit_transform(test['Sex'])\n",
    "data['Cabin'] = lbe.fit_transform(data['Cabin'].replace(np.nan, 'nan'))\n",
    "test['Cabin'] = lbe.fit_transform(test['Cabin'].replace(np.nan, 'nan'))\n",
    "data['Cabin'] = data['Cabin'].replace(6, 999)\n",
    "test['Cabin'] = test['Cabin'].replace(6, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=0).fit(data)\n",
    "new_data = pd.DataFrame(imp.transform(data), columns=data.columns)\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=0).fit(test)\n",
    "new_test = pd.DataFrame(imp.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['Age'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.copy()\n",
    "categorical = [\n",
    "    'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = pd.DataFrame(MinMaxScaler().fit_transform(data['Age'].values.reshape(-1,1)))\n",
    "data['Fare'] = pd.DataFrame(StandardScaler().fit_transform(data['Fare'].values.reshape(-1,1)))\n",
    "\n",
    "lbe = LabelEncoder()\n",
    "data['Sex'] = lbe.fit_transform(data['Sex'])\n",
    "sex = lbe.classes_\n",
    "data['Embarked'] = lbe.fit_transform(data['Embarked'])\n",
    "emb = lbe.classes_\n",
    "\n",
    "for c in categorical:\n",
    "    data = pd.concat([data, pd.get_dummies(data[c], prefix=c)], axis=1)\n",
    "    data = data.drop(c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(new_data, target, test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3190984284532672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "## logistic\n",
    "acc = 0\n",
    "for tr_idx, val_idx in kfold.split(train_X):\n",
    "    tr_X, tr_y = train_X.iloc[tr_idx, :], train_y.iloc[tr_idx]\n",
    "    val_X, val_y = train_X.iloc[val_idx, :], train_y.iloc[val_idx]\n",
    "    lr = LogisticRegression(random_state=0).fit(tr_X, tr_y)\n",
    "    acc += accuracy_score(val_y, lr.predict(val_X))/10\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7977460711331679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "## 조금 더 간단히 할 수 있음\n",
    "lr  = LogisticRegression(random_state=0)\n",
    "acc = cross_val_score(lr, train_X, train_y, cv=kfold, n_jobs=1, scoring='accuracy')\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## knn\n",
    "opt = []\n",
    "for n in range(2, 30):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    acc = []\n",
    "    for tr_idx, val_idx in kfold.split(train_X):\n",
    "        tr_X, tr_y = train_X.iloc[tr_idx, :], train_y.iloc[tr_idx]\n",
    "        val_X, val_y = train_X.iloc[val_idx, :], train_y.iloc[val_idx]\n",
    "        knn.fit(tr_X, tr_y)\n",
    "        acc.append(accuracy_score(val_y, knn.predict(val_X)))\n",
    "    opt.append(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6902088502894955, 0.688564929693962, 0.6837779156327544, 0.7046836228287842, 0.6790219189412738, 0.6886993382961125, 0.6790322580645162, 0.6951095947063689, 0.6966914805624482, 0.6870554177005791, 0.6918631100082714, 0.6982940446650123, 0.7015198511166253, 0.701509511993383, 0.6967121588089331, 0.6966914805624482, 0.6967018196856907, 0.7031327543424318, 0.7015508684863523, 0.7047559966914805, 0.6983250620347394, 0.6903225806451613, 0.6967328370554177, 0.6983147229114971, 0.70154052936311, 0.6935173697270471, 0.6951302729528536, 0.7015301902398676]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(opt)\n",
    "print(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## knn's n_neighbor = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=4).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797777088502895\n"
     ]
    }
   ],
   "source": [
    "## RF with no paramter tuning\n",
    "acc = 0\n",
    "for tr_idx, val_idx in kfold.split(train_X):\n",
    "    tr_X, tr_y = train_X.iloc[tr_idx, :], train_y.iloc[tr_idx]\n",
    "    val_X, val_y = train_X.iloc[val_idx, :], train_y.iloc[val_idx]\n",
    "    rf = RandomForestClassifier(random_state=0).fit(tr_X, tr_y)\n",
    "    acc += accuracy_score(val_y, rf.predict(val_X))/k\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xgboost\n",
    "xgb_bounds = {\n",
    "    'max_depth': (3, 12),\n",
    "    'subsample': (0.3, 1),\n",
    "    'colsample_bytree': (0.3, 1),\n",
    "    'reg_alpha': (0.1, 3),\n",
    "    'reg_lamda': (0.1, 3)\n",
    "}\n",
    "\n",
    "best_ns = []\n",
    "\n",
    "def bayes_xgb(max_depth, subsample, colsample_bytree, reg_alpha, reg_lamda):\n",
    "    global best_ns\n",
    "    params = {\n",
    "        'n_estimators': 1000,\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': 0,\n",
    "        'n_jobs': -1,\n",
    "        'max_depth': int(max_depth),\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'reg_alpha': reg_alpha,\n",
    "        'reg_lamda': reg_lamda\n",
    "    }\n",
    "    \n",
    "    acc = 0\n",
    "    best_n = 0\n",
    "    for tr_idx, val_idx in kfold.split(train_X):\n",
    "        tr_X, tr_y = train_X.iloc[tr_idx, :], train_y.iloc[tr_idx]\n",
    "        val_X, val_y = train_X.iloc[val_idx, :], train_y.iloc[val_idx]\n",
    "        clf = XGBClassifier(**params).fit(tr_X, tr_y, eval_metric = 'error', eval_set=[[val_X, val_y]], early_stopping_rounds=100, verbose=0)\n",
    "        acc += accuracy_score(val_y, clf.predict(val_X))/k\n",
    "        best_n += clf.best_iteration/k\n",
    "    best_ns.append(best_n)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | max_depth | reg_alpha | reg_lamda | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8283  \u001b[0m | \u001b[0m 0.6842  \u001b[0m | \u001b[0m 9.437   \u001b[0m | \u001b[0m 1.848   \u001b[0m | \u001b[0m 1.68    \u001b[0m | \u001b[0m 0.5966  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8315  \u001b[0m | \u001b[95m 0.7521  \u001b[0m | \u001b[95m 6.938   \u001b[0m | \u001b[95m 2.686   \u001b[0m | \u001b[95m 2.895   \u001b[0m | \u001b[95m 0.5684  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 0.8542  \u001b[0m | \u001b[0m 7.76    \u001b[0m | \u001b[0m 1.747   \u001b[0m | \u001b[0m 2.784   \u001b[0m | \u001b[0m 0.3497  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8091  \u001b[0m | \u001b[0m 0.361   \u001b[0m | \u001b[0m 3.182   \u001b[0m | \u001b[0m 2.515   \u001b[0m | \u001b[0m 2.357   \u001b[0m | \u001b[0m 0.909   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8347  \u001b[0m | \u001b[95m 0.985   \u001b[0m | \u001b[95m 10.19   \u001b[0m | \u001b[95m 1.438   \u001b[0m | \u001b[95m 2.364   \u001b[0m | \u001b[95m 0.3828  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.7479  \u001b[0m | \u001b[0m 4.29    \u001b[0m | \u001b[0m 2.84    \u001b[0m | \u001b[0m 1.613   \u001b[0m | \u001b[0m 0.5903  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.4852  \u001b[0m | \u001b[0m 9.968   \u001b[0m | \u001b[0m 1.423   \u001b[0m | \u001b[0m 1.748   \u001b[0m | \u001b[0m 0.3132  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 8.509   \u001b[0m | \u001b[0m 1.889   \u001b[0m | \u001b[0m 2.837   \u001b[0m | \u001b[0m 0.7773  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.5517  \u001b[0m | \u001b[0m 6.933   \u001b[0m | \u001b[0m 2.123   \u001b[0m | \u001b[0m 0.2747  \u001b[0m | \u001b[0m 0.7667  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8347  \u001b[0m | \u001b[95m 0.7694  \u001b[0m | \u001b[95m 4.893   \u001b[0m | \u001b[95m 0.4739  \u001b[0m | \u001b[95m 1.015   \u001b[0m | \u001b[95m 0.5546  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8203  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 2.893   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.3131  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 0.9036  \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 0.1026  \u001b[0m | \u001b[0m 0.1582  \u001b[0m | \u001b[0m 0.7815  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8331  \u001b[0m | \u001b[0m 0.906   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.3     \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.817   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 11.68   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.777   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 0.9282  \u001b[0m | \u001b[0m 8.129   \u001b[0m | \u001b[0m 0.1602  \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 0.9474  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 0.9763  \u001b[0m | \u001b[0m 3.1     \u001b[0m | \u001b[0m 0.1006  \u001b[0m | \u001b[0m 2.951   \u001b[0m | \u001b[0m 0.8944  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 11.62   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8347  \u001b[0m | \u001b[0m 0.9964  \u001b[0m | \u001b[0m 3.62    \u001b[0m | \u001b[0m 0.5146  \u001b[0m | \u001b[0m 0.1522  \u001b[0m | \u001b[0m 0.9757  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 8.869   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.686   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.933   \u001b[0m | \u001b[0m 1.57    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.9813  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.9928  \u001b[0m | \u001b[0m 11.38   \u001b[0m | \u001b[0m 1.839   \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.3297  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 11.93   \u001b[0m | \u001b[0m 1.579   \u001b[0m | \u001b[0m 1.138   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.4231  \u001b[0m | \u001b[0m 4.136   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.3     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8187  \u001b[0m | \u001b[0m 0.9902  \u001b[0m | \u001b[0m 6.641   \u001b[0m | \u001b[0m 2.951   \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 0.9758  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8235  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 5.38    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8171  \u001b[0m | \u001b[0m 0.9806  \u001b[0m | \u001b[0m 3.849   \u001b[0m | \u001b[0m 1.232   \u001b[0m | \u001b[0m 2.173   \u001b[0m | \u001b[0m 0.3226  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8123  \u001b[0m | \u001b[0m 0.4384  \u001b[0m | \u001b[0m 3.064   \u001b[0m | \u001b[0m 2.911   \u001b[0m | \u001b[0m 0.1515  \u001b[0m | \u001b[0m 0.3618  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8123  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 9.437   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.3     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.9687  \u001b[0m | \u001b[0m 8.779   \u001b[0m | \u001b[0m 0.1952  \u001b[0m | \u001b[0m 2.721   \u001b[0m | \u001b[0m 0.9722  \u001b[0m |\n",
      "=====================================================================================\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = BayesianOptimization(bayes_xgb, xgb_bounds, random_state=0)\n",
    "\n",
    "init_points = 10\n",
    "n_iter = 20\n",
    "\n",
    "optimizer.maximize(init_points=init_points, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('best_params.bin', 'rb') as f:\n",
    "    best_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7694465087327116,\n",
       " 'max_depth': 4.893443049664568,\n",
       " 'reg_alpha': 0.47388626319907456,\n",
       " 'reg_lamda': 1.0147422176801333,\n",
       " 'subsample': 0.5545975396598358}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.0,\n",
       " 69.75,\n",
       " 33.75,\n",
       " 66.0,\n",
       " 121.5,\n",
       " 29.5,\n",
       " 70.75,\n",
       " 9.0,\n",
       " 48.0,\n",
       " 42.75,\n",
       " 59.0,\n",
       " 26.5,\n",
       " 97.25,\n",
       " 16.0,\n",
       " 41.25,\n",
       " 11.0,\n",
       " 29.0,\n",
       " 13.0,\n",
       " 22.75,\n",
       " 54.75,\n",
       " 18.75,\n",
       " 38.25,\n",
       " 11.25,\n",
       " 69.25,\n",
       " 17.5,\n",
       " 47.25,\n",
       " 18.25,\n",
       " 50.0,\n",
       " 60.0,\n",
       " 25.25]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'n_estimators': 40,\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 0,\n",
    "    'n_jobs': -1,\n",
    "    'max_depth': int(optimizer.max['params']['max_depth']),\n",
    "    'subsample': optimizer.max['params']['subsample'],\n",
    "    'colsample_bytree': optimizer.max['params']['colsample_bytree'],\n",
    "    'reg_alpha': optimizer.max['params']['reg_alpha'],\n",
    "    'reg_lamda': optimizer.max['params']['reg_lamda'],\n",
    "    'metric': 'error'\n",
    "}\n",
    "\n",
    "clf = XGBClassifier(**best_params).fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\young\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3152688172043011\n"
     ]
    }
   ],
   "source": [
    "## voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "v_lr = LogisticRegression(random_state=0)\n",
    "v_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "v_rf = RandomForestClassifier(max_depth=9, random_state=0)\n",
    "\n",
    "vclf = VotingClassifier(estimators=[\n",
    "    ('lr', v_lr),\n",
    "    ('knn', v_knn),\n",
    "    ('rf', v_rf)\n",
    "], voting='soft')\n",
    "\n",
    "acc = 0\n",
    "for tr_idx, val_idx in kfold.split(train_X):\n",
    "    tr_X, tr_y = train_X.iloc[tr_idx, :], train_y.iloc[tr_idx]\n",
    "    val_X, val_y = train_X.iloc[val_idx, :], train_y.iloc[val_idx]\n",
    "    vclf.fit(tr_X, tr_y)\n",
    "    acc += accuracy_score(val_y, vclf.predict(val_X))/10\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 모델들과 앙상블모형을 통틀어 xgboost가 가장 높은 성능을 보여줄 것으로 기대된다.  \n",
    "실제 test셋의 결과는 어떨까?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.8059701492537313\n",
      "knn: 0.6977611940298507\n",
      "rf: 0.8134328358208955\n",
      "xgboost: 0.8283582089552238\n",
      "voting: 0.8022388059701493\n"
     ]
    }
   ],
   "source": [
    "print('lr:', accuracy_score(test_y, lr.predict(test_X)))\n",
    "print('knn:', accuracy_score(test_y, knn.predict(test_X)))\n",
    "print('rf:', accuracy_score(test_y, rf.predict(test_X)))\n",
    "print('xgboost:', accuracy_score(test_y, clf.predict(test_X)))\n",
    "print('voting:', accuracy_score(test_y, vclf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nn 및 stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nn\n",
    "input_layer = layers.Input(shape=((train_X.shape[1], )))\n",
    "\n",
    "layer1 = layers.Dense(64, activation='relu')(input_layer)\n",
    "# drop1 = layers.Dropout(0.1)(layer1)\n",
    "layer2 = layers.Dense(32, activation='relu')(layer1)\n",
    "\n",
    "out_layer = layers.Dense(1, activation='sigmoid')(layer2)\n",
    "\n",
    "model = models.Model(input_layer, out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y,\n",
    "          epochs=200,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self cv 예시\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def make_model():\n",
    "    K.clear_session()\n",
    "    input_layer = layers.Input(shape=((train_X.shape[1], )))\n",
    "\n",
    "    layer1 = layers.Dense(32, activation='relu')(input_layer)\n",
    "    drop1 = layers.Dropout(0.1)(layer1)\n",
    "    layer2 = layers.Dense(16, activation='relu')(drop1)\n",
    "    \n",
    "    out_layer = layers.Dense(1, activation='sigmoid')(layer2)\n",
    "\n",
    "    model = models.Model(input_layer, out_layer)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for tr_idx, val_idx in kfold.split(train_X):\n",
    "    tr_X, tr_y = train_X.iloc[tr_idx, :], train_y.iloc[tr_idx]\n",
    "    val_X, val_y = train_X.iloc[val_idx, :], train_y.iloc[val_idx]\n",
    "    model = make_model()\n",
    "    model.fit(tr_X, tr_y, \n",
    "            epochs=40, \n",
    "#           callbacks = [es], \n",
    "            validation_data=[val_X, val_y],\n",
    "            verbose=0)\n",
    "    acc += model.evaluate(val_X, val_y)[1]/10\n",
    "\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## meta_training\n",
    "meta_train = pd.DataFrame()\n",
    "meta_train['lr'] = list(zip(*lr.predict_proba(train_X)))[0]\n",
    "meta_train['knn'] = list(zip(*knn.predict_proba(train_X)))[0]\n",
    "meta_train['rf'] = list(zip(*rf.predict_proba(train_X)))[0]\n",
    "meta_train['xgboost'] = list(zip(*clf.predict_proba(train_X)))[0]\n",
    "meta_train['voting'] = list(zip(*vclf.predict_proba(train_X)))[0]\n",
    "\n",
    "## meta_test\n",
    "meta_test = pd.DataFrame()\n",
    "meta_test['lr'] = list(zip(*lr.predict_proba(test_X)))[0]\n",
    "meta_test['knn'] = list(zip(*knn.predict_proba(test_X)))[0]\n",
    "meta_test['rf'] = list(zip(*rf.predict_proba(test_X)))[0]\n",
    "meta_test['xgboost'] = list(zip(*clf.predict_proba(test_X)))[0]\n",
    "meta_test['voting'] = list(zip(*vclf.predict_proba(test_X)))[0]\n",
    "# knn\n",
    "# rf\n",
    "# clf\n",
    "# vclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "def stack_net():\n",
    "    K.clear_session()\n",
    "    \n",
    "    input_layer = layers.Input(shape=((meta_train.shape[1], )))\n",
    "\n",
    "    layer1 = layers.Dense(4, activation='relu')(input_layer)\n",
    "#     layer2 = layers.Dense(8, activation='relu')(layer1)\n",
    "    \n",
    "    out_layer = layers.Dense(1, activation='sigmoid')(layer1)\n",
    "\n",
    "    model = models.Model(input_layer, out_layer)\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', patience=20, restore_best_weights=True, verbose=1)\n",
    "stack = stack_net()\n",
    "stack.fit(meta_train, train_y,\n",
    "          epochs=200,\n",
    "          validation_split = 0.3,\n",
    "          callbacks = [es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.evaluate(meta_test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lr:', accuracy_score(test_y, lr.predict(test_X)))\n",
    "print('knn:', accuracy_score(test_y, knn.predict(test_X)))\n",
    "print('rf:', accuracy_score(test_y, rf.predict(test_X)))\n",
    "print('xgboost:', accuracy_score(test_y, clf.predict(test_X)))\n",
    "print('voting:', accuracy_score(test_y, vclf.predict(test_X)))\n",
    "print('nn:', model.evaluate(test_X, test_y)[1])\n",
    "print('stacking:', stack.evaluate(meta_test, test_y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission['Survived'] = clf.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sub5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>999</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>999</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>999</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>999</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>999</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>999</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>999</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>999</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch      Fare  Cabin  Embarked\n",
       "0         3    1  34.5      0      0    7.8292    999  0.389610\n",
       "1         3    0  47.0      1      0    7.0000    999  0.336957\n",
       "2         2    1  62.0      0      0    9.6875    999  0.389610\n",
       "3         3    1  27.0      0      0    8.6625    999  0.336957\n",
       "4         3    0  22.0      1      1   12.2875    999  0.336957\n",
       "..      ...  ...   ...    ...    ...       ...    ...       ...\n",
       "413       3    1   NaN      0      0    8.0500    999  0.336957\n",
       "414       1    0  39.0      0      0  108.9000      2  0.738462\n",
       "415       3    1  38.5      0      0    7.2500    999  0.336957\n",
       "416       3    1   NaN      0      0    8.0500    999  0.336957\n",
       "417       3    1   NaN      1      1   22.3583    999  0.738462\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
