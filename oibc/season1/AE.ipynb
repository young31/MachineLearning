{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import operator\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy.stats import norm, kurtosis\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers, initializers, regularizers, constraints, losses\n",
    "from keras.models import Sequential, Model, load_model, Input\n",
    "from keras.layers import (Dense, Concatenate, BatchNormalization, Activation, Add,\n",
    "                          concatenate, Dropout, AlphaDropout, Reshape, Layer, Multiply, Lambda)\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.losses import binary_crossentropy,  kullback_leibler_divergence, mean_squared_error\n",
    "\n",
    "def mish(x):\n",
    "    return x*K.tanh(K.softplus(x))\n",
    "\n",
    "def decay(epoch, steps=100):\n",
    "    initial_lrate = 1e-3\n",
    "    drop = 0.9\n",
    "    epochs_drop = 50\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    lrate = max(lrate, 5e-5)\n",
    "    return lrate\n",
    "\n",
    "es = EarlyStopping(patience=25, restore_best_weights=True)\n",
    "lrs = LearningRateScheduler(decay, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./data/SolarPV_Elec_Problem.csv', header=None)\n",
    "data = pd.read_csv('./data/features3.csv')#.iloc[0:-2,:] # 자료가 21시까지\n",
    "# sub = pd.read_csv('./data/제출양식_복원값.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grap_year(x):\n",
    "    y, _, _ = x.split('-')\n",
    "    return int(y)\n",
    "\n",
    "def grap_date(x):\n",
    "    y = x[5:10].replace('-','')\n",
    "    return y\n",
    "\n",
    "def grap_hour(x):\n",
    "    return x[11:13]\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    res = 0\n",
    "    cnt = 1\n",
    "    for i in range(0, len(y_true), 24):\n",
    "        yt = y_true[i:i+24]\n",
    "        yp = y_pred[i:i+24]\n",
    "        a = np.abs(yt-yp)\n",
    "        c = 113\n",
    "        S = np.sum(yt)\n",
    "        res += np.sum(a*yt/(S*c))\n",
    "        cnt += 1\n",
    "    return res/cnt\n",
    "\n",
    "class Lookahead(keras.optimizers.Optimizer):\n",
    "    \"\"\"The lookahead mechanism for optimizers.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        optimizer: An existed optimizer.\n",
    "        sync_period: int > 0. The synchronization period.\n",
    "        slow_step: float, 0 < alpha < 1. The step size of slow weights.\n",
    "    # References\n",
    "        - [Lookahead Optimizer: k steps forward, 1 step back]\n",
    "          (https://arxiv.org/pdf/1907.08610v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, sync_period=5, slow_step=0.5, **kwargs):\n",
    "        super(Lookahead, self).__init__(**kwargs)\n",
    "        self.optimizer = keras.optimizers.get(optimizer)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.sync_period = K.variable(sync_period, dtype='int64', name='sync_period')\n",
    "            self.slow_step = K.variable(slow_step, name='slow_step')\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self.optimizer.lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, lr):\n",
    "        self.optimizer.lr = lr\n",
    "\n",
    "    @property\n",
    "    def learning_rate(self):\n",
    "        return self.optimizer.learning_rate\n",
    "\n",
    "    @learning_rate.setter\n",
    "    def learning_rate(self, learning_rate):\n",
    "        self.optimizer.learning_rate = learning_rate\n",
    "\n",
    "    @property\n",
    "    def iterations(self):\n",
    "        return self.optimizer.iterations\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        sync_cond = K.equal((self.iterations + 1) // self.sync_period * self.sync_period, (self.iterations + 1))\n",
    "        slow_params = {p.name: K.variable(K.get_value(p), name='sp_{}'.format(i)) for i, p in enumerate(params)}\n",
    "        update_names = ['update', 'update_add', 'update_sub']\n",
    "        original_updates = [getattr(K, name) for name in update_names]\n",
    "        setattr(K, 'update', lambda x, new_x: ('update', x, new_x))\n",
    "        setattr(K, 'update_add', lambda x, new_x: ('update_add', x, new_x))\n",
    "        setattr(K, 'update_sub', lambda x, new_x: ('update_sub', x, new_x))\n",
    "        self.updates = self.optimizer.get_updates(loss, params)\n",
    "        for name, original_update in zip(update_names, original_updates):\n",
    "            setattr(K, name, original_update)\n",
    "        slow_updates = []\n",
    "        for i, update in enumerate(self.updates):\n",
    "            if isinstance(update, tuple):\n",
    "                name, x, new_x, adjusted = update + (update[-1],)\n",
    "                update_func = getattr(K, name)\n",
    "                if name == 'update_add':\n",
    "                    adjusted = x + new_x\n",
    "                if name == 'update_sub':\n",
    "                    adjusted = x - new_x\n",
    "                if x.name not in slow_params:\n",
    "                    self.updates[i] = update_func(x, new_x)\n",
    "                else:\n",
    "                    slow_param = slow_params[x.name]\n",
    "                    slow_param_t = slow_param + self.slow_step * (adjusted - slow_param)\n",
    "                    slow_updates.append(K.update(slow_param, K.switch(\n",
    "                        sync_cond,\n",
    "                        slow_param_t,\n",
    "                        slow_param,\n",
    "                    )))\n",
    "                    self.updates[i] = K.update(x, K.switch(\n",
    "                        sync_cond,\n",
    "                        slow_param_t,\n",
    "                        adjusted,\n",
    "                    ))\n",
    "        slow_params = list(slow_params.values())\n",
    "        self.updates += slow_updates\n",
    "        self.weights = self.optimizer.weights + slow_params\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'optimizer': keras.optimizers.serialize(self.optimizer),\n",
    "            'sync_period': int(K.get_value(self.sync_period)),\n",
    "            'slow_step': float(K.get_value(self.slow_step)),\n",
    "        }\n",
    "        base_config = super(Lookahead, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        optimizer = keras.optimizers.deserialize(config.pop('optimizer'))\n",
    "        return cls(optimizer, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['year'] = target[0].map(grap_year)\n",
    "target['md'] = target[0].map(grap_date)\n",
    "target['hour'] = target[0].map(grap_hour)\n",
    "target = target.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.fillna(-10)\n",
    "y = target.groupby(['year', 'md', 'hour']).sum()[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y[:5136] # 0701~0130\n",
    "y2 = y[5160:6552] # 0201~0330\n",
    "y3 = y[6600:8016] # 0401~0530\n",
    "y4 = y[8064:] # 0530~0630\n",
    "\n",
    "val_y1 = y[5112:5136]\n",
    "val_y2 = y[6552:6576]\n",
    "val_y3 = y[8016:8040]\n",
    "\n",
    "val_y = np.hstack([val_y1, val_y2, val_y3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y1 = y[24:5136-24]\n",
    "tr_X1 = y[:5112-24]\n",
    "\n",
    "val_y1 = y[5112:5136]\n",
    "val_X1 = y[5112-24:5136-24]\n",
    "\n",
    "tr_y2 = y[5184:6576-24]\n",
    "tr_X2 = y[5160:6552-24]\n",
    "\n",
    "val_y2 = y[6552:6576]\n",
    "val_X2 = y[6552-24:6552]\n",
    "\n",
    "tr_y3 = y[6624:8016]\n",
    "tr_X3 = y[6600:8016-24]\n",
    "\n",
    "val_y3 = y[8016:8040]\n",
    "val_X3 = y[8016-24:8016]\n",
    "\n",
    "tr_y4 = y[8088:8760]\n",
    "tr_X4 = y[8064:8760-24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_X2)/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate([tr_X1, tr_X2, tr_X3, tr_X4])\n",
    "train_y = np.concatenate([tr_y1, tr_y2, tr_y3, tr_y4])\n",
    "validation_X = np.concatenate([val_X1,  val_X2, val_X3])\n",
    "validation_y = np.concatenate([val_y1, val_y2, val_y3])\n",
    "\n",
    "tr_X = []\n",
    "for i in range(0, len(train_X), 24):\n",
    "    tr_X.append(train_X[i:i+24])\n",
    "tr_X = np.array(tr_X)\n",
    "\n",
    "tr_y = []\n",
    "for i in range(0, len(train_y), 24):\n",
    "    tr_y.append(train_y[i:i+24])\n",
    "tr_y = np.array(tr_y)\n",
    "\n",
    "val_y = []\n",
    "for i in range(0, len(validation_y), 24):\n",
    "    val_y.append(validation_y[i:i+24])\n",
    "val_y= np.array(val_y)\n",
    "\n",
    "val_X = []\n",
    "for i in range(0, len(validation_X), 24):\n",
    "    val_X.append(validation_X[i:i+24])\n",
    "val_X= np.array(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 24), (355, 24))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, tr_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE():\n",
    "    activation=mish\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(16))\n",
    "#     nn.add(BatchNormalization())\n",
    "    nn.add(Activation(activation))\n",
    "    nn.add(Dense(8))\n",
    "    nn.add(Activation('sigmoid'))\n",
    "    nn.add(Dense(16))\n",
    "#     nn.add(BatchNormalization())\n",
    "    nn.add(Activation(activation))\n",
    "    nn.add(Dense(24))\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AE()\n",
    "a.compile(loss='mse', optimizer=Lookahead(optimizers.Adam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 301 samples, validate on 54 samples\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 1008.8743 - val_loss: 1369.6661\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 1004.3994 - val_loss: 1361.7658\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 997.2522 - val_loss: 1351.7094\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 987.1496 - val_loss: 1340.4004\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 980.2023 - val_loss: 1331.9273\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 973.2108 - val_loss: 1321.8045\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 961.3012 - val_loss: 1302.4803\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 949.2130 - val_loss: 1291.6566\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 940.4185 - val_loss: 1280.9063\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 931.9152 - val_loss: 1270.3179\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 923.4767 - val_loss: 1259.8455\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 915.0980 - val_loss: 1249.3842\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 906.8337 - val_loss: 1238.7379\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 898.3422 - val_loss: 1228.2487\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 890.0746 - val_loss: 1217.7295\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 881.6821 - val_loss: 1207.3403\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 873.5622 - val_loss: 1196.8467\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 865.3456 - val_loss: 1186.5452\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 857.1065 - val_loss: 1176.2436\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 848.7835 - val_loss: 1164.3638\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 837.8782 - val_loss: 1142.1322\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 821.8703 - val_loss: 1129.3613\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 811.8623 - val_loss: 1117.4101\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 802.4929 - val_loss: 1105.7881\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 793.3238 - val_loss: 1094.4657\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 784.5128 - val_loss: 1083.1218\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 775.7397 - val_loss: 1072.1390\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 767.1815 - val_loss: 1061.3411\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 758.7507 - val_loss: 1050.5327\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 750.3955 - val_loss: 1039.9206\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 742.1032 - val_loss: 1029.5504\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 734.1023 - val_loss: 1019.1949\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 726.1482 - val_loss: 1008.9836\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 718.1398 - val_loss: 999.0603\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 710.4516 - val_loss: 989.0334\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 702.7068 - val_loss: 979.2553\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 695.0898 - val_loss: 969.5662\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 687.6210 - val_loss: 959.8681\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 680.1572 - val_loss: 950.3191\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 672.7554 - val_loss: 940.8855\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 665.5375 - val_loss: 931.5100\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 658.3608 - val_loss: 922.2048\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 651.3357 - val_loss: 912.8638\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 644.2048 - val_loss: 903.8481\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 637.2966 - val_loss: 895.0571\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 630.7193 - val_loss: 886.0247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 623.8433 - val_loss: 877.4834\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 617.3697 - val_loss: 868.8130\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 610.8122 - val_loss: 860.2297\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 604.5492 - val_loss: 852.7122\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 598.8348 - val_loss: 845.1999\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 593.1911 - val_loss: 837.8351\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 587.7093 - val_loss: 830.4571\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 582.1379 - val_loss: 823.3271\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 576.7422 - val_loss: 816.1609\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 571.3997 - val_loss: 809.1087\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 566.0906 - val_loss: 802.1040\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 560.9419 - val_loss: 795.1626\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 555.7120 - val_loss: 788.2072\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 550.5771 - val_loss: 781.3573\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 545.4825 - val_loss: 774.6700\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 540.5079 - val_loss: 768.0381\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 102us/step - loss: 535.6658 - val_loss: 761.3649\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 530.7526 - val_loss: 754.8265\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 525.9185 - val_loss: 748.4862\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 521.2560 - val_loss: 742.2207\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 516.6095 - val_loss: 735.8959\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 511.9882 - val_loss: 729.6182\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 507.3314 - val_loss: 723.5056\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 502.8432 - val_loss: 717.5519\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 498.4410 - val_loss: 711.3622\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 493.8941 - val_loss: 705.5082\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 489.7017 - val_loss: 699.5422\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 485.2906 - val_loss: 693.8644\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 481.1778 - val_loss: 687.9972\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 476.9053 - val_loss: 682.3035\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 472.7153 - val_loss: 676.7783\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 468.6293 - val_loss: 671.1489\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 464.6565 - val_loss: 665.4582\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 460.5661 - val_loss: 660.0459\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 456.6169 - val_loss: 654.7667\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 452.7490 - val_loss: 649.3861\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 448.9106 - val_loss: 643.9492\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 444.9853 - val_loss: 638.6707\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 441.2812 - val_loss: 633.4118\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 437.5132 - val_loss: 628.1828\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 433.7223 - val_loss: 623.1084\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 430.0991 - val_loss: 618.0569\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 106us/step - loss: 426.4931 - val_loss: 613.0258\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 422.8960 - val_loss: 608.1530\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 419.3429 - val_loss: 603.3390\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 105us/step - loss: 415.9317 - val_loss: 598.4699\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 412.5100 - val_loss: 593.6786\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 409.0815 - val_loss: 588.9622\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 405.7070 - val_loss: 584.3704\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 402.4793 - val_loss: 579.6588\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 399.1028 - val_loss: 575.1328\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 395.9298 - val_loss: 570.4745\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 392.7373 - val_loss: 565.9565\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 389.7042 - val_loss: 562.1124\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 386.9062 - val_loss: 558.3715\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 98us/step - loss: 384.2435 - val_loss: 554.4418\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 381.4884 - val_loss: 550.5917\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 378.7573 - val_loss: 546.8571\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 376.1590 - val_loss: 543.1393\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 373.5232 - val_loss: 539.3966\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 370.9242 - val_loss: 535.7020\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 368.3393 - val_loss: 532.0632\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 365.7689 - val_loss: 528.6847\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 363.3050 - val_loss: 525.1465\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 360.8622 - val_loss: 521.4654\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 136us/step - loss: 358.3279 - val_loss: 517.8675\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 355.8546 - val_loss: 514.3820\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 353.4809 - val_loss: 510.9534\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 351.0024 - val_loss: 507.6313\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 348.7013 - val_loss: 504.2355\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 346.3734 - val_loss: 500.9103\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 344.1383 - val_loss: 497.5811\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 341.8463 - val_loss: 494.2918\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 339.5528 - val_loss: 491.0785\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 337.3507 - val_loss: 487.9055\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 335.1744 - val_loss: 484.8139\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 333.0107 - val_loss: 481.7037\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 330.8469 - val_loss: 478.6822\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 328.7879 - val_loss: 475.5989\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 326.7162 - val_loss: 472.6412\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 324.6350 - val_loss: 469.7961\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 322.6437 - val_loss: 466.7889\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 320.6008 - val_loss: 463.8641\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 318.6061 - val_loss: 460.8999\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 100us/step - loss: 316.6059 - val_loss: 457.8840\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 314.6368 - val_loss: 454.9861\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 312.7198 - val_loss: 452.0646\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 310.7377 - val_loss: 449.2934\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 308.8230 - val_loss: 446.5094\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 306.9857 - val_loss: 443.7084\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 305.1005 - val_loss: 441.0701\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 303.3482 - val_loss: 438.4500\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 301.5053 - val_loss: 435.8050\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 299.6676 - val_loss: 433.1934\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 297.8855 - val_loss: 430.5784\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 296.1502 - val_loss: 428.0078\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 294.4221 - val_loss: 425.5124\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 292.7450 - val_loss: 423.0349\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 291.1018 - val_loss: 420.5079\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 289.4174 - val_loss: 418.1831\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 287.8123 - val_loss: 415.7610\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 286.1796 - val_loss: 413.2623\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 284.5464 - val_loss: 410.7662\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 282.9751 - val_loss: 408.6851\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 281.5484 - val_loss: 406.6154\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 280.2294 - val_loss: 404.4500\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 278.8361 - val_loss: 402.3589\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 277.5788 - val_loss: 400.3161\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 276.1335 - val_loss: 398.4469\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 274.8976 - val_loss: 396.5193\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 273.6018 - val_loss: 394.5701\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 272.2994 - val_loss: 392.6366\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 271.0321 - val_loss: 390.5596\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 269.7122 - val_loss: 388.6582\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 268.4949 - val_loss: 386.8148\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 267.2873 - val_loss: 384.8776\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 266.0768 - val_loss: 382.9068\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 264.8077 - val_loss: 381.0787\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 263.6301 - val_loss: 379.2180\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 262.4879 - val_loss: 377.4677\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 261.3214 - val_loss: 375.6440\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 260.1659 - val_loss: 373.8711\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 120us/step - loss: 259.0411 - val_loss: 372.1096\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 120us/step - loss: 257.9417 - val_loss: 370.3668\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 256.8476 - val_loss: 368.6381\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 255.7613 - val_loss: 366.9438\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 254.6643 - val_loss: 365.2847\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 253.6407 - val_loss: 363.5789\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 252.5701 - val_loss: 361.9516\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 251.5163 - val_loss: 360.4172\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 250.5348 - val_loss: 358.7314\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 249.5402 - val_loss: 357.1032\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 248.5107 - val_loss: 355.6094\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 247.5505 - val_loss: 353.9963\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 246.5817 - val_loss: 352.4917\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 245.5860 - val_loss: 350.9728\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 244.6154 - val_loss: 349.4901\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 243.6757 - val_loss: 347.9020\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 242.7173 - val_loss: 346.4205\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 241.8199 - val_loss: 344.9935\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 240.9236 - val_loss: 343.5784\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 239.9162 - val_loss: 342.3300\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 238.8951 - val_loss: 340.9690\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 237.6570 - val_loss: 339.4471\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 236.5347 - val_loss: 338.1709\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 235.6783 - val_loss: 336.7621\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 234.7450 - val_loss: 335.2820\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 233.8165 - val_loss: 334.0589\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 233.0030 - val_loss: 332.7109\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 232.1242 - val_loss: 331.3706\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 231.3312 - val_loss: 330.1573\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 230.5486 - val_loss: 328.7678\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 229.7114 - val_loss: 327.5944\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 229.0030 - val_loss: 326.3816\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 228.2353 - val_loss: 325.2476\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 227.6139 - val_loss: 324.1465\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 226.8537 - val_loss: 323.0233\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 226.1205 - val_loss: 321.8486\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 225.2772 - val_loss: 320.6767\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 224.3712 - val_loss: 319.6051\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 223.5888 - val_loss: 318.5720\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 222.9211 - val_loss: 317.4606\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 222.1039 - val_loss: 316.4304\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 221.4294 - val_loss: 315.2950\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 220.7462 - val_loss: 314.1203\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 220.0629 - val_loss: 313.0082\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 219.4358 - val_loss: 311.8934\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 218.6726 - val_loss: 310.8597\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 217.9547 - val_loss: 309.7521\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 217.2914 - val_loss: 308.7342\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 216.7033 - val_loss: 307.7926\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 216.0390 - val_loss: 306.7020\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 215.3989 - val_loss: 305.6975\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 214.8318 - val_loss: 304.5515\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 214.1752 - val_loss: 303.5825\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 213.5983 - val_loss: 302.4943\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 212.9735 - val_loss: 301.6104\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 212.4643 - val_loss: 300.6343\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 211.8449 - val_loss: 299.6947\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 211.1919 - val_loss: 298.8180\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 210.6458 - val_loss: 297.9237\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 210.0693 - val_loss: 297.1153\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 209.8346 - val_loss: 296.2533\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 209.0143 - val_loss: 295.2765\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 208.4078 - val_loss: 294.5068\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 208.0005 - val_loss: 293.5818\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 207.3934 - val_loss: 292.6451\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 206.8583 - val_loss: 291.7727\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 206.4615 - val_loss: 290.8530\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 205.7764 - val_loss: 290.2042\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 205.3748 - val_loss: 289.2959\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 204.8679 - val_loss: 288.4917\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 204.3488 - val_loss: 287.6294\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 203.7731 - val_loss: 286.7863\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 203.2792 - val_loss: 285.9455\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 202.7597 - val_loss: 285.2039\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 202.3060 - val_loss: 284.3262\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 201.7537 - val_loss: 283.4911\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 201.2643 - val_loss: 282.6667\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 200.7217 - val_loss: 281.8618\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 200.2558 - val_loss: 281.0271\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 199.8437 - val_loss: 280.2042\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 199.2553 - val_loss: 279.4030\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 198.7662 - val_loss: 278.7172\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 198.3678 - val_loss: 277.9879\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 197.9143 - val_loss: 277.3635\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 197.4163 - val_loss: 276.7204\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 197.0049 - val_loss: 276.1096\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 196.5813 - val_loss: 275.4056\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 196.1156 - val_loss: 274.7669\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 195.7323 - val_loss: 274.1176\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.00059049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 96us/step - loss: 195.3469 - val_loss: 273.4999\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 194.9094 - val_loss: 272.9581\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 194.5719 - val_loss: 272.4248\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 194.1732 - val_loss: 271.7930\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 193.7587 - val_loss: 271.1948\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 193.3789 - val_loss: 270.6753\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 193.0039 - val_loss: 270.0623\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 192.6591 - val_loss: 269.3891\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 192.2616 - val_loss: 268.8875\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 191.8970 - val_loss: 268.3600\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 191.6509 - val_loss: 267.8125\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 191.1703 - val_loss: 267.1849\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 190.8389 - val_loss: 266.6605\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 190.5789 - val_loss: 266.0289\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 190.1293 - val_loss: 265.3941\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 189.8038 - val_loss: 264.9368\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 189.5286 - val_loss: 264.5678\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 189.2547 - val_loss: 264.0268\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 188.8855 - val_loss: 263.5536\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 188.5168 - val_loss: 263.0365\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 188.1625 - val_loss: 262.5942\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 187.7690 - val_loss: 262.1701\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 187.4203 - val_loss: 261.5465\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 187.0913 - val_loss: 261.0259\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 186.7271 - val_loss: 260.5829\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 186.4724 - val_loss: 260.2166\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 186.1325 - val_loss: 259.7893\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 185.8135 - val_loss: 259.4192\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 185.4813 - val_loss: 258.8529\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 185.3709 - val_loss: 258.3889\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 102us/step - loss: 184.9429 - val_loss: 257.9491\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 107us/step - loss: 184.6568 - val_loss: 257.5632\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 184.4324 - val_loss: 256.9576\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 184.1886 - val_loss: 256.6811\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 183.8203 - val_loss: 256.3477\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 183.5834 - val_loss: 255.9627\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 183.3995 - val_loss: 255.5096\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 105us/step - loss: 183.0428 - val_loss: 255.1189\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 182.8610 - val_loss: 254.6955\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 182.5396 - val_loss: 254.2760\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 182.2986 - val_loss: 253.7917\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 182.1625 - val_loss: 253.4258\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 181.8515 - val_loss: 252.9682\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 181.6228 - val_loss: 252.6345\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 181.4573 - val_loss: 252.3446\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.000531441.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 181.2271 - val_loss: 251.9880\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 181.0223 - val_loss: 251.6886\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 180.8253 - val_loss: 251.3344\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 180.6205 - val_loss: 251.0348\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 180.4244 - val_loss: 250.7910\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 180.2442 - val_loss: 250.4548\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 180.0962 - val_loss: 250.1727\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 179.9002 - val_loss: 249.8488\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 179.7193 - val_loss: 249.5169\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 179.5327 - val_loss: 249.2830\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 179.4223 - val_loss: 248.9719\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 179.1575 - val_loss: 248.7532\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 179.0592 - val_loss: 248.4797\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 178.7950 - val_loss: 248.2122\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 178.6693 - val_loss: 247.8092\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 178.5439 - val_loss: 247.6025\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 178.2567 - val_loss: 247.2633\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 178.0975 - val_loss: 246.9965\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 177.9063 - val_loss: 246.6525\n",
      "Epoch 322/2000\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 177.7092 - val_loss: 246.3038\n",
      "Epoch 323/2000\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 177.5451 - val_loss: 245.9223\n",
      "Epoch 324/2000\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 177.4096 - val_loss: 245.6049\n",
      "Epoch 325/2000\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 177.2007 - val_loss: 245.3298\n",
      "Epoch 326/2000\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 177.0200 - val_loss: 245.1624\n",
      "Epoch 327/2000\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 176.8323 - val_loss: 244.9352\n",
      "Epoch 328/2000\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 176.6899 - val_loss: 244.7467\n",
      "Epoch 329/2000\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 176.4884 - val_loss: 244.5302\n",
      "Epoch 330/2000\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 176.3530 - val_loss: 244.1962\n",
      "Epoch 331/2000\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 176.1940 - val_loss: 243.9429\n",
      "Epoch 332/2000\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 176.0342 - val_loss: 243.7577\n",
      "Epoch 333/2000\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 175.9024 - val_loss: 243.5439\n",
      "Epoch 334/2000\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 175.7535 - val_loss: 243.3321\n",
      "Epoch 335/2000\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 175.6317 - val_loss: 242.9462\n",
      "Epoch 336/2000\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 175.4338 - val_loss: 242.7280\n",
      "Epoch 337/2000\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 175.2876 - val_loss: 242.5860\n",
      "Epoch 338/2000\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 175.1396 - val_loss: 242.2893\n",
      "Epoch 339/2000\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 175.0137 - val_loss: 241.9803\n",
      "Epoch 340/2000\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 174.8370 - val_loss: 241.7679\n",
      "Epoch 341/2000\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 174.7025 - val_loss: 241.5537\n",
      "Epoch 342/2000\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 174.5765 - val_loss: 241.5519\n",
      "Epoch 343/2000\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 174.4326 - val_loss: 241.2275\n",
      "Epoch 344/2000\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 174.2750 - val_loss: 241.0567\n",
      "Epoch 345/2000\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 174.1449 - val_loss: 240.7993\n",
      "Epoch 346/2000\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 174.0184 - val_loss: 240.7557\n",
      "Epoch 347/2000\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 173.8633 - val_loss: 240.4246\n",
      "Epoch 348/2000\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 0.000531441.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 96us/step - loss: 173.7238 - val_loss: 240.1449\n",
      "Epoch 349/2000\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 173.6031 - val_loss: 239.9717\n",
      "Epoch 350/2000\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 173.4632 - val_loss: 239.7739\n",
      "Epoch 351/2000\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 116us/step - loss: 173.3541 - val_loss: 239.5386\n",
      "Epoch 352/2000\n",
      "\n",
      "Epoch 00352: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 120us/step - loss: 173.2880 - val_loss: 239.3443\n",
      "Epoch 353/2000\n",
      "\n",
      "Epoch 00353: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 173.1282 - val_loss: 239.2971\n",
      "Epoch 354/2000\n",
      "\n",
      "Epoch 00354: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 172.9834 - val_loss: 239.3914\n",
      "Epoch 355/2000\n",
      "\n",
      "Epoch 00355: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 172.8450 - val_loss: 239.2400\n",
      "Epoch 356/2000\n",
      "\n",
      "Epoch 00356: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 172.7445 - val_loss: 239.1787\n",
      "Epoch 357/2000\n",
      "\n",
      "Epoch 00357: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 172.5885 - val_loss: 239.2252\n",
      "Epoch 358/2000\n",
      "\n",
      "Epoch 00358: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 172.4813 - val_loss: 239.3252\n",
      "Epoch 359/2000\n",
      "\n",
      "Epoch 00359: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 172.3696 - val_loss: 239.4783\n",
      "Epoch 360/2000\n",
      "\n",
      "Epoch 00360: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 172.2241 - val_loss: 239.3498\n",
      "Epoch 361/2000\n",
      "\n",
      "Epoch 00361: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 172.1276 - val_loss: 239.3313\n",
      "Epoch 362/2000\n",
      "\n",
      "Epoch 00362: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 172.0043 - val_loss: 239.4133\n",
      "Epoch 363/2000\n",
      "\n",
      "Epoch 00363: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 171.8515 - val_loss: 239.1472\n",
      "Epoch 364/2000\n",
      "\n",
      "Epoch 00364: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 120us/step - loss: 171.7736 - val_loss: 239.1580\n",
      "Epoch 365/2000\n",
      "\n",
      "Epoch 00365: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 171.6760 - val_loss: 238.8880\n",
      "Epoch 366/2000\n",
      "\n",
      "Epoch 00366: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 171.6143 - val_loss: 238.9473\n",
      "Epoch 367/2000\n",
      "\n",
      "Epoch 00367: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 171.4417 - val_loss: 238.8535\n",
      "Epoch 368/2000\n",
      "\n",
      "Epoch 00368: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 171.3032 - val_loss: 238.5626\n",
      "Epoch 369/2000\n",
      "\n",
      "Epoch 00369: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 171.1797 - val_loss: 238.5444\n",
      "Epoch 370/2000\n",
      "\n",
      "Epoch 00370: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 171.1378 - val_loss: 238.3569\n",
      "Epoch 371/2000\n",
      "\n",
      "Epoch 00371: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 171.0189 - val_loss: 238.3851\n",
      "Epoch 372/2000\n",
      "\n",
      "Epoch 00372: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 170.8810 - val_loss: 238.3394\n",
      "Epoch 373/2000\n",
      "\n",
      "Epoch 00373: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 170.8036 - val_loss: 238.0443\n",
      "Epoch 374/2000\n",
      "\n",
      "Epoch 00374: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 170.7397 - val_loss: 237.8408\n",
      "Epoch 375/2000\n",
      "\n",
      "Epoch 00375: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 170.5536 - val_loss: 237.9820\n",
      "Epoch 376/2000\n",
      "\n",
      "Epoch 00376: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 170.4887 - val_loss: 237.9781\n",
      "Epoch 377/2000\n",
      "\n",
      "Epoch 00377: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 170.4901 - val_loss: 237.8853\n",
      "Epoch 378/2000\n",
      "\n",
      "Epoch 00378: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 170.3077 - val_loss: 237.6718\n",
      "Epoch 379/2000\n",
      "\n",
      "Epoch 00379: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 170.1772 - val_loss: 237.4710\n",
      "Epoch 380/2000\n",
      "\n",
      "Epoch 00380: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 170.1390 - val_loss: 237.2965\n",
      "Epoch 381/2000\n",
      "\n",
      "Epoch 00381: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 169.9831 - val_loss: 237.0767\n",
      "Epoch 382/2000\n",
      "\n",
      "Epoch 00382: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 169.9086 - val_loss: 236.7208\n",
      "Epoch 383/2000\n",
      "\n",
      "Epoch 00383: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 169.7975 - val_loss: 236.5462\n",
      "Epoch 384/2000\n",
      "\n",
      "Epoch 00384: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 169.7165 - val_loss: 236.4723\n",
      "Epoch 385/2000\n",
      "\n",
      "Epoch 00385: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 169.6211 - val_loss: 236.3782\n",
      "Epoch 386/2000\n",
      "\n",
      "Epoch 00386: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 169.5454 - val_loss: 236.3385\n",
      "Epoch 387/2000\n",
      "\n",
      "Epoch 00387: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 169.4509 - val_loss: 236.4304\n",
      "Epoch 388/2000\n",
      "\n",
      "Epoch 00388: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 169.3555 - val_loss: 236.2971\n",
      "Epoch 389/2000\n",
      "\n",
      "Epoch 00389: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 169.2858 - val_loss: 236.2369\n",
      "Epoch 390/2000\n",
      "\n",
      "Epoch 00390: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 100us/step - loss: 169.1744 - val_loss: 236.1076\n",
      "Epoch 391/2000\n",
      "\n",
      "Epoch 00391: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 169.0882 - val_loss: 236.1066\n",
      "Epoch 392/2000\n",
      "\n",
      "Epoch 00392: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 169.0367 - val_loss: 236.0099\n",
      "Epoch 393/2000\n",
      "\n",
      "Epoch 00393: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 168.9403 - val_loss: 235.9516\n",
      "Epoch 394/2000\n",
      "\n",
      "Epoch 00394: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 168.9023 - val_loss: 235.8077\n",
      "Epoch 395/2000\n",
      "\n",
      "Epoch 00395: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 168.8247 - val_loss: 235.5506\n",
      "Epoch 396/2000\n",
      "\n",
      "Epoch 00396: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 168.7086 - val_loss: 235.4436\n",
      "Epoch 397/2000\n",
      "\n",
      "Epoch 00397: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 168.6676 - val_loss: 235.4682\n",
      "Epoch 398/2000\n",
      "\n",
      "Epoch 00398: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 168.5418 - val_loss: 235.3258\n",
      "Epoch 399/2000\n",
      "\n",
      "Epoch 00399: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 168.4299 - val_loss: 235.1323\n",
      "Epoch 400/2000\n",
      "\n",
      "Epoch 00400: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 168.4032 - val_loss: 235.0760\n",
      "Epoch 401/2000\n",
      "\n",
      "Epoch 00401: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 168.3359 - val_loss: 234.9740\n",
      "Epoch 402/2000\n",
      "\n",
      "Epoch 00402: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 168.2429 - val_loss: 234.8728\n",
      "Epoch 403/2000\n",
      "\n",
      "Epoch 00403: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 168.1367 - val_loss: 234.7457\n",
      "Epoch 404/2000\n",
      "\n",
      "Epoch 00404: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 168.0936 - val_loss: 234.5926\n",
      "Epoch 405/2000\n",
      "\n",
      "Epoch 00405: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 168.0408 - val_loss: 234.4870\n",
      "Epoch 406/2000\n",
      "\n",
      "Epoch 00406: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.9974 - val_loss: 234.4248\n",
      "Epoch 407/2000\n",
      "\n",
      "Epoch 00407: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.9020 - val_loss: 234.3473\n",
      "Epoch 408/2000\n",
      "\n",
      "Epoch 00408: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 167.8380 - val_loss: 234.2207\n",
      "Epoch 409/2000\n",
      "\n",
      "Epoch 00409: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.7861 - val_loss: 234.1376\n",
      "Epoch 410/2000\n",
      "\n",
      "Epoch 00410: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 167.7352 - val_loss: 234.1648\n",
      "Epoch 411/2000\n",
      "\n",
      "Epoch 00411: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.6476 - val_loss: 234.1231\n",
      "Epoch 412/2000\n",
      "\n",
      "Epoch 00412: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.5729 - val_loss: 234.0546\n",
      "Epoch 413/2000\n",
      "\n",
      "Epoch 00413: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 167.5322 - val_loss: 233.9785\n",
      "Epoch 414/2000\n",
      "\n",
      "Epoch 00414: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 167.4672 - val_loss: 233.9285\n",
      "Epoch 415/2000\n",
      "\n",
      "Epoch 00415: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 167.4264 - val_loss: 233.9108\n",
      "Epoch 416/2000\n",
      "\n",
      "Epoch 00416: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.3609 - val_loss: 233.8244\n",
      "Epoch 417/2000\n",
      "\n",
      "Epoch 00417: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.3005 - val_loss: 233.8604\n",
      "Epoch 418/2000\n",
      "\n",
      "Epoch 00418: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.2552 - val_loss: 233.8242\n",
      "Epoch 419/2000\n",
      "\n",
      "Epoch 00419: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.1944 - val_loss: 233.8441\n",
      "Epoch 420/2000\n",
      "\n",
      "Epoch 00420: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 167.1897 - val_loss: 233.6811\n",
      "Epoch 421/2000\n",
      "\n",
      "Epoch 00421: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.0915 - val_loss: 233.6014\n",
      "Epoch 422/2000\n",
      "\n",
      "Epoch 00422: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 167.0471 - val_loss: 233.4621\n",
      "Epoch 423/2000\n",
      "\n",
      "Epoch 00423: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 166.9804 - val_loss: 233.4871\n",
      "Epoch 424/2000\n",
      "\n",
      "Epoch 00424: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 166.8864 - val_loss: 233.2596\n",
      "Epoch 425/2000\n",
      "\n",
      "Epoch 00425: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 166.8373 - val_loss: 233.2000\n",
      "Epoch 426/2000\n",
      "\n",
      "Epoch 00426: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 166.7749 - val_loss: 233.1153\n",
      "Epoch 427/2000\n",
      "\n",
      "Epoch 00427: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 166.7198 - val_loss: 233.1113\n",
      "Epoch 428/2000\n",
      "\n",
      "Epoch 00428: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 166.6857 - val_loss: 232.9913\n",
      "Epoch 429/2000\n",
      "\n",
      "Epoch 00429: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 166.6042 - val_loss: 232.9239\n",
      "Epoch 430/2000\n",
      "\n",
      "Epoch 00430: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 166.6105 - val_loss: 232.7302\n",
      "Epoch 431/2000\n",
      "\n",
      "Epoch 00431: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 166.5528 - val_loss: 232.7542\n",
      "Epoch 432/2000\n",
      "\n",
      "Epoch 00432: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 106us/step - loss: 166.4543 - val_loss: 232.8598\n",
      "Epoch 433/2000\n",
      "\n",
      "Epoch 00433: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 166.4004 - val_loss: 232.7785\n",
      "Epoch 434/2000\n",
      "\n",
      "Epoch 00434: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 166.3823 - val_loss: 232.6896\n",
      "Epoch 435/2000\n",
      "\n",
      "Epoch 00435: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 166.3170 - val_loss: 232.6516\n",
      "Epoch 436/2000\n",
      "\n",
      "Epoch 00436: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 166.2703 - val_loss: 232.6982\n",
      "Epoch 437/2000\n",
      "\n",
      "Epoch 00437: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 166.2169 - val_loss: 232.7109\n",
      "Epoch 438/2000\n",
      "\n",
      "Epoch 00438: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 105us/step - loss: 166.1807 - val_loss: 232.6876\n",
      "Epoch 439/2000\n",
      "\n",
      "Epoch 00439: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 166.1721 - val_loss: 232.6228\n",
      "Epoch 440/2000\n",
      "\n",
      "Epoch 00440: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 166.0903 - val_loss: 232.6470\n",
      "Epoch 441/2000\n",
      "\n",
      "Epoch 00441: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 166.0444 - val_loss: 232.6331\n",
      "Epoch 442/2000\n",
      "\n",
      "Epoch 00442: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.9838 - val_loss: 232.5532\n",
      "Epoch 443/2000\n",
      "\n",
      "Epoch 00443: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 165.9495 - val_loss: 232.4781\n",
      "Epoch 444/2000\n",
      "\n",
      "Epoch 00444: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 165.8872 - val_loss: 232.3705\n",
      "Epoch 445/2000\n",
      "\n",
      "Epoch 00445: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 165.8419 - val_loss: 232.2944\n",
      "Epoch 446/2000\n",
      "\n",
      "Epoch 00446: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 165.8040 - val_loss: 232.3383\n",
      "Epoch 447/2000\n",
      "\n",
      "Epoch 00447: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.7550 - val_loss: 232.2722\n",
      "Epoch 448/2000\n",
      "\n",
      "Epoch 00448: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.7748 - val_loss: 232.2989\n",
      "Epoch 449/2000\n",
      "\n",
      "Epoch 00449: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.6697 - val_loss: 232.2476\n",
      "Epoch 450/2000\n",
      "\n",
      "Epoch 00450: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.6591 - val_loss: 232.1798\n",
      "Epoch 451/2000\n",
      "\n",
      "Epoch 00451: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 165.5812 - val_loss: 232.0840\n",
      "Epoch 452/2000\n",
      "\n",
      "Epoch 00452: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.5418 - val_loss: 232.0524\n",
      "Epoch 453/2000\n",
      "\n",
      "Epoch 00453: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.4955 - val_loss: 231.9429\n",
      "Epoch 454/2000\n",
      "\n",
      "Epoch 00454: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.4538 - val_loss: 231.9629\n",
      "Epoch 455/2000\n",
      "\n",
      "Epoch 00455: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.3989 - val_loss: 231.9693\n",
      "Epoch 456/2000\n",
      "\n",
      "Epoch 00456: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 165.3449 - val_loss: 231.9618\n",
      "Epoch 457/2000\n",
      "\n",
      "Epoch 00457: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.3166 - val_loss: 231.9029\n",
      "Epoch 458/2000\n",
      "\n",
      "Epoch 00458: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.2852 - val_loss: 231.8605\n",
      "Epoch 459/2000\n",
      "\n",
      "Epoch 00459: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.2528 - val_loss: 231.9063\n",
      "Epoch 460/2000\n",
      "\n",
      "Epoch 00460: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.1886 - val_loss: 231.9383\n",
      "Epoch 461/2000\n",
      "\n",
      "Epoch 00461: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 165.1475 - val_loss: 231.9015\n",
      "Epoch 462/2000\n",
      "\n",
      "Epoch 00462: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.1618 - val_loss: 232.0340\n",
      "Epoch 463/2000\n",
      "\n",
      "Epoch 00463: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 165.0592 - val_loss: 231.9736\n",
      "Epoch 464/2000\n",
      "\n",
      "Epoch 00464: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 165.0221 - val_loss: 231.9651\n",
      "Epoch 465/2000\n",
      "\n",
      "Epoch 00465: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 165.0124 - val_loss: 231.8632\n",
      "Epoch 466/2000\n",
      "\n",
      "Epoch 00466: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.9511 - val_loss: 231.8285\n",
      "Epoch 467/2000\n",
      "\n",
      "Epoch 00467: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 164.9219 - val_loss: 231.9542\n",
      "Epoch 468/2000\n",
      "\n",
      "Epoch 00468: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.8905 - val_loss: 231.9685\n",
      "Epoch 469/2000\n",
      "\n",
      "Epoch 00469: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.8085 - val_loss: 231.9545\n",
      "Epoch 470/2000\n",
      "\n",
      "Epoch 00470: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 164.7819 - val_loss: 231.8512\n",
      "Epoch 471/2000\n",
      "\n",
      "Epoch 00471: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.7628 - val_loss: 231.8422\n",
      "Epoch 472/2000\n",
      "\n",
      "Epoch 00472: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.7292 - val_loss: 231.8725\n",
      "Epoch 473/2000\n",
      "\n",
      "Epoch 00473: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 164.7024 - val_loss: 231.9488\n",
      "Epoch 474/2000\n",
      "\n",
      "Epoch 00474: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 164.6187 - val_loss: 231.8358\n",
      "Epoch 475/2000\n",
      "\n",
      "Epoch 00475: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 164.5797 - val_loss: 231.8277\n",
      "Epoch 476/2000\n",
      "\n",
      "Epoch 00476: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.5485 - val_loss: 231.7980\n",
      "Epoch 477/2000\n",
      "\n",
      "Epoch 00477: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.4922 - val_loss: 231.7701\n",
      "Epoch 478/2000\n",
      "\n",
      "Epoch 00478: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 164.4647 - val_loss: 231.8246\n",
      "Epoch 479/2000\n",
      "\n",
      "Epoch 00479: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 164.4519 - val_loss: 231.8041\n",
      "Epoch 480/2000\n",
      "\n",
      "Epoch 00480: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 164.3986 - val_loss: 231.7494\n",
      "Epoch 481/2000\n",
      "\n",
      "Epoch 00481: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 164.3510 - val_loss: 231.6942\n",
      "Epoch 482/2000\n",
      "\n",
      "Epoch 00482: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 164.3348 - val_loss: 231.7959\n",
      "Epoch 483/2000\n",
      "\n",
      "Epoch 00483: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 164.2923 - val_loss: 231.7710\n",
      "Epoch 484/2000\n",
      "\n",
      "Epoch 00484: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.2347 - val_loss: 231.6229\n",
      "Epoch 485/2000\n",
      "\n",
      "Epoch 00485: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 164.1944 - val_loss: 231.5918\n",
      "Epoch 486/2000\n",
      "\n",
      "Epoch 00486: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 164.1939 - val_loss: 231.6027\n",
      "Epoch 487/2000\n",
      "\n",
      "Epoch 00487: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.1214 - val_loss: 231.5040\n",
      "Epoch 488/2000\n",
      "\n",
      "Epoch 00488: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 164.0867 - val_loss: 231.4394\n",
      "Epoch 489/2000\n",
      "\n",
      "Epoch 00489: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 164.0591 - val_loss: 231.5057\n",
      "Epoch 490/2000\n",
      "\n",
      "Epoch 00490: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.0324 - val_loss: 231.5289\n",
      "Epoch 491/2000\n",
      "\n",
      "Epoch 00491: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 164.0560 - val_loss: 231.4279\n",
      "Epoch 492/2000\n",
      "\n",
      "Epoch 00492: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.9704 - val_loss: 231.4549\n",
      "Epoch 493/2000\n",
      "\n",
      "Epoch 00493: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.9316 - val_loss: 231.4320\n",
      "Epoch 494/2000\n",
      "\n",
      "Epoch 00494: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.8944 - val_loss: 231.4570\n",
      "Epoch 495/2000\n",
      "\n",
      "Epoch 00495: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.9039 - val_loss: 231.4576\n",
      "Epoch 496/2000\n",
      "\n",
      "Epoch 00496: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.8389 - val_loss: 231.4409\n",
      "Epoch 497/2000\n",
      "\n",
      "Epoch 00497: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 163.7986 - val_loss: 231.4102\n",
      "Epoch 498/2000\n",
      "\n",
      "Epoch 00498: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 163.7703 - val_loss: 231.4472\n",
      "Epoch 499/2000\n",
      "\n",
      "Epoch 00499: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.7142 - val_loss: 231.4226\n",
      "Epoch 500/2000\n",
      "\n",
      "Epoch 00500: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 163.6904 - val_loss: 231.3753\n",
      "Epoch 501/2000\n",
      "\n",
      "Epoch 00501: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.6594 - val_loss: 231.3088\n",
      "Epoch 502/2000\n",
      "\n",
      "Epoch 00502: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 163.6415 - val_loss: 231.2548\n",
      "Epoch 503/2000\n",
      "\n",
      "Epoch 00503: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.5977 - val_loss: 231.2573\n",
      "Epoch 504/2000\n",
      "\n",
      "Epoch 00504: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 163.5524 - val_loss: 231.3023\n",
      "Epoch 505/2000\n",
      "\n",
      "Epoch 00505: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.5900 - val_loss: 231.3269\n",
      "Epoch 506/2000\n",
      "\n",
      "Epoch 00506: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.5206 - val_loss: 231.2826\n",
      "Epoch 507/2000\n",
      "\n",
      "Epoch 00507: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 98us/step - loss: 163.4915 - val_loss: 231.2104\n",
      "Epoch 508/2000\n",
      "\n",
      "Epoch 00508: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 163.4701 - val_loss: 231.2614\n",
      "Epoch 509/2000\n",
      "\n",
      "Epoch 00509: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.4294 - val_loss: 231.2844\n",
      "Epoch 510/2000\n",
      "\n",
      "Epoch 00510: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.4076 - val_loss: 231.2879\n",
      "Epoch 511/2000\n",
      "\n",
      "Epoch 00511: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.3911 - val_loss: 231.2310\n",
      "Epoch 512/2000\n",
      "\n",
      "Epoch 00512: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 163.3919 - val_loss: 231.2506\n",
      "Epoch 513/2000\n",
      "\n",
      "Epoch 00513: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.3202 - val_loss: 231.2463\n",
      "Epoch 514/2000\n",
      "\n",
      "Epoch 00514: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.3099 - val_loss: 231.2014\n",
      "Epoch 515/2000\n",
      "\n",
      "Epoch 00515: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 163.3267 - val_loss: 231.2473\n",
      "Epoch 516/2000\n",
      "\n",
      "Epoch 00516: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 100us/step - loss: 163.2889 - val_loss: 231.2123\n",
      "Epoch 517/2000\n",
      "\n",
      "Epoch 00517: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 163.2410 - val_loss: 231.2288\n",
      "Epoch 518/2000\n",
      "\n",
      "Epoch 00518: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.2077 - val_loss: 231.1388\n",
      "Epoch 519/2000\n",
      "\n",
      "Epoch 00519: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 163.1661 - val_loss: 231.1992\n",
      "Epoch 520/2000\n",
      "\n",
      "Epoch 00520: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.1350 - val_loss: 231.2082\n",
      "Epoch 521/2000\n",
      "\n",
      "Epoch 00521: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.1580 - val_loss: 231.2060\n",
      "Epoch 522/2000\n",
      "\n",
      "Epoch 00522: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.1223 - val_loss: 231.2425\n",
      "Epoch 523/2000\n",
      "\n",
      "Epoch 00523: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.0690 - val_loss: 231.2885\n",
      "Epoch 524/2000\n",
      "\n",
      "Epoch 00524: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 163.0620 - val_loss: 231.2078\n",
      "Epoch 525/2000\n",
      "\n",
      "Epoch 00525: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 163.0220 - val_loss: 231.1786\n",
      "Epoch 526/2000\n",
      "\n",
      "Epoch 00526: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 163.0164 - val_loss: 231.1757\n",
      "Epoch 527/2000\n",
      "\n",
      "Epoch 00527: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.9780 - val_loss: 231.1512\n",
      "Epoch 528/2000\n",
      "\n",
      "Epoch 00528: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.9638 - val_loss: 231.1372\n",
      "Epoch 529/2000\n",
      "\n",
      "Epoch 00529: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.9306 - val_loss: 231.0900\n",
      "Epoch 530/2000\n",
      "\n",
      "Epoch 00530: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 162.8852 - val_loss: 231.0733\n",
      "Epoch 531/2000\n",
      "\n",
      "Epoch 00531: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.9122 - val_loss: 231.0620\n",
      "Epoch 532/2000\n",
      "\n",
      "Epoch 00532: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.8600 - val_loss: 231.0543\n",
      "Epoch 533/2000\n",
      "\n",
      "Epoch 00533: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.8227 - val_loss: 230.9261\n",
      "Epoch 534/2000\n",
      "\n",
      "Epoch 00534: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 162.7850 - val_loss: 230.8553\n",
      "Epoch 535/2000\n",
      "\n",
      "Epoch 00535: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.7444 - val_loss: 230.8654\n",
      "Epoch 536/2000\n",
      "\n",
      "Epoch 00536: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 162.7390 - val_loss: 230.8881\n",
      "Epoch 537/2000\n",
      "\n",
      "Epoch 00537: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 116us/step - loss: 162.7468 - val_loss: 230.8175\n",
      "Epoch 538/2000\n",
      "\n",
      "Epoch 00538: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 162.6986 - val_loss: 230.8031\n",
      "Epoch 539/2000\n",
      "\n",
      "Epoch 00539: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.7216 - val_loss: 230.8289\n",
      "Epoch 540/2000\n",
      "\n",
      "Epoch 00540: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.6324 - val_loss: 230.7893\n",
      "Epoch 541/2000\n",
      "\n",
      "Epoch 00541: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.6211 - val_loss: 230.7912\n",
      "Epoch 542/2000\n",
      "\n",
      "Epoch 00542: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.5876 - val_loss: 230.7301\n",
      "Epoch 543/2000\n",
      "\n",
      "Epoch 00543: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.7004 - val_loss: 230.7387\n",
      "Epoch 544/2000\n",
      "\n",
      "Epoch 00544: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.5081 - val_loss: 230.6100\n",
      "Epoch 545/2000\n",
      "\n",
      "Epoch 00545: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.4859 - val_loss: 230.4387\n",
      "Epoch 546/2000\n",
      "\n",
      "Epoch 00546: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.5698 - val_loss: 230.4414\n",
      "Epoch 547/2000\n",
      "\n",
      "Epoch 00547: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.5074 - val_loss: 230.5205\n",
      "Epoch 548/2000\n",
      "\n",
      "Epoch 00548: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.4920 - val_loss: 230.5566\n",
      "Epoch 549/2000\n",
      "\n",
      "Epoch 00549: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.4233 - val_loss: 230.5727\n",
      "Epoch 550/2000\n",
      "\n",
      "Epoch 00550: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.4358 - val_loss: 230.4610\n",
      "Epoch 551/2000\n",
      "\n",
      "Epoch 00551: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.3892 - val_loss: 230.4537\n",
      "Epoch 552/2000\n",
      "\n",
      "Epoch 00552: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.3500 - val_loss: 230.5150\n",
      "Epoch 553/2000\n",
      "\n",
      "Epoch 00553: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.3412 - val_loss: 230.5240\n",
      "Epoch 554/2000\n",
      "\n",
      "Epoch 00554: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 162.3351 - val_loss: 230.5110\n",
      "Epoch 555/2000\n",
      "\n",
      "Epoch 00555: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.2890 - val_loss: 230.5147\n",
      "Epoch 556/2000\n",
      "\n",
      "Epoch 00556: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.2984 - val_loss: 230.4746\n",
      "Epoch 557/2000\n",
      "\n",
      "Epoch 00557: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.2911 - val_loss: 230.5622\n",
      "Epoch 558/2000\n",
      "\n",
      "Epoch 00558: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 162.2495 - val_loss: 230.5517\n",
      "Epoch 559/2000\n",
      "\n",
      "Epoch 00559: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 162.2452 - val_loss: 230.6418\n",
      "Epoch 560/2000\n",
      "\n",
      "Epoch 00560: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.2072 - val_loss: 230.6301\n",
      "Epoch 561/2000\n",
      "\n",
      "Epoch 00561: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.1877 - val_loss: 230.6636\n",
      "Epoch 562/2000\n",
      "\n",
      "Epoch 00562: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.1588 - val_loss: 230.6070\n",
      "Epoch 563/2000\n",
      "\n",
      "Epoch 00563: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.1669 - val_loss: 230.6485\n",
      "Epoch 564/2000\n",
      "\n",
      "Epoch 00564: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 162.1222 - val_loss: 230.5851\n",
      "Epoch 565/2000\n",
      "\n",
      "Epoch 00565: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 162.1158 - val_loss: 230.5192\n",
      "Epoch 566/2000\n",
      "\n",
      "Epoch 00566: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 102us/step - loss: 162.0768 - val_loss: 230.4691\n",
      "Epoch 567/2000\n",
      "\n",
      "Epoch 00567: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 162.0832 - val_loss: 230.4022\n",
      "Epoch 568/2000\n",
      "\n",
      "Epoch 00568: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.0714 - val_loss: 230.4380\n",
      "Epoch 569/2000\n",
      "\n",
      "Epoch 00569: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.1077 - val_loss: 230.3127\n",
      "Epoch 570/2000\n",
      "\n",
      "Epoch 00570: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.0480 - val_loss: 230.2879\n",
      "Epoch 571/2000\n",
      "\n",
      "Epoch 00571: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 162.0258 - val_loss: 230.3256\n",
      "Epoch 572/2000\n",
      "\n",
      "Epoch 00572: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 162.0172 - val_loss: 230.2418\n",
      "Epoch 573/2000\n",
      "\n",
      "Epoch 00573: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 98us/step - loss: 161.9249 - val_loss: 230.2436\n",
      "Epoch 574/2000\n",
      "\n",
      "Epoch 00574: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 95us/step - loss: 161.9638 - val_loss: 230.2652\n",
      "Epoch 575/2000\n",
      "\n",
      "Epoch 00575: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.9338 - val_loss: 230.2578\n",
      "Epoch 576/2000\n",
      "\n",
      "Epoch 00576: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.9021 - val_loss: 230.2353\n",
      "Epoch 577/2000\n",
      "\n",
      "Epoch 00577: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.8944 - val_loss: 230.2165\n",
      "Epoch 578/2000\n",
      "\n",
      "Epoch 00578: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.8697 - val_loss: 230.1409\n",
      "Epoch 579/2000\n",
      "\n",
      "Epoch 00579: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.8476 - val_loss: 230.0957\n",
      "Epoch 580/2000\n",
      "\n",
      "Epoch 00580: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.8299 - val_loss: 230.1012\n",
      "Epoch 581/2000\n",
      "\n",
      "Epoch 00581: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.7871 - val_loss: 230.0881\n",
      "Epoch 582/2000\n",
      "\n",
      "Epoch 00582: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.8007 - val_loss: 230.0869\n",
      "Epoch 583/2000\n",
      "\n",
      "Epoch 00583: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.7621 - val_loss: 230.0880\n",
      "Epoch 584/2000\n",
      "\n",
      "Epoch 00584: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.7662 - val_loss: 230.0180\n",
      "Epoch 585/2000\n",
      "\n",
      "Epoch 00585: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.7276 - val_loss: 230.0423\n",
      "Epoch 586/2000\n",
      "\n",
      "Epoch 00586: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.7098 - val_loss: 230.0962\n",
      "Epoch 587/2000\n",
      "\n",
      "Epoch 00587: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.6946 - val_loss: 230.0977\n",
      "Epoch 588/2000\n",
      "\n",
      "Epoch 00588: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 94us/step - loss: 161.6877 - val_loss: 230.1026\n",
      "Epoch 589/2000\n",
      "\n",
      "Epoch 00589: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 161.6658 - val_loss: 230.1263\n",
      "Epoch 590/2000\n",
      "\n",
      "Epoch 00590: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 107us/step - loss: 161.6497 - val_loss: 230.1169\n",
      "Epoch 591/2000\n",
      "\n",
      "Epoch 00591: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 161.6257 - val_loss: 230.1000\n",
      "Epoch 592/2000\n",
      "\n",
      "Epoch 00592: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 161.6374 - val_loss: 230.0584\n",
      "Epoch 593/2000\n",
      "\n",
      "Epoch 00593: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 95us/step - loss: 161.5879 - val_loss: 230.0953\n",
      "Epoch 594/2000\n",
      "\n",
      "Epoch 00594: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 161.5912 - val_loss: 230.1001\n",
      "Epoch 595/2000\n",
      "\n",
      "Epoch 00595: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.5769 - val_loss: 230.0894\n",
      "Epoch 596/2000\n",
      "\n",
      "Epoch 00596: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.5422 - val_loss: 230.0757\n",
      "Epoch 597/2000\n",
      "\n",
      "Epoch 00597: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.5286 - val_loss: 230.0525\n",
      "Epoch 598/2000\n",
      "\n",
      "Epoch 00598: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.4974 - val_loss: 230.0600\n",
      "Epoch 599/2000\n",
      "\n",
      "Epoch 00599: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.4783 - val_loss: 230.0317\n",
      "Epoch 600/2000\n",
      "\n",
      "Epoch 00600: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 161.4650 - val_loss: 229.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2000\n",
      "\n",
      "Epoch 00601: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 136us/step - loss: 161.4460 - val_loss: 229.9959\n",
      "Epoch 602/2000\n",
      "\n",
      "Epoch 00602: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 116us/step - loss: 161.4527 - val_loss: 230.0228\n",
      "Epoch 603/2000\n",
      "\n",
      "Epoch 00603: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.4343 - val_loss: 230.0243\n",
      "Epoch 604/2000\n",
      "\n",
      "Epoch 00604: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.4747 - val_loss: 230.0716\n",
      "Epoch 605/2000\n",
      "\n",
      "Epoch 00605: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.4056 - val_loss: 229.9957\n",
      "Epoch 606/2000\n",
      "\n",
      "Epoch 00606: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.3691 - val_loss: 229.9994\n",
      "Epoch 607/2000\n",
      "\n",
      "Epoch 00607: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.3718 - val_loss: 230.0415\n",
      "Epoch 608/2000\n",
      "\n",
      "Epoch 00608: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.3653 - val_loss: 230.0391\n",
      "Epoch 609/2000\n",
      "\n",
      "Epoch 00609: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.3327 - val_loss: 229.9975\n",
      "Epoch 610/2000\n",
      "\n",
      "Epoch 00610: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.3142 - val_loss: 229.9932\n",
      "Epoch 611/2000\n",
      "\n",
      "Epoch 00611: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.2960 - val_loss: 230.0049\n",
      "Epoch 612/2000\n",
      "\n",
      "Epoch 00612: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.2995 - val_loss: 229.9785\n",
      "Epoch 613/2000\n",
      "\n",
      "Epoch 00613: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.2888 - val_loss: 230.0182\n",
      "Epoch 614/2000\n",
      "\n",
      "Epoch 00614: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.2945 - val_loss: 230.0024\n",
      "Epoch 615/2000\n",
      "\n",
      "Epoch 00615: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.2383 - val_loss: 230.0097\n",
      "Epoch 616/2000\n",
      "\n",
      "Epoch 00616: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.2253 - val_loss: 230.0411\n",
      "Epoch 617/2000\n",
      "\n",
      "Epoch 00617: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.2227 - val_loss: 230.0439\n",
      "Epoch 618/2000\n",
      "\n",
      "Epoch 00618: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.1964 - val_loss: 230.0727\n",
      "Epoch 619/2000\n",
      "\n",
      "Epoch 00619: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 161.2469 - val_loss: 230.0797\n",
      "Epoch 620/2000\n",
      "\n",
      "Epoch 00620: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.1643 - val_loss: 230.0693\n",
      "Epoch 621/2000\n",
      "\n",
      "Epoch 00621: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.1539 - val_loss: 230.0796\n",
      "Epoch 622/2000\n",
      "\n",
      "Epoch 00622: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.1402 - val_loss: 230.0324\n",
      "Epoch 623/2000\n",
      "\n",
      "Epoch 00623: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 161.1623 - val_loss: 229.9991\n",
      "Epoch 624/2000\n",
      "\n",
      "Epoch 00624: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.1086 - val_loss: 229.9457\n",
      "Epoch 625/2000\n",
      "\n",
      "Epoch 00625: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.0910 - val_loss: 229.9312\n",
      "Epoch 626/2000\n",
      "\n",
      "Epoch 00626: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.0775 - val_loss: 229.9904\n",
      "Epoch 627/2000\n",
      "\n",
      "Epoch 00627: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.0685 - val_loss: 229.9622\n",
      "Epoch 628/2000\n",
      "\n",
      "Epoch 00628: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 102us/step - loss: 161.0699 - val_loss: 229.8995\n",
      "Epoch 629/2000\n",
      "\n",
      "Epoch 00629: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 161.0339 - val_loss: 229.9041\n",
      "Epoch 630/2000\n",
      "\n",
      "Epoch 00630: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.0518 - val_loss: 229.9366\n",
      "Epoch 631/2000\n",
      "\n",
      "Epoch 00631: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 161.0255 - val_loss: 229.9480\n",
      "Epoch 632/2000\n",
      "\n",
      "Epoch 00632: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 160.9914 - val_loss: 229.9573\n",
      "Epoch 633/2000\n",
      "\n",
      "Epoch 00633: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 160.9776 - val_loss: 229.9404\n",
      "Epoch 634/2000\n",
      "\n",
      "Epoch 00634: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 160.9576 - val_loss: 229.9112\n",
      "Epoch 635/2000\n",
      "\n",
      "Epoch 00635: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.9586 - val_loss: 229.8659\n",
      "Epoch 636/2000\n",
      "\n",
      "Epoch 00636: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.9342 - val_loss: 229.8428\n",
      "Epoch 637/2000\n",
      "\n",
      "Epoch 00637: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.9407 - val_loss: 229.8638\n",
      "Epoch 638/2000\n",
      "\n",
      "Epoch 00638: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.9239 - val_loss: 229.8420\n",
      "Epoch 639/2000\n",
      "\n",
      "Epoch 00639: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.8939 - val_loss: 229.8458\n",
      "Epoch 640/2000\n",
      "\n",
      "Epoch 00640: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.8897 - val_loss: 229.8690\n",
      "Epoch 641/2000\n",
      "\n",
      "Epoch 00641: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.8783 - val_loss: 229.8164\n",
      "Epoch 642/2000\n",
      "\n",
      "Epoch 00642: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 160.8697 - val_loss: 229.8222\n",
      "Epoch 643/2000\n",
      "\n",
      "Epoch 00643: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 160.8625 - val_loss: 229.8733\n",
      "Epoch 644/2000\n",
      "\n",
      "Epoch 00644: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.8343 - val_loss: 229.8840\n",
      "Epoch 645/2000\n",
      "\n",
      "Epoch 00645: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.8291 - val_loss: 229.8623\n",
      "Epoch 646/2000\n",
      "\n",
      "Epoch 00646: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.7883 - val_loss: 229.8408\n",
      "Epoch 647/2000\n",
      "\n",
      "Epoch 00647: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.8095 - val_loss: 229.8449\n",
      "Epoch 648/2000\n",
      "\n",
      "Epoch 00648: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.7721 - val_loss: 229.8145\n",
      "Epoch 649/2000\n",
      "\n",
      "Epoch 00649: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.7619 - val_loss: 229.8463\n",
      "Epoch 650/2000\n",
      "\n",
      "Epoch 00650: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.7356 - val_loss: 229.8520\n",
      "Epoch 651/2000\n",
      "\n",
      "Epoch 00651: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 160.7249 - val_loss: 229.8275\n",
      "Epoch 652/2000\n",
      "\n",
      "Epoch 00652: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.7218 - val_loss: 229.8437\n",
      "Epoch 653/2000\n",
      "\n",
      "Epoch 00653: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.7089 - val_loss: 229.8011\n",
      "Epoch 654/2000\n",
      "\n",
      "Epoch 00654: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.7400 - val_loss: 229.7974\n",
      "Epoch 655/2000\n",
      "\n",
      "Epoch 00655: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.6751 - val_loss: 229.8335\n",
      "Epoch 656/2000\n",
      "\n",
      "Epoch 00656: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.6589 - val_loss: 229.8021\n",
      "Epoch 657/2000\n",
      "\n",
      "Epoch 00657: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.6427 - val_loss: 229.7966\n",
      "Epoch 658/2000\n",
      "\n",
      "Epoch 00658: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.6405 - val_loss: 229.7795\n",
      "Epoch 659/2000\n",
      "\n",
      "Epoch 00659: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.6178 - val_loss: 229.7576\n",
      "Epoch 660/2000\n",
      "\n",
      "Epoch 00660: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.6032 - val_loss: 229.7697\n",
      "Epoch 661/2000\n",
      "\n",
      "Epoch 00661: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.6323 - val_loss: 229.7491\n",
      "Epoch 662/2000\n",
      "\n",
      "Epoch 00662: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.6042 - val_loss: 229.7051\n",
      "Epoch 663/2000\n",
      "\n",
      "Epoch 00663: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.5689 - val_loss: 229.6739\n",
      "Epoch 664/2000\n",
      "\n",
      "Epoch 00664: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 160.5703 - val_loss: 229.6578\n",
      "Epoch 665/2000\n",
      "\n",
      "Epoch 00665: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.5383 - val_loss: 229.6911\n",
      "Epoch 666/2000\n",
      "\n",
      "Epoch 00666: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 107us/step - loss: 160.5334 - val_loss: 229.6664\n",
      "Epoch 667/2000\n",
      "\n",
      "Epoch 00667: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.5123 - val_loss: 229.6726\n",
      "Epoch 668/2000\n",
      "\n",
      "Epoch 00668: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.5163 - val_loss: 229.6615\n",
      "Epoch 669/2000\n",
      "\n",
      "Epoch 00669: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.5146 - val_loss: 229.5987\n",
      "Epoch 670/2000\n",
      "\n",
      "Epoch 00670: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.4901 - val_loss: 229.5910\n",
      "Epoch 671/2000\n",
      "\n",
      "Epoch 00671: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 105us/step - loss: 160.4876 - val_loss: 229.5810\n",
      "Epoch 672/2000\n",
      "\n",
      "Epoch 00672: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.4642 - val_loss: 229.5746\n",
      "Epoch 673/2000\n",
      "\n",
      "Epoch 00673: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 160.4411 - val_loss: 229.6046\n",
      "Epoch 674/2000\n",
      "\n",
      "Epoch 00674: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.4935 - val_loss: 229.6938\n",
      "Epoch 675/2000\n",
      "\n",
      "Epoch 00675: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.4388 - val_loss: 229.6846\n",
      "Epoch 676/2000\n",
      "\n",
      "Epoch 00676: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.4225 - val_loss: 229.6645\n",
      "Epoch 677/2000\n",
      "\n",
      "Epoch 00677: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 160.4200 - val_loss: 229.7323\n",
      "Epoch 678/2000\n",
      "\n",
      "Epoch 00678: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 101us/step - loss: 160.4044 - val_loss: 229.7250\n",
      "Epoch 679/2000\n",
      "\n",
      "Epoch 00679: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 133us/step - loss: 160.3980 - val_loss: 229.7699\n",
      "Epoch 680/2000\n",
      "\n",
      "Epoch 00680: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 110us/step - loss: 160.3739 - val_loss: 229.7881\n",
      "Epoch 681/2000\n",
      "\n",
      "Epoch 00681: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.3653 - val_loss: 229.8047\n",
      "Epoch 682/2000\n",
      "\n",
      "Epoch 00682: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 113us/step - loss: 160.3400 - val_loss: 229.7766\n",
      "Epoch 683/2000\n",
      "\n",
      "Epoch 00683: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.3258 - val_loss: 229.7843\n",
      "Epoch 684/2000\n",
      "\n",
      "Epoch 00684: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.3100 - val_loss: 229.7586\n",
      "Epoch 685/2000\n",
      "\n",
      "Epoch 00685: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 103us/step - loss: 160.3046 - val_loss: 229.7557\n",
      "Epoch 686/2000\n",
      "\n",
      "Epoch 00686: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.2805 - val_loss: 229.7328\n",
      "Epoch 687/2000\n",
      "\n",
      "Epoch 00687: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.2832 - val_loss: 229.6829\n",
      "Epoch 688/2000\n",
      "\n",
      "Epoch 00688: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.2818 - val_loss: 229.7175\n",
      "Epoch 689/2000\n",
      "\n",
      "Epoch 00689: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.2648 - val_loss: 229.7679\n",
      "Epoch 690/2000\n",
      "\n",
      "Epoch 00690: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 106us/step - loss: 160.2412 - val_loss: 229.6926\n",
      "Epoch 691/2000\n",
      "\n",
      "Epoch 00691: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.2610 - val_loss: 229.7081\n",
      "Epoch 692/2000\n",
      "\n",
      "Epoch 00692: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 160.2214 - val_loss: 229.6870\n",
      "Epoch 693/2000\n",
      "\n",
      "Epoch 00693: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 96us/step - loss: 160.2128 - val_loss: 229.6795\n",
      "Epoch 694/2000\n",
      "\n",
      "Epoch 00694: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 103us/step - loss: 160.1955 - val_loss: 229.7283\n",
      "Epoch 695/2000\n",
      "\n",
      "Epoch 00695: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 93us/step - loss: 160.1739 - val_loss: 229.6590\n",
      "Epoch 696/2000\n",
      "\n",
      "Epoch 00696: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.1819 - val_loss: 229.6295\n",
      "Epoch 697/2000\n",
      "\n",
      "Epoch 00697: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "301/301 [==============================] - 0s 100us/step - loss: 160.1535 - val_loss: 229.6613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23e23c358c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit(tr_X, tr_y,\n",
    "     epochs=2000,\n",
    "     validation_split=0.15,\n",
    "     shuffle=True,\n",
    "     callbacks=[es, lrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = a.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14325110655155882"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss(val_y.flatten(), q.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def Denseblock(n):\n",
    "    def f(x):\n",
    "        activation=mish\n",
    "        x = Dense(n)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation)(x)\n",
    "        return x\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, d_dim, latent_dim):\n",
    "        K.clear_session()\n",
    "        self.d_dim = d_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hist = []\n",
    "        self.enc, self.dec, self.vae = self.build_vae()\n",
    "\n",
    "    def build_vae(self):\n",
    "        enc_input = Input(shape = (self.d_dim[1], ))\n",
    "        \n",
    "        x = Denseblock(16)(enc_input)\n",
    "        x = Denseblock(8)(x)\n",
    "        # mapping process\n",
    "        z_mean = Dense(self.latent_dim)(x)\n",
    "        z_log_var = Dense(self.latent_dim)(x)\n",
    "        enc_out = Lambda(sampling, output_shape=(self.latent_dim, ))([z_mean, z_log_var])\n",
    "        \n",
    "        dec_input = Input(shape = (self.latent_dim, ))\n",
    "        x = Denseblock(8)(dec_input)\n",
    "        x = Denseblock(16)(x)\n",
    "        \n",
    "        dec_out = Dense(self.d_dim[1], activation='sigmoid')(x)\n",
    "        \n",
    "        enc = Model(enc_input, enc_out, name='encoder')\n",
    "        dec = Model(dec_input, dec_out, name='decoder')\n",
    "        vae = Model(enc_input, dec(enc(enc_input)), name='vae')\n",
    "        \n",
    "        def vae_loss(x, x_decoded_mean):\n",
    "            xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "            mse = mean_squared_error(x, x_decoded_mean)\n",
    "            return xent_loss + kl_loss + mse\n",
    "        \n",
    "        vae.compile(optimizer=Lookahead(optimizers.Adam()), loss=vae_loss)\n",
    "        \n",
    "        return enc, dec, vae     \n",
    "    \n",
    "    # or fit manually\n",
    "    def train(self, x, y, epochs=10, batch_size=1024):\n",
    "        for e in range(epochs+1):\n",
    "            idx = np.random.randint(0, len(x), batch_size)\n",
    "            tr_X = x[idx]\n",
    "            tr_y = x[idx]\n",
    "\n",
    "            loss = self.vae.train_on_batch(tr_X, tr_y)\n",
    "            self.hist.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = VAE(tr_X.shape, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 71 samples\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.2907 - val_loss: 0.8510\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 1.1184 - val_loss: 0.8343\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 1.0015 - val_loss: 0.8171\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.9212 - val_loss: 0.8098\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.8615 - val_loss: 0.7946\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 320us/step - loss: 0.8126 - val_loss: 0.7847\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.7732 - val_loss: 0.7663\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.7418 - val_loss: 0.7565\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.7104 - val_loss: 0.7335\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.6896 - val_loss: 0.7076\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.6600 - val_loss: 0.7003\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.6428 - val_loss: 0.6785\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.6184 - val_loss: 0.6602\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.6020 - val_loss: 0.6590\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.5846 - val_loss: 0.6501\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.5767 - val_loss: 0.6446\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.5562 - val_loss: 0.6198\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.5466 - val_loss: 0.5921\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 301us/step - loss: 0.5341 - val_loss: 0.5917\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.5258 - val_loss: 0.5934\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.5084 - val_loss: 0.5562\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.5054 - val_loss: 0.5590\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.4865 - val_loss: 0.5439\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.4825 - val_loss: 0.5389\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.4715 - val_loss: 0.5297\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.4632 - val_loss: 0.5113\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.4565 - val_loss: 0.5060\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.4494 - val_loss: 0.5030\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 292us/step - loss: 0.4447 - val_loss: 0.4902\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.4404 - val_loss: 0.4879\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.4314 - val_loss: 0.4761\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.4247 - val_loss: 0.4748\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.4194 - val_loss: 0.4572\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 309us/step - loss: 0.4128 - val_loss: 0.4594\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.4075 - val_loss: 0.4552\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.4070 - val_loss: 0.4523\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 328us/step - loss: 0.3975 - val_loss: 0.4464\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.3946 - val_loss: 0.4447\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 335us/step - loss: 0.3931 - val_loss: 0.4361\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3891 - val_loss: 0.4359\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 292us/step - loss: 0.3851 - val_loss: 0.4295\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3801 - val_loss: 0.4289\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3758 - val_loss: 0.4240\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3724 - val_loss: 0.4209\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3709 - val_loss: 0.4197\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.3683 - val_loss: 0.4103\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.3633 - val_loss: 0.4119\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 317us/step - loss: 0.3640 - val_loss: 0.4117\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3603 - val_loss: 0.4114\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3574 - val_loss: 0.4065\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.3579 - val_loss: 0.4131\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3526 - val_loss: 0.4080\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3504 - val_loss: 0.4067\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3494 - val_loss: 0.4008\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3432 - val_loss: 0.4077\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3448 - val_loss: 0.4003\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3444 - val_loss: 0.4013\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3464 - val_loss: 0.4022\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3401 - val_loss: 0.3971\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3372 - val_loss: 0.3944\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3357 - val_loss: 0.3957\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3355 - val_loss: 0.3934\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3359 - val_loss: 0.3930\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3318 - val_loss: 0.3941\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3318 - val_loss: 0.3930\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3282 - val_loss: 0.3933\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3269 - val_loss: 0.3898\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.3289 - val_loss: 0.3888\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3271 - val_loss: 0.3889\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3253 - val_loss: 0.3872\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3253 - val_loss: 0.3891\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 311us/step - loss: 0.3231 - val_loss: 0.3849\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3228 - val_loss: 0.3866\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.3209 - val_loss: 0.3815\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3198 - val_loss: 0.3820\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.3194 - val_loss: 0.3841\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3194 - val_loss: 0.3834\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3183 - val_loss: 0.3824\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3145 - val_loss: 0.3814\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3164 - val_loss: 0.3797\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3146 - val_loss: 0.3818\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.3131 - val_loss: 0.3801\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3132 - val_loss: 0.3789\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3127 - val_loss: 0.3790\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3125 - val_loss: 0.3787\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3107 - val_loss: 0.3780\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3097 - val_loss: 0.3756\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 312us/step - loss: 0.3074 - val_loss: 0.3746\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3088 - val_loss: 0.3757\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 308us/step - loss: 0.3083 - val_loss: 0.3740\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3084 - val_loss: 0.3763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 312us/step - loss: 0.3070 - val_loss: 0.3742\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.3056 - val_loss: 0.3742\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.3059 - val_loss: 0.3725\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3057 - val_loss: 0.3716\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3050 - val_loss: 0.3704\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 319us/step - loss: 0.3049 - val_loss: 0.3701\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3060 - val_loss: 0.3699\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3040 - val_loss: 0.3683\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3029 - val_loss: 0.3701\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3031 - val_loss: 0.3675\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3020 - val_loss: 0.3680\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.3026 - val_loss: 0.3680\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.3024 - val_loss: 0.3673\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.3020 - val_loss: 0.3682\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3013 - val_loss: 0.3689\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.3010 - val_loss: 0.3681\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.3005 - val_loss: 0.3666\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.3008 - val_loss: 0.3690\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2995 - val_loss: 0.3664\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2997 - val_loss: 0.3658\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2978 - val_loss: 0.3649\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2980 - val_loss: 0.3651\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 328us/step - loss: 0.2979 - val_loss: 0.3648\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2976 - val_loss: 0.3676\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2994 - val_loss: 0.3660\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2962 - val_loss: 0.3650\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 292us/step - loss: 0.2961 - val_loss: 0.3650\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2959 - val_loss: 0.3627\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2962 - val_loss: 0.3640\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2963 - val_loss: 0.3639\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2966 - val_loss: 0.3623\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2957 - val_loss: 0.3639\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2948 - val_loss: 0.3644\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2953 - val_loss: 0.3628\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2940 - val_loss: 0.3616\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2951 - val_loss: 0.3645\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2945 - val_loss: 0.3631\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2949 - val_loss: 0.3623\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2953 - val_loss: 0.3622\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2942 - val_loss: 0.3621\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2939 - val_loss: 0.3624\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2925 - val_loss: 0.3596\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2927 - val_loss: 0.3597\n",
      "Epoch 135/2000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 338us/step - loss: 0.2940 - val_loss: 0.3604\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2931 - val_loss: 0.3602\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2920 - val_loss: 0.3600\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2912 - val_loss: 0.3584\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2919 - val_loss: 0.3589\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2905 - val_loss: 0.3607\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2918 - val_loss: 0.3598\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 314us/step - loss: 0.2923 - val_loss: 0.3589\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2910 - val_loss: 0.3590\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2905 - val_loss: 0.3584\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.2910 - val_loss: 0.3564\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2909 - val_loss: 0.3580\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2906 - val_loss: 0.3569\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2908 - val_loss: 0.3574\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2890 - val_loss: 0.3588\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2897 - val_loss: 0.3592\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2910 - val_loss: 0.3566\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2894 - val_loss: 0.3574\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2908 - val_loss: 0.3576\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2888 - val_loss: 0.3563\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2891 - val_loss: 0.3572\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2882 - val_loss: 0.3571\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 308us/step - loss: 0.2886 - val_loss: 0.3555\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2885 - val_loss: 0.3578\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2892 - val_loss: 0.3552\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 297us/step - loss: 0.2880 - val_loss: 0.3559\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2887 - val_loss: 0.3562\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2884 - val_loss: 0.3557\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2880 - val_loss: 0.3555\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2866 - val_loss: 0.3565\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2881 - val_loss: 0.3554\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2880 - val_loss: 0.3564\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2869 - val_loss: 0.3551\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2872 - val_loss: 0.3551\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2880 - val_loss: 0.3549\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2867 - val_loss: 0.3563\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 320us/step - loss: 0.2863 - val_loss: 0.3553\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 321us/step - loss: 0.2869 - val_loss: 0.3546\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2876 - val_loss: 0.3539\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2861 - val_loss: 0.3554\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2872 - val_loss: 0.3553\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2856 - val_loss: 0.3555\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2870 - val_loss: 0.3553\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 303us/step - loss: 0.2861 - val_loss: 0.3549\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 300us/step - loss: 0.2865 - val_loss: 0.3550\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2850 - val_loss: 0.3537\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2852 - val_loss: 0.3543\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2854 - val_loss: 0.3543\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2860 - val_loss: 0.3546\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2854 - val_loss: 0.3547\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2847 - val_loss: 0.3550\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2849 - val_loss: 0.3542\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2856 - val_loss: 0.3532\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2855 - val_loss: 0.3538\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2861 - val_loss: 0.3535\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2844 - val_loss: 0.3522\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2848 - val_loss: 0.3540\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 312us/step - loss: 0.2847 - val_loss: 0.3545\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2849 - val_loss: 0.3515\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2845 - val_loss: 0.3541\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2851 - val_loss: 0.3500\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2841 - val_loss: 0.3513\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 307us/step - loss: 0.2847 - val_loss: 0.3516\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2840 - val_loss: 0.3528\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2840 - val_loss: 0.3534\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2839 - val_loss: 0.3520\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 314us/step - loss: 0.2842 - val_loss: 0.3520\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 311us/step - loss: 0.2841 - val_loss: 0.3512\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2834 - val_loss: 0.3526\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2847 - val_loss: 0.3530\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2828 - val_loss: 0.3516\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2833 - val_loss: 0.3511\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 305us/step - loss: 0.2837 - val_loss: 0.3534\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 334us/step - loss: 0.2835 - val_loss: 0.3525\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2829 - val_loss: 0.3517\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2839 - val_loss: 0.3512\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2836 - val_loss: 0.3499\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 289us/step - loss: 0.2836 - val_loss: 0.3512\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2830 - val_loss: 0.3504\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2825 - val_loss: 0.3525\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2830 - val_loss: 0.3526\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2836 - val_loss: 0.3498\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2839 - val_loss: 0.3499\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 314us/step - loss: 0.2827 - val_loss: 0.3510\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2833 - val_loss: 0.3503\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 312us/step - loss: 0.2826 - val_loss: 0.3505\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 299us/step - loss: 0.2823 - val_loss: 0.3500\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2823 - val_loss: 0.3512\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2822 - val_loss: 0.3508\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 320us/step - loss: 0.2827 - val_loss: 0.3514\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2824 - val_loss: 0.3519\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2822 - val_loss: 0.3517\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2822 - val_loss: 0.3517\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2822 - val_loss: 0.3521\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2814 - val_loss: 0.3501\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2818 - val_loss: 0.3496\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2819 - val_loss: 0.3506\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2816 - val_loss: 0.3499\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2808 - val_loss: 0.3511\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2828 - val_loss: 0.3507\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2826 - val_loss: 0.3497\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2824 - val_loss: 0.3502\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2821 - val_loss: 0.3498\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 307us/step - loss: 0.2816 - val_loss: 0.3512\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2813 - val_loss: 0.3510\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2811 - val_loss: 0.3501\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 320us/step - loss: 0.2821 - val_loss: 0.3490\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2821 - val_loss: 0.3491\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.2814 - val_loss: 0.3491\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2815 - val_loss: 0.3482\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 301us/step - loss: 0.2815 - val_loss: 0.3497\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2810 - val_loss: 0.3497\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2810 - val_loss: 0.3505\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2812 - val_loss: 0.3487\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2812 - val_loss: 0.3488\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2806 - val_loss: 0.3487\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2808 - val_loss: 0.3489\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2804 - val_loss: 0.3482\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 314us/step - loss: 0.2806 - val_loss: 0.3490\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2807 - val_loss: 0.3505\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2810 - val_loss: 0.3489\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2799 - val_loss: 0.3498\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2813 - val_loss: 0.3487\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2810 - val_loss: 0.3486\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 314us/step - loss: 0.2808 - val_loss: 0.3479\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2802 - val_loss: 0.3478\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2804 - val_loss: 0.3482\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 312us/step - loss: 0.2805 - val_loss: 0.3481\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2799 - val_loss: 0.3496\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2799 - val_loss: 0.3485\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.00059049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 315us/step - loss: 0.2804 - val_loss: 0.3477\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2796 - val_loss: 0.3486\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 331us/step - loss: 0.2803 - val_loss: 0.3485\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2804 - val_loss: 0.3482\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2799 - val_loss: 0.3474\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2802 - val_loss: 0.3480\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2803 - val_loss: 0.3476\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2800 - val_loss: 0.3473\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.2800 - val_loss: 0.3490\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2803 - val_loss: 0.3506\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 320us/step - loss: 0.2798 - val_loss: 0.3477\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2801 - val_loss: 0.3487\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 327us/step - loss: 0.2804 - val_loss: 0.3476\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2803 - val_loss: 0.3480\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2796 - val_loss: 0.3489\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2802 - val_loss: 0.3474\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2793 - val_loss: 0.3468\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2798 - val_loss: 0.3471\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 301us/step - loss: 0.2795 - val_loss: 0.3479\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2797 - val_loss: 0.3478\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2794 - val_loss: 0.3476\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2794 - val_loss: 0.3479\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 324us/step - loss: 0.2793 - val_loss: 0.3508\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2793 - val_loss: 0.3471\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2794 - val_loss: 0.3473\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2796 - val_loss: 0.3479\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2796 - val_loss: 0.3481\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2792 - val_loss: 0.3480\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2798 - val_loss: 0.3461\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2798 - val_loss: 0.3464\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2795 - val_loss: 0.3474\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2791 - val_loss: 0.3456\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 310us/step - loss: 0.2785 - val_loss: 0.3480\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2795 - val_loss: 0.3459\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2790 - val_loss: 0.3463\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2789 - val_loss: 0.3470\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2783 - val_loss: 0.3475\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2792 - val_loss: 0.3483\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 309us/step - loss: 0.2789 - val_loss: 0.3460\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2793 - val_loss: 0.3457\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 320us/step - loss: 0.2783 - val_loss: 0.3470\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2789 - val_loss: 0.3469\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2791 - val_loss: 0.3473\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 306us/step - loss: 0.2794 - val_loss: 0.3482\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2792 - val_loss: 0.3467\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2789 - val_loss: 0.3477\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.000531441.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 327us/step - loss: 0.2790 - val_loss: 0.3477\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2789 - val_loss: 0.3463\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 317us/step - loss: 0.2789 - val_loss: 0.3473\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2796 - val_loss: 0.3477\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 313us/step - loss: 0.2786 - val_loss: 0.3468\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 305us/step - loss: 0.2788 - val_loss: 0.3464\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 296us/step - loss: 0.2792 - val_loss: 0.3456\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 307us/step - loss: 0.2787 - val_loss: 0.3466\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 303us/step - loss: 0.2788 - val_loss: 0.3456\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 299us/step - loss: 0.2781 - val_loss: 0.3471\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "284/284 [==============================] - 0s 305us/step - loss: 0.2779 - val_loss: 0.3473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23f7b052648>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.vae.fit(tr_X/113, tr_y/113,\n",
    "       epochs=2000,\n",
    "         validation_split=0.2,\n",
    "          shuffle=True,\n",
    "         callbacks=[es, lrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15663910454867103"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = b.vae.predict(val_X/113)*113\n",
    "custom_loss(val_y.flatten(), w.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
